[2022-12-04 23:00:11,366] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:68)
[2022-12-04 23:00:11,370] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Private Build, OpenJDK 64-Bit Server VM, 19.0.1, 19.0.1+10-Ubuntu-1ubuntu122.04
	jvm.classpath = /home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/activation-1.1.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/argparse4j-0.7.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/audience-annotations-0.5.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/commons-cli-1.4.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/commons-lang3-3.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-api-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-basic-auth-extension-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-file-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-json-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-mirror-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-mirror-client-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-runtime-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-transforms-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/hk2-api-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/hk2-locator-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/hk2-utils-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-annotations-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-core-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-databind-2.10.5.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-module-paranamer-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.inject-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/javassist-3.27.0-GA.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/javax.servlet-api-3.1.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jaxb-api-2.3.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-client-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-common-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-container-servlet-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-hk2-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-server-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jline-3.12.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jopt-simple-5.0.4.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka_2.13-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka_2.13-2.8.1-sources.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-clients-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-connect-jdbc-10.6.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-log4j-appender-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-metadata-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-raft-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-shell-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-streams-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-streams-examples-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-streams-scala_2.13-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-streams-test-utils-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-tools-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/log4j-1.2.17.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/lz4-java-1.7.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/maven-artifact-3.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/metrics-core-2.2.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-buffer-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-codec-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-common-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-handler-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-resolver-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-transport-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-transport-native-epoll-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-transport-native-unix-common-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/paranamer-2.8.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/plexus-utils-3.2.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/postgresql-42.5.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/reflections-0.9.12.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/rocksdbjni-5.18.4.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-collection-compat_2.13-2.3.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-library-2.13.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-logging_2.13-3.9.2.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-reflect-2.13.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/slf4j-api-1.7.30.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/snappy-java-1.1.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/zookeeper-3.5.9.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/zookeeper-jute-3.5.9.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/zstd-jni-1.4.9-1.jar
	os.spec = Linux, amd64, 6.0.0-1006-oem
	os.vcpus = 20
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2022-12-04 23:00:11,371] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:77)
[2022-12-04 23:00:12,129] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@251a69d7 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:269)
[2022-12-04 23:00:12,129] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,129] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,129] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,129] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,129] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,130] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,130] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,130] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,130] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,130] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,130] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,130] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,130] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,130] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,130] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,130] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,130] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,131] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,131] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,131] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,131] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,131] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,131] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,131] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,132] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,132] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,132] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,132] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,132] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,132] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,132] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,132] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,132] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,132] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,132] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,132] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,132] INFO Added plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,133] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,133] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,133] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,133] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,133] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,133] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,133] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,133] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,133] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,133] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,133] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,133] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,133] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,133] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,133] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,134] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:00:12,136] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:00:12,136] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:00:12,136] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:00:12,136] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:00:12,136] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:00:12,136] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:00:12,136] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:00:12,137] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:00:12,137] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:00:12,137] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:00:12,137] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:00:12,137] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:00:12,137] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:00:12,137] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:00:12,137] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:00:12,137] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:00:12,137] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:00:12,137] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:00:12,137] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:00:12,137] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:00:12,137] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:00:12,137] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:00:12,138] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:00:12,138] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:00:12,138] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:00:12,138] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:00:12,138] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:00:12,138] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:00:12,138] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:00:12,138] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:00:12,138] INFO Added aliases 'PredicatedTransformation' and 'Predicated' to plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:00:12,138] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:00:12,138] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:00:12,138] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:00:12,138] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:00:12,138] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:00:12,138] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:00:12,138] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:00:12,138] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:00:12,138] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:00:12,139] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:00:12,139] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:00:12,147] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = null
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:372)
[2022-12-04 23:00:12,147] WARN Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results. (org.apache.kafka.connect.runtime.WorkerConfig:420)
[2022-12-04 23:00:12,147] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:49)
[2022-12-04 23:00:12,149] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2022-12-04 23:00:12,182] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:00:12,182] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:00:12,182] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:00:12,182] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:00:12,182] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:00:12,182] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:00:12,182] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:00:12,183] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:00:12,183] INFO Kafka startTimeMs: 1670194812182 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:00:12,305] INFO Kafka cluster ID: uYYJbbgfRseD3C81aqQl8w (org.apache.kafka.connect.util.ConnectUtils:65)
[2022-12-04 23:00:12,306] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-04 23:00:12,309] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-04 23:00:12,309] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-04 23:00:12,309] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-04 23:00:12,315] INFO Logging initialized @1157ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2022-12-04 23:00:12,331] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:132)
[2022-12-04 23:00:12,331] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:204)
[2022-12-04 23:00:12,334] INFO jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 19.0.1+10-Ubuntu-1ubuntu122.04 (org.eclipse.jetty.server.Server:375)
[2022-12-04 23:00:12,348] INFO Started http_8083@36ac8a63{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:331)
[2022-12-04 23:00:12,348] INFO Started @1190ms (org.eclipse.jetty.server.Server:415)
[2022-12-04 23:00:12,356] INFO Advertised URI: http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:371)
[2022-12-04 23:00:12,356] INFO REST server listening at http://192.168.1.123:8083/, advertising URL http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2022-12-04 23:00:12,357] INFO Advertised URI: http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:371)
[2022-12-04 23:00:12,357] INFO REST admin endpoints at http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:220)
[2022-12-04 23:00:12,357] INFO Advertised URI: http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:371)
[2022-12-04 23:00:12,359] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2022-12-04 23:00:12,363] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:49)
[2022-12-04 23:00:12,363] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2022-12-04 23:00:12,365] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:00:12,365] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:00:12,365] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:00:12,365] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:00:12,365] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:00:12,365] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:00:12,365] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:00:12,365] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:00:12,366] INFO Kafka startTimeMs: 1670194812365 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:00:12,372] INFO Kafka cluster ID: uYYJbbgfRseD3C81aqQl8w (org.apache.kafka.connect.util.ConnectUtils:65)
[2022-12-04 23:00:12,372] INFO App info kafka.admin.client for adminclient-2 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-04 23:00:12,373] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-04 23:00:12,373] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-04 23:00:12,373] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-04 23:00:12,376] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:00:12,376] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:00:12,376] INFO Kafka startTimeMs: 1670194812375 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:00:12,420] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-04 23:00:12,421] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-04 23:00:12,424] INFO Kafka Connect standalone worker initialization took 1056ms (org.apache.kafka.connect.cli.ConnectStandalone:99)
[2022-12-04 23:00:12,424] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2022-12-04 23:00:12,424] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:94)
[2022-12-04 23:00:12,424] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:191)
[2022-12-04 23:00:12,425] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2022-12-04 23:00:12,428] INFO Worker started (org.apache.kafka.connect.runtime.Worker:198)
[2022-12-04 23:00:12,428] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:97)
[2022-12-04 23:00:12,428] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:224)
[2022-12-04 23:00:12,447] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:241)
[2022-12-04 23:00:12,481] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2022-12-04 23:00:12,481] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2022-12-04 23:00:12,482] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session:132)
[2022-12-04 23:00:12,660] INFO Started o.e.j.s.ServletContextHandler@3c017078{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:915)
[2022-12-04 23:00:12,660] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:319)
[2022-12-04 23:00:12,660] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2022-12-04 23:00:12,663] ERROR Failed to create job for config/sink-results.properties (org.apache.kafka.connect.cli.ConnectStandalone:107)
[2022-12-04 23:00:12,663] ERROR Stopping after connector error (org.apache.kafka.connect.cli.ConnectStandalone:117)
java.util.concurrent.ExecutionException: org.apache.kafka.common.config.ConfigException: Must configure one of topics or topics.regex
	at org.apache.kafka.connect.util.ConvertingFutureCallback.result(ConvertingFutureCallback.java:115)
	at org.apache.kafka.connect.util.ConvertingFutureCallback.get(ConvertingFutureCallback.java:99)
	at org.apache.kafka.connect.cli.ConnectStandalone.main(ConnectStandalone.java:114)
Caused by: org.apache.kafka.common.config.ConfigException: Must configure one of topics or topics.regex
	at org.apache.kafka.connect.runtime.SinkConnectorConfig.validate(SinkConnectorConfig.java:102)
	at org.apache.kafka.connect.runtime.AbstractHerder.validateConnectorConfig(AbstractHerder.java:377)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$validateConnectorConfig$2(AbstractHerder.java:351)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1589)
[2022-12-04 23:00:12,665] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2022-12-04 23:00:12,665] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:327)
[2022-12-04 23:00:12,667] INFO Stopped http_8083@36ac8a63{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:381)
[2022-12-04 23:00:12,667] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:149)
[2022-12-04 23:00:12,668] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:344)
[2022-12-04 23:00:12,668] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:102)
[2022-12-04 23:00:12,668] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:205)
[2022-12-04 23:00:12,668] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2022-12-04 23:00:12,668] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-04 23:00:12,668] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-04 23:00:12,668] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-04 23:00:12,669] INFO App info kafka.connect for 192.168.1.123:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-04 23:00:12,669] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:226)
[2022-12-04 23:00:12,669] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:120)
[2022-12-04 23:00:12,669] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2022-12-04 23:03:59,498] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:68)
[2022-12-04 23:03:59,502] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Private Build, OpenJDK 64-Bit Server VM, 19.0.1, 19.0.1+10-Ubuntu-1ubuntu122.04
	jvm.classpath = /home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/activation-1.1.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/argparse4j-0.7.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/audience-annotations-0.5.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/commons-cli-1.4.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/commons-lang3-3.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-api-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-basic-auth-extension-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-file-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-json-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-mirror-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-mirror-client-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-runtime-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-transforms-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/hk2-api-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/hk2-locator-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/hk2-utils-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-annotations-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-core-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-databind-2.10.5.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-module-paranamer-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.inject-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/javassist-3.27.0-GA.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/javax.servlet-api-3.1.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jaxb-api-2.3.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-client-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-common-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-container-servlet-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-hk2-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-server-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jline-3.12.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jopt-simple-5.0.4.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka_2.13-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka_2.13-2.8.1-sources.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-clients-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-connect-jdbc-10.6.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-log4j-appender-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-metadata-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-raft-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-shell-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-streams-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-streams-examples-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-streams-scala_2.13-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-streams-test-utils-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-tools-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/log4j-1.2.17.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/lz4-java-1.7.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/maven-artifact-3.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/metrics-core-2.2.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-buffer-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-codec-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-common-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-handler-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-resolver-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-transport-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-transport-native-epoll-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-transport-native-unix-common-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/paranamer-2.8.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/plexus-utils-3.2.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/postgresql-42.5.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/reflections-0.9.12.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/rocksdbjni-5.18.4.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-collection-compat_2.13-2.3.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-library-2.13.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-logging_2.13-3.9.2.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-reflect-2.13.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/slf4j-api-1.7.30.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/snappy-java-1.1.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/zookeeper-3.5.9.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/zookeeper-jute-3.5.9.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/zstd-jni-1.4.9-1.jar
	os.spec = Linux, amd64, 6.0.0-1006-oem
	os.vcpus = 20
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2022-12-04 23:03:59,503] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:77)
[2022-12-04 23:04:00,155] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@251a69d7 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:269)
[2022-12-04 23:04:00,155] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,155] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,155] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,155] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,155] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,155] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,155] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,155] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,156] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,156] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,156] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,156] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,156] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,156] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,156] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,157] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,157] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,157] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,157] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,157] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,158] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,158] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,158] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,158] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,158] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,158] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,158] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,158] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,158] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,158] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,158] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,158] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,158] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,159] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,159] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,159] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,159] INFO Added plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,159] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,159] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,159] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,159] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,159] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,159] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,159] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,159] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,159] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,159] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,159] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,159] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,160] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,160] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,160] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,160] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:04:00,162] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:04:00,163] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:04:00,163] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:04:00,163] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:04:00,163] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:04:00,163] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:04:00,163] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:04:00,163] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:04:00,163] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:04:00,163] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:04:00,163] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:04:00,163] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:04:00,163] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:04:00,164] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:04:00,164] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:04:00,164] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:04:00,164] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:04:00,164] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:04:00,164] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:04:00,164] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:04:00,164] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:04:00,164] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:04:00,164] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:04:00,164] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:04:00,164] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:04:00,164] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:04:00,164] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:04:00,164] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:04:00,164] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:04:00,164] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:04:00,164] INFO Added aliases 'PredicatedTransformation' and 'Predicated' to plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:04:00,165] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:04:00,165] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:04:00,165] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:04:00,165] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:04:00,165] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:04:00,165] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:04:00,165] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:04:00,165] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:04:00,165] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:04:00,165] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:04:00,165] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:04:00,174] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = null
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:372)
[2022-12-04 23:04:00,174] WARN Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results. (org.apache.kafka.connect.runtime.WorkerConfig:420)
[2022-12-04 23:04:00,175] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:49)
[2022-12-04 23:04:00,176] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2022-12-04 23:04:00,211] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:04:00,211] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:04:00,211] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:04:00,212] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:04:00,212] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:04:00,212] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:04:00,212] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:04:00,212] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:04:00,212] INFO Kafka startTimeMs: 1670195040212 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:04:00,348] INFO Kafka cluster ID: uYYJbbgfRseD3C81aqQl8w (org.apache.kafka.connect.util.ConnectUtils:65)
[2022-12-04 23:04:00,348] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-04 23:04:00,351] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-04 23:04:00,352] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-04 23:04:00,352] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-04 23:04:00,358] INFO Logging initialized @1080ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2022-12-04 23:04:00,376] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:132)
[2022-12-04 23:04:00,376] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:204)
[2022-12-04 23:04:00,380] INFO jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 19.0.1+10-Ubuntu-1ubuntu122.04 (org.eclipse.jetty.server.Server:375)
[2022-12-04 23:04:00,395] INFO Started http_8083@66d23e4a{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:331)
[2022-12-04 23:04:00,395] INFO Started @1116ms (org.eclipse.jetty.server.Server:415)
[2022-12-04 23:04:00,404] INFO Advertised URI: http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:371)
[2022-12-04 23:04:00,404] INFO REST server listening at http://192.168.1.123:8083/, advertising URL http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2022-12-04 23:04:00,405] INFO Advertised URI: http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:371)
[2022-12-04 23:04:00,405] INFO REST admin endpoints at http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:220)
[2022-12-04 23:04:00,405] INFO Advertised URI: http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:371)
[2022-12-04 23:04:00,407] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2022-12-04 23:04:00,411] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:49)
[2022-12-04 23:04:00,412] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2022-12-04 23:04:00,416] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:04:00,417] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:04:00,417] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:04:00,417] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:04:00,417] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:04:00,417] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:04:00,417] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:04:00,417] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:04:00,417] INFO Kafka startTimeMs: 1670195040417 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:04:00,426] INFO Kafka cluster ID: uYYJbbgfRseD3C81aqQl8w (org.apache.kafka.connect.util.ConnectUtils:65)
[2022-12-04 23:04:00,427] INFO App info kafka.admin.client for adminclient-2 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-04 23:04:00,428] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-04 23:04:00,428] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-04 23:04:00,428] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-04 23:04:00,431] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:04:00,431] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:04:00,431] INFO Kafka startTimeMs: 1670195040431 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:04:00,482] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-04 23:04:00,483] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-04 23:04:00,486] INFO Kafka Connect standalone worker initialization took 987ms (org.apache.kafka.connect.cli.ConnectStandalone:99)
[2022-12-04 23:04:00,486] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2022-12-04 23:04:00,487] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:94)
[2022-12-04 23:04:00,487] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:191)
[2022-12-04 23:04:00,487] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2022-12-04 23:04:00,491] INFO Worker started (org.apache.kafka.connect.runtime.Worker:198)
[2022-12-04 23:04:00,491] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:97)
[2022-12-04 23:04:00,491] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:224)
[2022-12-04 23:04:00,509] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:241)
[2022-12-04 23:04:00,549] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2022-12-04 23:04:00,549] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2022-12-04 23:04:00,550] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session:132)
[2022-12-04 23:04:00,755] INFO Started o.e.j.s.ServletContextHandler@3be4f71{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:915)
[2022-12-04 23:04:00,755] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:319)
[2022-12-04 23:04:00,755] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2022-12-04 23:04:00,768] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2022-12-04 23:04:00,773] INFO Creating connector sink-results of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:271)
[2022-12-04 23:04:00,773] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2022-12-04 23:04:00,774] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:04:00,775] INFO Instantiated connector sink-results with version 10.6.0 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:281)
[2022-12-04 23:04:00,776] INFO Finished creating connector sink-results (org.apache.kafka.connect.runtime.Worker:306)
[2022-12-04 23:04:00,777] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2022-12-04 23:04:00,777] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:04:00,777] INFO Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:51)
[2022-12-04 23:04:00,778] INFO Creating task sink-results-0 (org.apache.kafka.connect.runtime.Worker:505)
[2022-12-04 23:04:00,778] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2022-12-04 23:04:00,778] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:04:00,779] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2022-12-04 23:04:00,779] INFO Instantiated task sink-results-0 with version 10.6.0 of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:520)
[2022-12-04 23:04:00,780] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:372)
[2022-12-04 23:04:00,780] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-04 23:04:00,780] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task sink-results-0 using the connector config (org.apache.kafka.connect.runtime.Worker:535)
[2022-12-04 23:04:00,780] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task sink-results-0 using the connector config (org.apache.kafka.connect.runtime.Worker:541)
[2022-12-04 23:04:00,780] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task sink-results-0 using the worker config (org.apache.kafka.connect.runtime.Worker:546)
[2022-12-04 23:04:00,782] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:626)
[2022-12-04 23:04:00,782] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2022-12-04 23:04:00,782] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:04:00,788] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-sink-results-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-sink-results
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2022-12-04 23:04:00,807] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-04 23:04:00,807] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:04:00,808] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:04:00,808] INFO Kafka startTimeMs: 1670195040807 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:04:00,813] INFO Created connector sink-results (org.apache.kafka.connect.cli.ConnectStandalone:109)
[2022-12-04 23:04:00,814] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Subscribed to topic(s): ResultsWeather, ResultsAlert, ResultsLocation (org.apache.kafka.clients.consumer.KafkaConsumer:965)
[2022-12-04 23:04:00,814] INFO Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:48)
[2022-12-04 23:04:00,814] INFO JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:postgresql://localhost:5432/kafka
	connection.user = postgres
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = upsert
	max.retries = 10
	pk.fields = [id]
	pk.mode = none
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:372)
[2022-12-04 23:04:00,815] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:postgresql://localhost:5432/kafka
	connection.user = postgres
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = SELECT * FROM stations;
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = DBInfo
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:372)
[2022-12-04 23:04:00,816] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2022-12-04 23:04:00,816] INFO Creating connector source-dbinfo of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:271)
[2022-12-04 23:04:00,816] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2022-12-04 23:04:00,817] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:04:00,817] INFO Initializing writer using SQL dialect: PostgreSqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2022-12-04 23:04:00,818] INFO WorkerSinkTask{id=sink-results-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:310)
[2022-12-04 23:04:00,818] INFO WorkerSinkTask{id=sink-results-0} Executing sink task (org.apache.kafka.connect.runtime.WorkerSinkTask:196)
[2022-12-04 23:04:00,818] INFO Instantiated connector source-dbinfo with version 10.6.0 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:281)
[2022-12-04 23:04:00,819] INFO Finished creating connector source-dbinfo (org.apache.kafka.connect.runtime.Worker:306)
[2022-12-04 23:04:00,819] INFO Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:71)
[2022-12-04 23:04:00,820] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:postgresql://localhost:5432/kafka
	connection.user = postgres
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = SELECT * FROM stations;
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = DBInfo
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:372)
[2022-12-04 23:04:00,820] INFO Attempting to open connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:79)
[2022-12-04 23:04:00,828] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Cluster ID: uYYJbbgfRseD3C81aqQl8w (org.apache.kafka.clients.Metadata:279)
[2022-12-04 23:04:00,829] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Discovered group coordinator localhost:9092 (id: 2147483646 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:850)
[2022-12-04 23:04:00,830] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2022-12-04 23:04:00,843] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2022-12-04 23:04:00,882] INFO Maximum table name length for database is 63 bytes (io.confluent.connect.jdbc.dialect.PostgreSqlDatabaseDialect:130)
[2022-12-04 23:04:00,884] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2022-12-04 23:04:00,884] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:04:00,885] INFO Creating task source-dbinfo-0 (org.apache.kafka.connect.runtime.Worker:505)
[2022-12-04 23:04:00,886] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2022-12-04 23:04:00,886] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:04:00,886] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.source.JdbcSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2022-12-04 23:04:00,887] INFO Instantiated task source-dbinfo-0 with version 10.6.0 of type io.confluent.connect.jdbc.source.JdbcSourceTask (org.apache.kafka.connect.runtime.Worker:520)
[2022-12-04 23:04:00,887] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-04 23:04:00,887] INFO Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task source-dbinfo-0 using the worker config (org.apache.kafka.connect.runtime.Worker:533)
[2022-12-04 23:04:00,887] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-04 23:04:00,887] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task source-dbinfo-0 using the worker config (org.apache.kafka.connect.runtime.Worker:539)
[2022-12-04 23:04:00,888] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task source-dbinfo-0 using the worker config (org.apache.kafka.connect.runtime.Worker:546)
[2022-12-04 23:04:00,888] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2022-12-04 23:04:00,888] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:04:00,888] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:600)
[2022-12-04 23:04:00,891] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-source-dbinfo-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2022-12-04 23:04:00,899] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-04 23:04:00,899] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:04:00,899] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:04:00,899] INFO Kafka startTimeMs: 1670195040899 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:04:00,902] INFO [Producer clientId=connector-producer-source-dbinfo-0] Cluster ID: uYYJbbgfRseD3C81aqQl8w (org.apache.kafka.clients.Metadata:279)
[2022-12-04 23:04:00,902] INFO Starting JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:92)
[2022-12-04 23:04:00,902] INFO JdbcSourceTaskConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:postgresql://localhost:5432/kafka
	connection.user = postgres
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = SELECT * FROM stations;
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	tables = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = DBInfo
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceTaskConfig:372)
[2022-12-04 23:04:00,902] INFO Using JDBC dialect PostgreSql (io.confluent.connect.jdbc.source.JdbcSourceTask:127)
[2022-12-04 23:04:00,902] INFO Created connector source-dbinfo (org.apache.kafka.connect.cli.ConnectStandalone:109)
[2022-12-04 23:04:00,902] INFO Attempting to open connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:79)
[2022-12-04 23:04:00,908] INFO Maximum table name length for database is 63 bytes (io.confluent.connect.jdbc.dialect.PostgreSqlDatabaseDialect:130)
[2022-12-04 23:04:00,909] INFO Started JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:296)
[2022-12-04 23:04:00,910] INFO WorkerSourceTask{id=source-dbinfo-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:232)
[2022-12-04 23:04:00,910] INFO WorkerSourceTask{id=source-dbinfo-0} Executing source task (org.apache.kafka.connect.runtime.WorkerSourceTask:238)
[2022-12-04 23:04:00,919] INFO Begin using SQL query: SELECT * FROM stations; (io.confluent.connect.jdbc.source.TableQuerier:181)
[2022-12-04 23:04:03,848] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Successfully joined group with generation Generation{generationId=3, memberId='connector-consumer-sink-results-0-2698d442-12eb-4e42-8d9b-29da1aaa73e1', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2022-12-04 23:04:03,851] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Finished assignment for group at generation 3: {connector-consumer-sink-results-0-2698d442-12eb-4e42-8d9b-29da1aaa73e1=Assignment(partitions=[ResultsLocation-0, ResultsWeather-0, ResultsAlert-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:626)
[2022-12-04 23:04:03,857] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Successfully synced group in generation Generation{generationId=3, memberId='connector-consumer-sink-results-0-2698d442-12eb-4e42-8d9b-29da1aaa73e1', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:760)
[2022-12-04 23:04:03,857] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Notifying assignor about the new Assignment(partitions=[ResultsLocation-0, ResultsWeather-0, ResultsAlert-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:276)
[2022-12-04 23:04:03,859] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Adding newly assigned partitions: ResultsLocation-0, ResultsWeather-0, ResultsAlert-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:288)
[2022-12-04 23:04:03,863] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Found no committed offset for partition ResultsLocation-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1362)
[2022-12-04 23:04:03,863] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Found no committed offset for partition ResultsWeather-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1362)
[2022-12-04 23:04:03,863] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Found no committed offset for partition ResultsAlert-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1362)
[2022-12-04 23:04:03,869] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Resetting offset for partition ResultsLocation-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: r1)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-04 23:04:03,870] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Resetting offset for partition ResultsWeather-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: r1)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-04 23:04:03,870] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Resetting offset for partition ResultsAlert-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: r1)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-04 23:04:03,887] INFO Attempting to open connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:79)
[2022-12-04 23:04:03,893] INFO Maximum table name length for database is 63 bytes (io.confluent.connect.jdbc.dialect.PostgreSqlDatabaseDialect:130)
[2022-12-04 23:04:03,893] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2022-12-04 23:04:03,899] INFO Checking PostgreSql dialect for existence of TABLE "ResultsWeather" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:586)
[2022-12-04 23:04:03,901] INFO Using PostgreSql dialect TABLE "ResultsWeather" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:594)
[2022-12-04 23:04:03,907] INFO Checking PostgreSql dialect for type of TABLE "ResultsWeather" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:880)
[2022-12-04 23:04:03,909] INFO Setting metadata for table "ResultsWeather" to Table{name='"ResultsWeather"', type=TABLE columns=[Column{'count', isPrimaryKey=false, allowsNull=false, sqlType=int8}, Column{'station', isPrimaryKey=false, allowsNull=false, sqlType=text}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2022-12-04 23:04:03,910] ERROR WorkerSinkTask{id=sink-results-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted. Error: Write to table '"ResultsWeather"' in UPSERT mode requires key field names to be known, check the primary key configuration (org.apache.kafka.connect.runtime.WorkerSinkTask:608)
org.apache.kafka.connect.errors.ConnectException: Write to table '"ResultsWeather"' in UPSERT mode requires key field names to be known, check the primary key configuration
	at io.confluent.connect.jdbc.sink.BufferedRecords.getInsertSql(BufferedRecords.java:244)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:128)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:582)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:330)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:188)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1589)
[2022-12-04 23:04:03,911] ERROR WorkerSinkTask{id=sink-results-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:190)
org.apache.kafka.connect.errors.ConnectException: Exiting WorkerSinkTask due to unrecoverable exception.
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:610)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:330)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:188)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1589)
Caused by: org.apache.kafka.connect.errors.ConnectException: Write to table '"ResultsWeather"' in UPSERT mode requires key field names to be known, check the primary key configuration
	at io.confluent.connect.jdbc.sink.BufferedRecords.getInsertSql(BufferedRecords.java:244)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:128)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:582)
	... 10 more
[2022-12-04 23:04:03,911] INFO Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:161)
[2022-12-04 23:04:03,911] INFO Closing connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:105)
[2022-12-04 23:04:03,912] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Revoke previously assigned partitions ResultsLocation-0, ResultsWeather-0, ResultsAlert-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:307)
[2022-12-04 23:04:03,912] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Member connector-consumer-sink-results-0-2698d442-12eb-4e42-8d9b-29da1aaa73e1 sending LeaveGroup request to coordinator localhost:9092 (id: 2147483646 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:1045)
[2022-12-04 23:04:03,914] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-04 23:04:03,914] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-04 23:04:03,914] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-04 23:04:03,915] INFO App info kafka.consumer for connector-consumer-sink-results-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-04 23:04:10,903] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:04:20,911] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:04:30,914] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:04:40,916] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:04:50,918] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:05:00,921] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:05:10,922] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:05:20,925] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:05:23,279] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2022-12-04 23:05:23,279] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:327)
[2022-12-04 23:05:23,282] INFO Stopped http_8083@66d23e4a{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:381)
[2022-12-04 23:05:23,282] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:149)
[2022-12-04 23:05:23,284] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:344)
[2022-12-04 23:05:23,284] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:102)
[2022-12-04 23:05:23,285] INFO Stopping task source-dbinfo-0 (org.apache.kafka.connect.runtime.Worker:830)
[2022-12-04 23:05:25,972] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 7 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:05:25,976] INFO Stopping JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:354)
[2022-12-04 23:05:25,976] INFO Closing resources for JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:366)
[2022-12-04 23:05:25,976] INFO Closing connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:105)
[2022-12-04 23:05:25,977] INFO [Producer clientId=connector-producer-source-dbinfo-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1204)
[2022-12-04 23:05:25,978] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-04 23:05:25,979] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-04 23:05:25,979] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-04 23:05:25,980] INFO App info kafka.producer for connector-producer-source-dbinfo-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-04 23:05:25,983] INFO Stopping connector source-dbinfo (org.apache.kafka.connect.runtime.Worker:382)
[2022-12-04 23:05:25,984] INFO Scheduled shutdown for WorkerConnector{id=source-dbinfo} (org.apache.kafka.connect.runtime.WorkerConnector:248)
[2022-12-04 23:05:25,984] INFO Stopping table monitoring thread (io.confluent.connect.jdbc.JdbcSourceConnector:200)
[2022-12-04 23:05:25,984] INFO Shutting down thread monitoring tables. (io.confluent.connect.jdbc.source.TableMonitorThread:168)
[2022-12-04 23:05:25,985] INFO Closing connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:105)
[2022-12-04 23:05:25,985] INFO Completed shutdown for WorkerConnector{id=source-dbinfo} (org.apache.kafka.connect.runtime.WorkerConnector:268)
[2022-12-04 23:05:25,985] INFO Stopping task sink-results-0 (org.apache.kafka.connect.runtime.Worker:830)
[2022-12-04 23:05:25,987] INFO Stopping connector sink-results (org.apache.kafka.connect.runtime.Worker:382)
[2022-12-04 23:05:25,987] INFO Scheduled shutdown for WorkerConnector{id=sink-results} (org.apache.kafka.connect.runtime.WorkerConnector:248)
[2022-12-04 23:05:25,988] INFO Completed shutdown for WorkerConnector{id=sink-results} (org.apache.kafka.connect.runtime.WorkerConnector:268)
[2022-12-04 23:05:25,988] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:205)
[2022-12-04 23:05:25,989] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2022-12-04 23:05:25,990] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-04 23:05:25,990] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-04 23:05:25,990] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-04 23:05:25,991] INFO App info kafka.connect for 192.168.1.123:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-04 23:05:25,991] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:226)
[2022-12-04 23:05:25,993] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:120)
[2022-12-04 23:05:25,993] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2022-12-04 23:05:27,167] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:68)
[2022-12-04 23:05:27,171] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Private Build, OpenJDK 64-Bit Server VM, 19.0.1, 19.0.1+10-Ubuntu-1ubuntu122.04
	jvm.classpath = /home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/activation-1.1.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/argparse4j-0.7.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/audience-annotations-0.5.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/commons-cli-1.4.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/commons-lang3-3.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-api-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-basic-auth-extension-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-file-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-json-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-mirror-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-mirror-client-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-runtime-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-transforms-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/hk2-api-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/hk2-locator-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/hk2-utils-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-annotations-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-core-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-databind-2.10.5.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-module-paranamer-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.inject-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/javassist-3.27.0-GA.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/javax.servlet-api-3.1.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jaxb-api-2.3.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-client-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-common-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-container-servlet-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-hk2-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-server-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jline-3.12.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jopt-simple-5.0.4.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka_2.13-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka_2.13-2.8.1-sources.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-clients-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-connect-jdbc-10.6.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-log4j-appender-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-metadata-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-raft-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-shell-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-streams-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-streams-examples-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-streams-scala_2.13-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-streams-test-utils-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-tools-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/log4j-1.2.17.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/lz4-java-1.7.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/maven-artifact-3.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/metrics-core-2.2.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-buffer-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-codec-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-common-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-handler-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-resolver-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-transport-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-transport-native-epoll-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-transport-native-unix-common-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/paranamer-2.8.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/plexus-utils-3.2.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/postgresql-42.5.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/reflections-0.9.12.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/rocksdbjni-5.18.4.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-collection-compat_2.13-2.3.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-library-2.13.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-logging_2.13-3.9.2.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-reflect-2.13.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/slf4j-api-1.7.30.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/snappy-java-1.1.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/zookeeper-3.5.9.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/zookeeper-jute-3.5.9.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/zstd-jni-1.4.9-1.jar
	os.spec = Linux, amd64, 6.0.0-1006-oem
	os.vcpus = 20
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2022-12-04 23:05:27,172] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:77)
[2022-12-04 23:05:27,767] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@251a69d7 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:269)
[2022-12-04 23:05:27,767] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,767] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,768] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,768] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,768] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,768] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,768] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,768] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,768] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,768] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,768] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,768] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,769] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,769] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,769] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,769] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,769] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,770] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,770] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,770] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,770] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,770] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,770] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,770] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,770] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,770] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,770] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,771] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,771] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,771] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,771] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,771] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,771] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,771] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,771] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,771] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,771] INFO Added plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,771] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,771] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,772] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,772] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,772] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,772] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,772] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,772] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,772] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,772] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,772] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,772] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,772] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,773] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,773] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,773] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:05:27,776] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:05:27,776] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:05:27,776] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:05:27,776] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:05:27,776] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:05:27,776] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:05:27,777] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:05:27,777] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:05:27,777] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:05:27,777] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:05:27,777] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:05:27,777] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:05:27,777] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:05:27,777] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:05:27,777] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:05:27,777] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:05:27,778] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:05:27,778] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:05:27,778] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:05:27,778] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:05:27,778] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:05:27,778] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:05:27,778] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:05:27,778] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:05:27,778] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:05:27,778] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:05:27,778] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:05:27,778] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:05:27,778] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:05:27,779] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:05:27,779] INFO Added aliases 'PredicatedTransformation' and 'Predicated' to plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:05:27,779] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:05:27,779] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:05:27,779] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:05:27,779] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:05:27,779] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:05:27,779] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:05:27,779] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:05:27,779] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:05:27,779] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:05:27,779] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:05:27,780] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:05:27,790] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = null
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:372)
[2022-12-04 23:05:27,790] WARN Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results. (org.apache.kafka.connect.runtime.WorkerConfig:420)
[2022-12-04 23:05:27,790] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:49)
[2022-12-04 23:05:27,792] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2022-12-04 23:05:27,822] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:05:27,822] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:05:27,822] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:05:27,822] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:05:27,822] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:05:27,822] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:05:27,822] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:05:27,822] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:05:27,822] INFO Kafka startTimeMs: 1670195127822 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:05:27,946] INFO Kafka cluster ID: uYYJbbgfRseD3C81aqQl8w (org.apache.kafka.connect.util.ConnectUtils:65)
[2022-12-04 23:05:27,947] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-04 23:05:27,950] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-04 23:05:27,950] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-04 23:05:27,950] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-04 23:05:27,956] INFO Logging initialized @1008ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2022-12-04 23:05:27,972] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:132)
[2022-12-04 23:05:27,972] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:204)
[2022-12-04 23:05:27,975] INFO jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 19.0.1+10-Ubuntu-1ubuntu122.04 (org.eclipse.jetty.server.Server:375)
[2022-12-04 23:05:27,985] INFO Started http_8083@66d23e4a{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:331)
[2022-12-04 23:05:27,985] INFO Started @1037ms (org.eclipse.jetty.server.Server:415)
[2022-12-04 23:05:27,994] INFO Advertised URI: http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:371)
[2022-12-04 23:05:27,994] INFO REST server listening at http://192.168.1.123:8083/, advertising URL http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2022-12-04 23:05:27,994] INFO Advertised URI: http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:371)
[2022-12-04 23:05:27,994] INFO REST admin endpoints at http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:220)
[2022-12-04 23:05:27,995] INFO Advertised URI: http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:371)
[2022-12-04 23:05:27,996] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2022-12-04 23:05:28,001] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:49)
[2022-12-04 23:05:28,001] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2022-12-04 23:05:28,005] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:05:28,005] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:05:28,005] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:05:28,005] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:05:28,006] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:05:28,006] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:05:28,006] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:05:28,006] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:05:28,006] INFO Kafka startTimeMs: 1670195128006 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:05:28,012] INFO Kafka cluster ID: uYYJbbgfRseD3C81aqQl8w (org.apache.kafka.connect.util.ConnectUtils:65)
[2022-12-04 23:05:28,012] INFO App info kafka.admin.client for adminclient-2 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-04 23:05:28,014] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-04 23:05:28,014] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-04 23:05:28,014] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-04 23:05:28,016] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:05:28,016] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:05:28,016] INFO Kafka startTimeMs: 1670195128016 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:05:28,058] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-04 23:05:28,059] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-04 23:05:28,062] INFO Kafka Connect standalone worker initialization took 894ms (org.apache.kafka.connect.cli.ConnectStandalone:99)
[2022-12-04 23:05:28,062] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2022-12-04 23:05:28,062] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:94)
[2022-12-04 23:05:28,062] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:191)
[2022-12-04 23:05:28,063] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2022-12-04 23:05:28,066] INFO Worker started (org.apache.kafka.connect.runtime.Worker:198)
[2022-12-04 23:05:28,066] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:97)
[2022-12-04 23:05:28,066] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:224)
[2022-12-04 23:05:28,082] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:241)
[2022-12-04 23:05:28,112] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2022-12-04 23:05:28,112] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2022-12-04 23:05:28,113] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session:132)
[2022-12-04 23:05:28,312] INFO Started o.e.j.s.ServletContextHandler@3be4f71{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:915)
[2022-12-04 23:05:28,312] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:319)
[2022-12-04 23:05:28,312] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2022-12-04 23:05:28,325] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2022-12-04 23:05:28,330] INFO Creating connector sink-results of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:271)
[2022-12-04 23:05:28,330] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2022-12-04 23:05:28,330] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:05:28,331] INFO Instantiated connector sink-results with version 10.6.0 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:281)
[2022-12-04 23:05:28,332] INFO Finished creating connector sink-results (org.apache.kafka.connect.runtime.Worker:306)
[2022-12-04 23:05:28,333] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2022-12-04 23:05:28,333] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:05:28,334] INFO Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:51)
[2022-12-04 23:05:28,334] INFO Creating task sink-results-0 (org.apache.kafka.connect.runtime.Worker:505)
[2022-12-04 23:05:28,334] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2022-12-04 23:05:28,335] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:05:28,335] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2022-12-04 23:05:28,335] INFO Instantiated task sink-results-0 with version 10.6.0 of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:520)
[2022-12-04 23:05:28,336] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:372)
[2022-12-04 23:05:28,336] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-04 23:05:28,336] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task sink-results-0 using the connector config (org.apache.kafka.connect.runtime.Worker:535)
[2022-12-04 23:05:28,336] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task sink-results-0 using the connector config (org.apache.kafka.connect.runtime.Worker:541)
[2022-12-04 23:05:28,336] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task sink-results-0 using the worker config (org.apache.kafka.connect.runtime.Worker:546)
[2022-12-04 23:05:28,337] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:626)
[2022-12-04 23:05:28,338] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2022-12-04 23:05:28,338] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:05:28,342] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-sink-results-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-sink-results
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2022-12-04 23:05:28,356] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-04 23:05:28,356] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:05:28,356] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:05:28,356] INFO Kafka startTimeMs: 1670195128356 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:05:28,361] INFO Created connector sink-results (org.apache.kafka.connect.cli.ConnectStandalone:109)
[2022-12-04 23:05:28,362] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Subscribed to topic(s): ResultsWeather, ResultsAlert, ResultsLocation (org.apache.kafka.clients.consumer.KafkaConsumer:965)
[2022-12-04 23:05:28,362] INFO Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:48)
[2022-12-04 23:05:28,362] INFO JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:postgresql://localhost:5432/kafka
	connection.user = postgres
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = upsert
	max.retries = 10
	pk.fields = [id]
	pk.mode = none
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:372)
[2022-12-04 23:05:28,363] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:postgresql://localhost:5432/kafka
	connection.user = postgres
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = SELECT * FROM stations;
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = DBInfo
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:372)
[2022-12-04 23:05:28,363] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2022-12-04 23:05:28,364] INFO Creating connector source-dbinfo of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:271)
[2022-12-04 23:05:28,364] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2022-12-04 23:05:28,364] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:05:28,365] INFO Instantiated connector source-dbinfo with version 10.6.0 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:281)
[2022-12-04 23:05:28,365] INFO Initializing writer using SQL dialect: PostgreSqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2022-12-04 23:05:28,365] INFO Finished creating connector source-dbinfo (org.apache.kafka.connect.runtime.Worker:306)
[2022-12-04 23:05:28,365] INFO Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:71)
[2022-12-04 23:05:28,365] INFO WorkerSinkTask{id=sink-results-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:310)
[2022-12-04 23:05:28,365] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:postgresql://localhost:5432/kafka
	connection.user = postgres
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = SELECT * FROM stations;
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = DBInfo
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:372)
[2022-12-04 23:05:28,365] INFO WorkerSinkTask{id=sink-results-0} Executing sink task (org.apache.kafka.connect.runtime.WorkerSinkTask:196)
[2022-12-04 23:05:28,365] INFO Attempting to open connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:79)
[2022-12-04 23:05:28,372] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Cluster ID: uYYJbbgfRseD3C81aqQl8w (org.apache.kafka.clients.Metadata:279)
[2022-12-04 23:05:28,373] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Discovered group coordinator localhost:9092 (id: 2147483646 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:850)
[2022-12-04 23:05:28,374] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2022-12-04 23:05:28,380] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2022-12-04 23:05:28,414] INFO Maximum table name length for database is 63 bytes (io.confluent.connect.jdbc.dialect.PostgreSqlDatabaseDialect:130)
[2022-12-04 23:05:28,415] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2022-12-04 23:05:28,415] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:05:28,416] INFO Creating task source-dbinfo-0 (org.apache.kafka.connect.runtime.Worker:505)
[2022-12-04 23:05:28,416] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2022-12-04 23:05:28,416] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:05:28,418] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.source.JdbcSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2022-12-04 23:05:28,418] INFO Instantiated task source-dbinfo-0 with version 10.6.0 of type io.confluent.connect.jdbc.source.JdbcSourceTask (org.apache.kafka.connect.runtime.Worker:520)
[2022-12-04 23:05:28,419] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-04 23:05:28,419] INFO Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task source-dbinfo-0 using the worker config (org.apache.kafka.connect.runtime.Worker:533)
[2022-12-04 23:05:28,419] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-04 23:05:28,419] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task source-dbinfo-0 using the worker config (org.apache.kafka.connect.runtime.Worker:539)
[2022-12-04 23:05:28,419] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task source-dbinfo-0 using the worker config (org.apache.kafka.connect.runtime.Worker:546)
[2022-12-04 23:05:28,419] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2022-12-04 23:05:28,419] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:05:28,419] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:600)
[2022-12-04 23:05:28,421] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-source-dbinfo-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2022-12-04 23:05:28,429] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-04 23:05:28,429] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:05:28,429] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:05:28,429] INFO Kafka startTimeMs: 1670195128429 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:05:28,432] INFO Starting JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:92)
[2022-12-04 23:05:28,432] INFO [Producer clientId=connector-producer-source-dbinfo-0] Cluster ID: uYYJbbgfRseD3C81aqQl8w (org.apache.kafka.clients.Metadata:279)
[2022-12-04 23:05:28,432] INFO Created connector source-dbinfo (org.apache.kafka.connect.cli.ConnectStandalone:109)
[2022-12-04 23:05:28,432] INFO JdbcSourceTaskConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:postgresql://localhost:5432/kafka
	connection.user = postgres
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = SELECT * FROM stations;
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	tables = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = DBInfo
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceTaskConfig:372)
[2022-12-04 23:05:28,432] INFO Using JDBC dialect PostgreSql (io.confluent.connect.jdbc.source.JdbcSourceTask:127)
[2022-12-04 23:05:28,432] INFO Attempting to open connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:79)
[2022-12-04 23:05:28,436] INFO Maximum table name length for database is 63 bytes (io.confluent.connect.jdbc.dialect.PostgreSqlDatabaseDialect:130)
[2022-12-04 23:05:28,437] INFO Started JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:296)
[2022-12-04 23:05:28,437] INFO WorkerSourceTask{id=source-dbinfo-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:232)
[2022-12-04 23:05:28,438] INFO WorkerSourceTask{id=source-dbinfo-0} Executing source task (org.apache.kafka.connect.runtime.WorkerSourceTask:238)
[2022-12-04 23:05:28,445] INFO Begin using SQL query: SELECT * FROM stations; (io.confluent.connect.jdbc.source.TableQuerier:181)
[2022-12-04 23:05:31,383] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Successfully joined group with generation Generation{generationId=5, memberId='connector-consumer-sink-results-0-e173c28f-6abc-441f-a247-1ad46dc31f28', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2022-12-04 23:05:31,385] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Finished assignment for group at generation 5: {connector-consumer-sink-results-0-e173c28f-6abc-441f-a247-1ad46dc31f28=Assignment(partitions=[ResultsLocation-0, ResultsWeather-0, ResultsAlert-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:626)
[2022-12-04 23:05:31,389] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Successfully synced group in generation Generation{generationId=5, memberId='connector-consumer-sink-results-0-e173c28f-6abc-441f-a247-1ad46dc31f28', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:760)
[2022-12-04 23:05:31,390] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Notifying assignor about the new Assignment(partitions=[ResultsLocation-0, ResultsWeather-0, ResultsAlert-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:276)
[2022-12-04 23:05:31,391] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Adding newly assigned partitions: ResultsLocation-0, ResultsWeather-0, ResultsAlert-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:288)
[2022-12-04 23:05:31,396] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Found no committed offset for partition ResultsLocation-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1362)
[2022-12-04 23:05:31,396] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Found no committed offset for partition ResultsWeather-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1362)
[2022-12-04 23:05:31,396] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Found no committed offset for partition ResultsAlert-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1362)
[2022-12-04 23:05:31,400] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Resetting offset for partition ResultsLocation-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: r1)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-04 23:05:31,401] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Resetting offset for partition ResultsWeather-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: r1)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-04 23:05:31,401] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Resetting offset for partition ResultsAlert-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: r1)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-04 23:05:31,418] INFO Attempting to open connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:79)
[2022-12-04 23:05:31,424] INFO Maximum table name length for database is 63 bytes (io.confluent.connect.jdbc.dialect.PostgreSqlDatabaseDialect:130)
[2022-12-04 23:05:31,424] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2022-12-04 23:05:31,429] INFO Checking PostgreSql dialect for existence of TABLE "ResultsWeather" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:586)
[2022-12-04 23:05:31,431] INFO Using PostgreSql dialect TABLE "ResultsWeather" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:594)
[2022-12-04 23:05:31,436] INFO Checking PostgreSql dialect for type of TABLE "ResultsWeather" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:880)
[2022-12-04 23:05:31,437] INFO Setting metadata for table "ResultsWeather" to Table{name='"ResultsWeather"', type=TABLE columns=[Column{'count', isPrimaryKey=false, allowsNull=false, sqlType=int8}, Column{'station', isPrimaryKey=false, allowsNull=false, sqlType=text}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2022-12-04 23:05:31,437] ERROR WorkerSinkTask{id=sink-results-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted. Error: Write to table '"ResultsWeather"' in UPSERT mode requires key field names to be known, check the primary key configuration (org.apache.kafka.connect.runtime.WorkerSinkTask:608)
org.apache.kafka.connect.errors.ConnectException: Write to table '"ResultsWeather"' in UPSERT mode requires key field names to be known, check the primary key configuration
	at io.confluent.connect.jdbc.sink.BufferedRecords.getInsertSql(BufferedRecords.java:244)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:128)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:582)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:330)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:188)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1589)
[2022-12-04 23:05:31,438] ERROR WorkerSinkTask{id=sink-results-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:190)
org.apache.kafka.connect.errors.ConnectException: Exiting WorkerSinkTask due to unrecoverable exception.
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:610)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:330)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:188)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1589)
Caused by: org.apache.kafka.connect.errors.ConnectException: Write to table '"ResultsWeather"' in UPSERT mode requires key field names to be known, check the primary key configuration
	at io.confluent.connect.jdbc.sink.BufferedRecords.getInsertSql(BufferedRecords.java:244)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:128)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:582)
	... 10 more
[2022-12-04 23:05:31,439] INFO Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:161)
[2022-12-04 23:05:31,439] INFO Closing connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:105)
[2022-12-04 23:05:31,439] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Revoke previously assigned partitions ResultsLocation-0, ResultsWeather-0, ResultsAlert-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:307)
[2022-12-04 23:05:31,439] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Member connector-consumer-sink-results-0-e173c28f-6abc-441f-a247-1ad46dc31f28 sending LeaveGroup request to coordinator localhost:9092 (id: 2147483646 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:1045)
[2022-12-04 23:05:31,441] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-04 23:05:31,441] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-04 23:05:31,441] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-04 23:05:31,442] INFO App info kafka.consumer for connector-consumer-sink-results-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-04 23:05:38,432] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:05:48,438] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:05:58,440] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:06:08,441] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:06:09,701] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2022-12-04 23:06:09,701] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:327)
[2022-12-04 23:06:09,708] INFO Stopped http_8083@66d23e4a{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:381)
[2022-12-04 23:06:09,709] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:149)
[2022-12-04 23:06:09,710] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:344)
[2022-12-04 23:06:09,710] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:102)
[2022-12-04 23:06:09,711] INFO Stopping task source-dbinfo-0 (org.apache.kafka.connect.runtime.Worker:830)
[2022-12-04 23:06:13,488] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 7 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:06:13,494] INFO Stopping JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:354)
[2022-12-04 23:06:13,494] INFO Closing resources for JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:366)
[2022-12-04 23:06:13,494] INFO Closing connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:105)
[2022-12-04 23:06:13,495] INFO [Producer clientId=connector-producer-source-dbinfo-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1204)
[2022-12-04 23:06:13,498] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-04 23:06:13,498] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-04 23:06:13,499] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-04 23:06:13,499] INFO App info kafka.producer for connector-producer-source-dbinfo-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-04 23:06:13,501] INFO Stopping connector source-dbinfo (org.apache.kafka.connect.runtime.Worker:382)
[2022-12-04 23:06:13,501] INFO Scheduled shutdown for WorkerConnector{id=source-dbinfo} (org.apache.kafka.connect.runtime.WorkerConnector:248)
[2022-12-04 23:06:13,502] INFO Stopping table monitoring thread (io.confluent.connect.jdbc.JdbcSourceConnector:200)
[2022-12-04 23:06:13,502] INFO Shutting down thread monitoring tables. (io.confluent.connect.jdbc.source.TableMonitorThread:168)
[2022-12-04 23:06:13,502] INFO Closing connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:105)
[2022-12-04 23:06:13,502] INFO Completed shutdown for WorkerConnector{id=source-dbinfo} (org.apache.kafka.connect.runtime.WorkerConnector:268)
[2022-12-04 23:06:13,503] INFO Stopping task sink-results-0 (org.apache.kafka.connect.runtime.Worker:830)
[2022-12-04 23:06:13,504] INFO Stopping connector sink-results (org.apache.kafka.connect.runtime.Worker:382)
[2022-12-04 23:06:13,504] INFO Scheduled shutdown for WorkerConnector{id=sink-results} (org.apache.kafka.connect.runtime.WorkerConnector:248)
[2022-12-04 23:06:13,504] INFO Completed shutdown for WorkerConnector{id=sink-results} (org.apache.kafka.connect.runtime.WorkerConnector:268)
[2022-12-04 23:06:13,505] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:205)
[2022-12-04 23:06:13,505] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2022-12-04 23:06:13,506] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-04 23:06:13,506] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-04 23:06:13,506] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-04 23:06:13,506] INFO App info kafka.connect for 192.168.1.123:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-04 23:06:13,506] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:226)
[2022-12-04 23:06:13,507] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:120)
[2022-12-04 23:06:13,507] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2022-12-04 23:06:36,391] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:68)
[2022-12-04 23:06:36,395] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Private Build, OpenJDK 64-Bit Server VM, 19.0.1, 19.0.1+10-Ubuntu-1ubuntu122.04
	jvm.classpath = /home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/activation-1.1.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/argparse4j-0.7.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/audience-annotations-0.5.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/commons-cli-1.4.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/commons-lang3-3.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-api-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-basic-auth-extension-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-file-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-json-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-mirror-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-mirror-client-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-runtime-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-transforms-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/hk2-api-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/hk2-locator-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/hk2-utils-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-annotations-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-core-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-databind-2.10.5.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-module-paranamer-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.inject-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/javassist-3.27.0-GA.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/javax.servlet-api-3.1.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jaxb-api-2.3.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-client-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-common-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-container-servlet-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-hk2-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-server-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jline-3.12.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jopt-simple-5.0.4.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka_2.13-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka_2.13-2.8.1-sources.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-clients-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-connect-jdbc-10.6.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-log4j-appender-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-metadata-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-raft-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-shell-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-streams-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-streams-examples-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-streams-scala_2.13-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-streams-test-utils-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-tools-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/log4j-1.2.17.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/lz4-java-1.7.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/maven-artifact-3.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/metrics-core-2.2.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-buffer-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-codec-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-common-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-handler-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-resolver-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-transport-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-transport-native-epoll-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-transport-native-unix-common-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/paranamer-2.8.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/plexus-utils-3.2.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/postgresql-42.5.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/reflections-0.9.12.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/rocksdbjni-5.18.4.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-collection-compat_2.13-2.3.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-library-2.13.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-logging_2.13-3.9.2.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-reflect-2.13.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/slf4j-api-1.7.30.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/snappy-java-1.1.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/zookeeper-3.5.9.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/zookeeper-jute-3.5.9.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/zstd-jni-1.4.9-1.jar
	os.spec = Linux, amd64, 6.0.0-1006-oem
	os.vcpus = 20
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2022-12-04 23:06:36,396] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:77)
[2022-12-04 23:06:37,121] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@251a69d7 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:269)
[2022-12-04 23:06:37,121] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,121] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,121] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,122] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,122] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,122] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,122] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,122] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,122] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,123] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,123] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,123] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,123] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,123] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,123] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,124] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,124] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,124] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,124] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,124] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,124] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,125] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,125] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,125] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,125] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,125] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,125] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,125] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,125] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,125] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,125] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,125] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,125] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,125] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,126] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,126] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,126] INFO Added plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,126] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,126] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,126] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,126] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,126] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,126] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,126] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,126] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,126] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,126] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,126] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,126] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,126] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,126] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,127] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,127] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:06:37,129] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:06:37,129] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:06:37,129] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:06:37,129] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:06:37,130] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:06:37,130] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:06:37,130] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:06:37,130] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:06:37,130] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:06:37,130] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:06:37,130] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:06:37,130] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:06:37,130] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:06:37,130] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:06:37,130] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:06:37,131] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:06:37,131] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:06:37,131] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:06:37,131] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:06:37,131] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:06:37,131] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:06:37,131] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:06:37,131] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:06:37,131] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:06:37,131] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:06:37,131] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:06:37,131] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:06:37,131] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:06:37,131] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:06:37,131] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:06:37,131] INFO Added aliases 'PredicatedTransformation' and 'Predicated' to plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:06:37,131] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:06:37,131] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:06:37,132] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:06:37,132] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:06:37,132] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:06:37,132] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:06:37,132] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:06:37,132] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:06:37,132] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:06:37,132] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:06:37,132] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:06:37,141] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = null
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:372)
[2022-12-04 23:06:37,142] WARN Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results. (org.apache.kafka.connect.runtime.WorkerConfig:420)
[2022-12-04 23:06:37,142] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:49)
[2022-12-04 23:06:37,143] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2022-12-04 23:06:37,178] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:06:37,178] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:06:37,179] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:06:37,179] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:06:37,179] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:06:37,179] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:06:37,179] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:06:37,179] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:06:37,179] INFO Kafka startTimeMs: 1670195197179 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:06:37,303] INFO Kafka cluster ID: uYYJbbgfRseD3C81aqQl8w (org.apache.kafka.connect.util.ConnectUtils:65)
[2022-12-04 23:06:37,303] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-04 23:06:37,306] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-04 23:06:37,306] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-04 23:06:37,306] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-04 23:06:37,313] INFO Logging initialized @1135ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2022-12-04 23:06:37,329] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:132)
[2022-12-04 23:06:37,329] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:204)
[2022-12-04 23:06:37,332] INFO jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 19.0.1+10-Ubuntu-1ubuntu122.04 (org.eclipse.jetty.server.Server:375)
[2022-12-04 23:06:37,344] INFO Started http_8083@66d23e4a{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:331)
[2022-12-04 23:06:37,344] INFO Started @1167ms (org.eclipse.jetty.server.Server:415)
[2022-12-04 23:06:37,353] INFO Advertised URI: http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:371)
[2022-12-04 23:06:37,354] INFO REST server listening at http://192.168.1.123:8083/, advertising URL http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2022-12-04 23:06:37,354] INFO Advertised URI: http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:371)
[2022-12-04 23:06:37,354] INFO REST admin endpoints at http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:220)
[2022-12-04 23:06:37,354] INFO Advertised URI: http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:371)
[2022-12-04 23:06:37,355] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2022-12-04 23:06:37,359] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:49)
[2022-12-04 23:06:37,360] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2022-12-04 23:06:37,363] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:06:37,363] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:06:37,363] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:06:37,363] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:06:37,363] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:06:37,363] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:06:37,363] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:06:37,364] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:06:37,364] INFO Kafka startTimeMs: 1670195197363 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:06:37,370] INFO Kafka cluster ID: uYYJbbgfRseD3C81aqQl8w (org.apache.kafka.connect.util.ConnectUtils:65)
[2022-12-04 23:06:37,371] INFO App info kafka.admin.client for adminclient-2 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-04 23:06:37,373] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-04 23:06:37,373] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-04 23:06:37,373] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-04 23:06:37,376] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:06:37,376] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:06:37,376] INFO Kafka startTimeMs: 1670195197376 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:06:37,424] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-04 23:06:37,425] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-04 23:06:37,428] INFO Kafka Connect standalone worker initialization took 1036ms (org.apache.kafka.connect.cli.ConnectStandalone:99)
[2022-12-04 23:06:37,428] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2022-12-04 23:06:37,429] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:94)
[2022-12-04 23:06:37,429] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:191)
[2022-12-04 23:06:37,429] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2022-12-04 23:06:37,433] INFO Worker started (org.apache.kafka.connect.runtime.Worker:198)
[2022-12-04 23:06:37,433] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:97)
[2022-12-04 23:06:37,433] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:224)
[2022-12-04 23:06:37,449] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:241)
[2022-12-04 23:06:37,483] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2022-12-04 23:06:37,483] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2022-12-04 23:06:37,484] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session:132)
[2022-12-04 23:06:37,684] INFO Started o.e.j.s.ServletContextHandler@3be4f71{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:915)
[2022-12-04 23:06:37,684] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:319)
[2022-12-04 23:06:37,684] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2022-12-04 23:06:37,696] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2022-12-04 23:06:37,701] INFO Creating connector sink-results of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:271)
[2022-12-04 23:06:37,701] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2022-12-04 23:06:37,702] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:06:37,703] INFO Instantiated connector sink-results with version 10.6.0 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:281)
[2022-12-04 23:06:37,704] INFO Finished creating connector sink-results (org.apache.kafka.connect.runtime.Worker:306)
[2022-12-04 23:06:37,705] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2022-12-04 23:06:37,705] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:06:37,705] INFO Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:51)
[2022-12-04 23:06:37,706] INFO Creating task sink-results-0 (org.apache.kafka.connect.runtime.Worker:505)
[2022-12-04 23:06:37,707] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2022-12-04 23:06:37,707] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:06:37,707] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2022-12-04 23:06:37,707] INFO Instantiated task sink-results-0 with version 10.6.0 of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:520)
[2022-12-04 23:06:37,708] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:372)
[2022-12-04 23:06:37,708] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-04 23:06:37,708] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task sink-results-0 using the connector config (org.apache.kafka.connect.runtime.Worker:535)
[2022-12-04 23:06:37,708] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task sink-results-0 using the connector config (org.apache.kafka.connect.runtime.Worker:541)
[2022-12-04 23:06:37,708] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task sink-results-0 using the worker config (org.apache.kafka.connect.runtime.Worker:546)
[2022-12-04 23:06:37,709] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:626)
[2022-12-04 23:06:37,710] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2022-12-04 23:06:37,710] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:06:37,716] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-sink-results-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-sink-results
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2022-12-04 23:06:37,735] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-04 23:06:37,736] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:06:37,736] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:06:37,736] INFO Kafka startTimeMs: 1670195197736 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:06:37,741] INFO Created connector sink-results (org.apache.kafka.connect.cli.ConnectStandalone:109)
[2022-12-04 23:06:37,741] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Subscribed to topic(s): ResultsWeather, ResultsAlert, ResultsLocation (org.apache.kafka.clients.consumer.KafkaConsumer:965)
[2022-12-04 23:06:37,741] INFO Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:48)
[2022-12-04 23:06:37,741] INFO JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:postgresql://localhost:5432/kafka
	connection.user = postgres
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = upsert
	max.retries = 10
	pk.fields = [id]
	pk.mode = record_key
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:372)
[2022-12-04 23:06:37,742] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:postgresql://localhost:5432/kafka
	connection.user = postgres
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = SELECT * FROM stations;
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = DBInfo
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:372)
[2022-12-04 23:06:37,743] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2022-12-04 23:06:37,743] INFO Creating connector source-dbinfo of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:271)
[2022-12-04 23:06:37,743] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2022-12-04 23:06:37,743] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:06:37,744] INFO Initializing writer using SQL dialect: PostgreSqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2022-12-04 23:06:37,745] INFO Instantiated connector source-dbinfo with version 10.6.0 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:281)
[2022-12-04 23:06:37,745] INFO Finished creating connector source-dbinfo (org.apache.kafka.connect.runtime.Worker:306)
[2022-12-04 23:06:37,745] INFO Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:71)
[2022-12-04 23:06:37,745] INFO WorkerSinkTask{id=sink-results-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:310)
[2022-12-04 23:06:37,745] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:postgresql://localhost:5432/kafka
	connection.user = postgres
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = SELECT * FROM stations;
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = DBInfo
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:372)
[2022-12-04 23:06:37,745] INFO WorkerSinkTask{id=sink-results-0} Executing sink task (org.apache.kafka.connect.runtime.WorkerSinkTask:196)
[2022-12-04 23:06:37,746] INFO Attempting to open connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:79)
[2022-12-04 23:06:37,755] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Cluster ID: uYYJbbgfRseD3C81aqQl8w (org.apache.kafka.clients.Metadata:279)
[2022-12-04 23:06:37,755] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Discovered group coordinator localhost:9092 (id: 2147483646 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:850)
[2022-12-04 23:06:37,757] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2022-12-04 23:06:37,768] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2022-12-04 23:06:37,798] INFO Maximum table name length for database is 63 bytes (io.confluent.connect.jdbc.dialect.PostgreSqlDatabaseDialect:130)
[2022-12-04 23:06:37,799] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2022-12-04 23:06:37,800] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:06:37,800] INFO Creating task source-dbinfo-0 (org.apache.kafka.connect.runtime.Worker:505)
[2022-12-04 23:06:37,801] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2022-12-04 23:06:37,801] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:06:37,801] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.source.JdbcSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2022-12-04 23:06:37,801] INFO Instantiated task source-dbinfo-0 with version 10.6.0 of type io.confluent.connect.jdbc.source.JdbcSourceTask (org.apache.kafka.connect.runtime.Worker:520)
[2022-12-04 23:06:37,802] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-04 23:06:37,802] INFO Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task source-dbinfo-0 using the worker config (org.apache.kafka.connect.runtime.Worker:533)
[2022-12-04 23:06:37,802] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-04 23:06:37,802] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task source-dbinfo-0 using the worker config (org.apache.kafka.connect.runtime.Worker:539)
[2022-12-04 23:06:37,802] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task source-dbinfo-0 using the worker config (org.apache.kafka.connect.runtime.Worker:546)
[2022-12-04 23:06:37,802] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2022-12-04 23:06:37,802] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:06:37,802] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:600)
[2022-12-04 23:06:37,804] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-source-dbinfo-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2022-12-04 23:06:37,813] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-04 23:06:37,813] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:06:37,813] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:06:37,813] INFO Kafka startTimeMs: 1670195197813 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:06:37,815] INFO Starting JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:92)
[2022-12-04 23:06:37,815] INFO [Producer clientId=connector-producer-source-dbinfo-0] Cluster ID: uYYJbbgfRseD3C81aqQl8w (org.apache.kafka.clients.Metadata:279)
[2022-12-04 23:06:37,816] INFO Created connector source-dbinfo (org.apache.kafka.connect.cli.ConnectStandalone:109)
[2022-12-04 23:06:37,816] INFO JdbcSourceTaskConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:postgresql://localhost:5432/kafka
	connection.user = postgres
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = SELECT * FROM stations;
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	tables = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = DBInfo
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceTaskConfig:372)
[2022-12-04 23:06:37,816] INFO Using JDBC dialect PostgreSql (io.confluent.connect.jdbc.source.JdbcSourceTask:127)
[2022-12-04 23:06:37,816] INFO Attempting to open connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:79)
[2022-12-04 23:06:37,821] INFO Maximum table name length for database is 63 bytes (io.confluent.connect.jdbc.dialect.PostgreSqlDatabaseDialect:130)
[2022-12-04 23:06:37,822] INFO Started JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:296)
[2022-12-04 23:06:37,822] INFO WorkerSourceTask{id=source-dbinfo-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:232)
[2022-12-04 23:06:37,822] INFO WorkerSourceTask{id=source-dbinfo-0} Executing source task (org.apache.kafka.connect.runtime.WorkerSourceTask:238)
[2022-12-04 23:06:37,828] INFO Begin using SQL query: SELECT * FROM stations; (io.confluent.connect.jdbc.source.TableQuerier:181)
[2022-12-04 23:06:40,773] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Successfully joined group with generation Generation{generationId=7, memberId='connector-consumer-sink-results-0-e699e7a7-f7c7-43b4-822d-37c2f2687843', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2022-12-04 23:06:40,776] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Finished assignment for group at generation 7: {connector-consumer-sink-results-0-e699e7a7-f7c7-43b4-822d-37c2f2687843=Assignment(partitions=[ResultsLocation-0, ResultsWeather-0, ResultsAlert-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:626)
[2022-12-04 23:06:40,780] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Successfully synced group in generation Generation{generationId=7, memberId='connector-consumer-sink-results-0-e699e7a7-f7c7-43b4-822d-37c2f2687843', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:760)
[2022-12-04 23:06:40,781] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Notifying assignor about the new Assignment(partitions=[ResultsLocation-0, ResultsWeather-0, ResultsAlert-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:276)
[2022-12-04 23:06:40,782] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Adding newly assigned partitions: ResultsLocation-0, ResultsWeather-0, ResultsAlert-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:288)
[2022-12-04 23:06:40,787] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Found no committed offset for partition ResultsLocation-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1362)
[2022-12-04 23:06:40,787] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Found no committed offset for partition ResultsWeather-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1362)
[2022-12-04 23:06:40,787] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Found no committed offset for partition ResultsAlert-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1362)
[2022-12-04 23:06:40,792] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Resetting offset for partition ResultsLocation-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: r1)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-04 23:06:40,792] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Resetting offset for partition ResultsWeather-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: r1)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-04 23:06:40,792] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Resetting offset for partition ResultsAlert-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: r1)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-04 23:06:40,809] INFO Attempting to open connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:79)
[2022-12-04 23:06:40,814] INFO Maximum table name length for database is 63 bytes (io.confluent.connect.jdbc.dialect.PostgreSqlDatabaseDialect:130)
[2022-12-04 23:06:40,814] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2022-12-04 23:06:40,820] INFO Checking PostgreSql dialect for existence of TABLE "ResultsWeather" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:586)
[2022-12-04 23:06:40,822] INFO Using PostgreSql dialect TABLE "ResultsWeather" absent (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:594)
[2022-12-04 23:06:40,823] INFO Creating table with sql: CREATE TABLE "ResultsWeather" (
"station" TEXT NOT NULL,
"count" BIGINT NOT NULL,
"id" TEXT NOT NULL,
PRIMARY KEY("id")) (io.confluent.connect.jdbc.sink.DbStructure:122)
[2022-12-04 23:06:40,850] INFO Checking PostgreSql dialect for existence of TABLE "ResultsWeather" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:586)
[2022-12-04 23:06:40,851] INFO Using PostgreSql dialect TABLE "ResultsWeather" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:594)
[2022-12-04 23:06:40,858] INFO Checking PostgreSql dialect for type of TABLE "ResultsWeather" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:880)
[2022-12-04 23:06:40,860] INFO Setting metadata for table "ResultsWeather" to Table{name='"ResultsWeather"', type=TABLE columns=[Column{'count', isPrimaryKey=false, allowsNull=false, sqlType=int8}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=text}, Column{'station', isPrimaryKey=false, allowsNull=false, sqlType=text}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2022-12-04 23:06:40,870] WARN Write of 87 records failed, remainingRetries=10 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('LA',5675) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).  Call getNextException to see other errors in the batch.
	at org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2367)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:560)
	at org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:893)
	at org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:916)
	at org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1684)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:196)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:186)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:582)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:330)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:188)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1589)
Caused by: org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2676)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2366)
	... 19 more
[2022-12-04 23:06:40,871] INFO Closing connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:105)
[2022-12-04 23:06:40,871] INFO Initializing writer using SQL dialect: PostgreSqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2022-12-04 23:06:40,872] ERROR WorkerSinkTask{id=sink-results-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:601)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('LA',5675) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).  Call getNextException to see other errors in the batch.
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:582)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:330)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:188)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1589)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('LA',5675) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).  Call getNextException to see other errors in the batch.
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2022-12-04 23:06:43,873] INFO Attempting to open connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:79)
[2022-12-04 23:06:43,884] INFO Maximum table name length for database is 63 bytes (io.confluent.connect.jdbc.dialect.PostgreSqlDatabaseDialect:130)
[2022-12-04 23:06:43,884] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2022-12-04 23:06:43,893] INFO Checking PostgreSql dialect for existence of TABLE "ResultsWeather" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:586)
[2022-12-04 23:06:43,899] INFO Using PostgreSql dialect TABLE "ResultsWeather" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:594)
[2022-12-04 23:06:43,904] INFO Checking PostgreSql dialect for type of TABLE "ResultsWeather" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:880)
[2022-12-04 23:06:43,905] INFO Setting metadata for table "ResultsWeather" to Table{name='"ResultsWeather"', type=TABLE columns=[Column{'count', isPrimaryKey=false, allowsNull=false, sqlType=int8}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=text}, Column{'station', isPrimaryKey=false, allowsNull=false, sqlType=text}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2022-12-04 23:06:43,909] WARN Write of 87 records failed, remainingRetries=9 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('LA',5675) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).  Call getNextException to see other errors in the batch.
	at org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2367)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:560)
	at org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:893)
	at org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:916)
	at org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1684)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:196)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:186)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:582)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:330)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:188)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1589)
Caused by: org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2676)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2366)
	... 19 more
[2022-12-04 23:06:43,909] INFO Closing connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:105)
[2022-12-04 23:06:43,909] INFO Initializing writer using SQL dialect: PostgreSqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2022-12-04 23:06:43,909] ERROR WorkerSinkTask{id=sink-results-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:601)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('LA',5675) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).  Call getNextException to see other errors in the batch.
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:582)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:330)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:188)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1589)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('LA',5675) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).  Call getNextException to see other errors in the batch.
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2022-12-04 23:06:46,910] INFO Attempting to open connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:79)
[2022-12-04 23:06:46,922] INFO Maximum table name length for database is 63 bytes (io.confluent.connect.jdbc.dialect.PostgreSqlDatabaseDialect:130)
[2022-12-04 23:06:46,922] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2022-12-04 23:06:46,930] INFO Checking PostgreSql dialect for existence of TABLE "ResultsWeather" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:586)
[2022-12-04 23:06:46,934] INFO Using PostgreSql dialect TABLE "ResultsWeather" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:594)
[2022-12-04 23:06:46,941] INFO Checking PostgreSql dialect for type of TABLE "ResultsWeather" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:880)
[2022-12-04 23:06:46,943] INFO Setting metadata for table "ResultsWeather" to Table{name='"ResultsWeather"', type=TABLE columns=[Column{'count', isPrimaryKey=false, allowsNull=false, sqlType=int8}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=text}, Column{'station', isPrimaryKey=false, allowsNull=false, sqlType=text}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2022-12-04 23:06:46,947] WARN Write of 87 records failed, remainingRetries=8 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('LA',5675) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).  Call getNextException to see other errors in the batch.
	at org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2367)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:560)
	at org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:893)
	at org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:916)
	at org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1684)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:196)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:186)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:582)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:330)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:188)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1589)
Caused by: org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2676)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2366)
	... 19 more
[2022-12-04 23:06:46,948] INFO Closing connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:105)
[2022-12-04 23:06:46,948] INFO Initializing writer using SQL dialect: PostgreSqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2022-12-04 23:06:46,948] ERROR WorkerSinkTask{id=sink-results-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:601)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('LA',5675) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).  Call getNextException to see other errors in the batch.
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:582)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:330)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:188)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1589)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('LA',5675) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).  Call getNextException to see other errors in the batch.
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2022-12-04 23:06:47,741] INFO Attempting to open connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:79)
[2022-12-04 23:06:47,751] INFO Maximum table name length for database is 63 bytes (io.confluent.connect.jdbc.dialect.PostgreSqlDatabaseDialect:130)
[2022-12-04 23:06:47,751] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2022-12-04 23:06:47,758] INFO Checking PostgreSql dialect for existence of TABLE "ResultsWeather" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:586)
[2022-12-04 23:06:47,761] INFO Using PostgreSql dialect TABLE "ResultsWeather" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:594)
[2022-12-04 23:06:47,767] INFO Checking PostgreSql dialect for type of TABLE "ResultsWeather" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:880)
[2022-12-04 23:06:47,769] INFO Setting metadata for table "ResultsWeather" to Table{name='"ResultsWeather"', type=TABLE columns=[Column{'count', isPrimaryKey=false, allowsNull=false, sqlType=int8}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=text}, Column{'station', isPrimaryKey=false, allowsNull=false, sqlType=text}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2022-12-04 23:06:47,774] WARN Write of 87 records failed, remainingRetries=7 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('LA',5675) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).  Call getNextException to see other errors in the batch.
	at org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2367)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:560)
	at org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:893)
	at org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:916)
	at org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1684)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:196)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:186)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:582)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:330)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:188)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1589)
Caused by: org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2676)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2366)
	... 19 more
[2022-12-04 23:06:47,774] INFO Closing connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:105)
[2022-12-04 23:06:47,774] INFO Initializing writer using SQL dialect: PostgreSqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2022-12-04 23:06:47,774] ERROR WorkerSinkTask{id=sink-results-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:601)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('LA',5675) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).  Call getNextException to see other errors in the batch.
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:582)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:330)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:188)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1589)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('LA',5675) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).  Call getNextException to see other errors in the batch.
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2022-12-04 23:06:47,817] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:06:50,777] INFO Attempting to open connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:79)
[2022-12-04 23:06:50,788] INFO Maximum table name length for database is 63 bytes (io.confluent.connect.jdbc.dialect.PostgreSqlDatabaseDialect:130)
[2022-12-04 23:06:50,788] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2022-12-04 23:06:50,796] INFO Checking PostgreSql dialect for existence of TABLE "ResultsWeather" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:586)
[2022-12-04 23:06:50,800] INFO Using PostgreSql dialect TABLE "ResultsWeather" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:594)
[2022-12-04 23:06:50,805] INFO Checking PostgreSql dialect for type of TABLE "ResultsWeather" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:880)
[2022-12-04 23:06:50,806] INFO Setting metadata for table "ResultsWeather" to Table{name='"ResultsWeather"', type=TABLE columns=[Column{'count', isPrimaryKey=false, allowsNull=false, sqlType=int8}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=text}, Column{'station', isPrimaryKey=false, allowsNull=false, sqlType=text}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2022-12-04 23:06:50,809] WARN Write of 87 records failed, remainingRetries=6 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('LA',5675) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).  Call getNextException to see other errors in the batch.
	at org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2367)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:560)
	at org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:893)
	at org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:916)
	at org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1684)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:196)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:186)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:582)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:330)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:188)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1589)
Caused by: org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2676)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2366)
	... 19 more
[2022-12-04 23:06:50,809] INFO Closing connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:105)
[2022-12-04 23:06:50,809] INFO Initializing writer using SQL dialect: PostgreSqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2022-12-04 23:06:50,809] ERROR WorkerSinkTask{id=sink-results-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:601)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('LA',5675) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).  Call getNextException to see other errors in the batch.
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:582)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:330)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:188)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1589)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('LA',5675) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).  Call getNextException to see other errors in the batch.
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2022-12-04 23:06:51,573] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2022-12-04 23:06:51,574] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:327)
[2022-12-04 23:06:51,581] INFO Stopped http_8083@66d23e4a{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:381)
[2022-12-04 23:06:51,582] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:149)
[2022-12-04 23:06:51,584] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:344)
[2022-12-04 23:06:51,584] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:102)
[2022-12-04 23:06:51,584] INFO Stopping task source-dbinfo-0 (org.apache.kafka.connect.runtime.Worker:830)
[2022-12-04 23:06:52,850] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 7 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:06:52,855] INFO Stopping JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:354)
[2022-12-04 23:06:52,855] INFO Closing resources for JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:366)
[2022-12-04 23:06:52,856] INFO Closing connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:105)
[2022-12-04 23:06:52,856] INFO [Producer clientId=connector-producer-source-dbinfo-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1204)
[2022-12-04 23:06:52,857] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-04 23:06:52,857] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-04 23:06:52,858] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-04 23:06:52,858] INFO App info kafka.producer for connector-producer-source-dbinfo-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-04 23:06:52,860] INFO Stopping connector source-dbinfo (org.apache.kafka.connect.runtime.Worker:382)
[2022-12-04 23:06:52,860] INFO Scheduled shutdown for WorkerConnector{id=source-dbinfo} (org.apache.kafka.connect.runtime.WorkerConnector:248)
[2022-12-04 23:06:52,860] INFO Stopping table monitoring thread (io.confluent.connect.jdbc.JdbcSourceConnector:200)
[2022-12-04 23:06:52,860] INFO Shutting down thread monitoring tables. (io.confluent.connect.jdbc.source.TableMonitorThread:168)
[2022-12-04 23:06:52,860] INFO Closing connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:105)
[2022-12-04 23:06:52,861] INFO Completed shutdown for WorkerConnector{id=source-dbinfo} (org.apache.kafka.connect.runtime.WorkerConnector:268)
[2022-12-04 23:06:52,861] INFO Stopping task sink-results-0 (org.apache.kafka.connect.runtime.Worker:830)
[2022-12-04 23:06:52,862] INFO Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:161)
[2022-12-04 23:06:52,862] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Revoke previously assigned partitions ResultsLocation-0, ResultsWeather-0, ResultsAlert-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:307)
[2022-12-04 23:06:52,863] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Member connector-consumer-sink-results-0-e699e7a7-f7c7-43b4-822d-37c2f2687843 sending LeaveGroup request to coordinator localhost:9092 (id: 2147483646 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:1045)
[2022-12-04 23:06:52,868] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-04 23:06:52,868] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-04 23:06:52,868] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-04 23:06:52,870] INFO App info kafka.consumer for connector-consumer-sink-results-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-04 23:06:52,873] INFO Stopping connector sink-results (org.apache.kafka.connect.runtime.Worker:382)
[2022-12-04 23:06:52,874] INFO Scheduled shutdown for WorkerConnector{id=sink-results} (org.apache.kafka.connect.runtime.WorkerConnector:248)
[2022-12-04 23:06:52,874] INFO Completed shutdown for WorkerConnector{id=sink-results} (org.apache.kafka.connect.runtime.WorkerConnector:268)
[2022-12-04 23:06:52,875] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:205)
[2022-12-04 23:06:52,877] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2022-12-04 23:06:52,877] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-04 23:06:52,878] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-04 23:06:52,878] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-04 23:06:52,879] INFO App info kafka.connect for 192.168.1.123:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-04 23:06:52,879] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:226)
[2022-12-04 23:06:52,881] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:120)
[2022-12-04 23:06:52,882] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2022-12-04 23:07:25,793] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:68)
[2022-12-04 23:07:25,797] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Private Build, OpenJDK 64-Bit Server VM, 19.0.1, 19.0.1+10-Ubuntu-1ubuntu122.04
	jvm.classpath = /home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/activation-1.1.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/argparse4j-0.7.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/audience-annotations-0.5.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/commons-cli-1.4.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/commons-lang3-3.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-api-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-basic-auth-extension-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-file-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-json-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-mirror-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-mirror-client-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-runtime-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-transforms-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/hk2-api-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/hk2-locator-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/hk2-utils-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-annotations-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-core-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-databind-2.10.5.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-module-paranamer-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.inject-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/javassist-3.27.0-GA.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/javax.servlet-api-3.1.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jaxb-api-2.3.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-client-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-common-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-container-servlet-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-hk2-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-server-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jline-3.12.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jopt-simple-5.0.4.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka_2.13-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka_2.13-2.8.1-sources.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-clients-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-connect-jdbc-10.6.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-log4j-appender-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-metadata-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-raft-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-shell-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-streams-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-streams-examples-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-streams-scala_2.13-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-streams-test-utils-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-tools-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/log4j-1.2.17.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/lz4-java-1.7.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/maven-artifact-3.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/metrics-core-2.2.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-buffer-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-codec-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-common-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-handler-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-resolver-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-transport-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-transport-native-epoll-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-transport-native-unix-common-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/paranamer-2.8.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/plexus-utils-3.2.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/postgresql-42.5.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/reflections-0.9.12.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/rocksdbjni-5.18.4.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-collection-compat_2.13-2.3.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-library-2.13.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-logging_2.13-3.9.2.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-reflect-2.13.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/slf4j-api-1.7.30.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/snappy-java-1.1.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/zookeeper-3.5.9.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/zookeeper-jute-3.5.9.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/zstd-jni-1.4.9-1.jar
	os.spec = Linux, amd64, 6.0.0-1006-oem
	os.vcpus = 20
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2022-12-04 23:07:25,798] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:77)
[2022-12-04 23:07:26,583] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@251a69d7 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:269)
[2022-12-04 23:07:26,584] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,584] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,584] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,584] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,584] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,584] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,584] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,584] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,584] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,584] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,584] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,584] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,585] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,585] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,585] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,585] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,585] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,585] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,585] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,586] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,586] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,586] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,586] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,586] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,587] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,587] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,587] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,587] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,587] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,587] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,587] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,588] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,588] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,588] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,588] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,588] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,588] INFO Added plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,588] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,588] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,588] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,589] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,589] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,589] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,589] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,589] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,589] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,589] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,589] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,590] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,590] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,590] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,590] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,590] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:07:26,592] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:07:26,592] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:07:26,592] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:07:26,592] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:07:26,592] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:07:26,592] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:07:26,593] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:07:26,593] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:07:26,593] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:07:26,593] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:07:26,593] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:07:26,593] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:07:26,593] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:07:26,593] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:07:26,593] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:07:26,593] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:07:26,593] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:07:26,593] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:07:26,593] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:07:26,594] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:07:26,594] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:07:26,594] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:07:26,594] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:07:26,594] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:07:26,594] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:07:26,594] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:07:26,594] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:07:26,594] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:07:26,594] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:07:26,594] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:07:26,594] INFO Added aliases 'PredicatedTransformation' and 'Predicated' to plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:07:26,594] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:07:26,594] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:07:26,594] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:07:26,594] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:07:26,594] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:07:26,594] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:07:26,595] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:07:26,595] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:07:26,595] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:07:26,595] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:07:26,595] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:07:26,604] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = null
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:372)
[2022-12-04 23:07:26,604] WARN Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results. (org.apache.kafka.connect.runtime.WorkerConfig:420)
[2022-12-04 23:07:26,604] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:49)
[2022-12-04 23:07:26,606] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2022-12-04 23:07:26,640] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:07:26,640] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:07:26,640] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:07:26,640] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:07:26,640] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:07:26,640] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:07:26,640] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:07:26,640] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:07:26,640] INFO Kafka startTimeMs: 1670195246640 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:07:26,760] INFO Kafka cluster ID: uYYJbbgfRseD3C81aqQl8w (org.apache.kafka.connect.util.ConnectUtils:65)
[2022-12-04 23:07:26,760] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-04 23:07:26,763] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-04 23:07:26,763] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-04 23:07:26,763] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-04 23:07:26,769] INFO Logging initialized @1178ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2022-12-04 23:07:26,784] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:132)
[2022-12-04 23:07:26,784] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:204)
[2022-12-04 23:07:26,787] INFO jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 19.0.1+10-Ubuntu-1ubuntu122.04 (org.eclipse.jetty.server.Server:375)
[2022-12-04 23:07:26,799] INFO Started http_8083@66d23e4a{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:331)
[2022-12-04 23:07:26,799] INFO Started @1208ms (org.eclipse.jetty.server.Server:415)
[2022-12-04 23:07:26,808] INFO Advertised URI: http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:371)
[2022-12-04 23:07:26,809] INFO REST server listening at http://192.168.1.123:8083/, advertising URL http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2022-12-04 23:07:26,809] INFO Advertised URI: http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:371)
[2022-12-04 23:07:26,809] INFO REST admin endpoints at http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:220)
[2022-12-04 23:07:26,810] INFO Advertised URI: http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:371)
[2022-12-04 23:07:26,813] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2022-12-04 23:07:26,816] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:49)
[2022-12-04 23:07:26,817] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2022-12-04 23:07:26,819] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:07:26,819] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:07:26,819] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:07:26,819] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:07:26,819] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:07:26,819] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:07:26,819] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:07:26,819] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:07:26,819] INFO Kafka startTimeMs: 1670195246819 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:07:26,826] INFO Kafka cluster ID: uYYJbbgfRseD3C81aqQl8w (org.apache.kafka.connect.util.ConnectUtils:65)
[2022-12-04 23:07:26,827] INFO App info kafka.admin.client for adminclient-2 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-04 23:07:26,828] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-04 23:07:26,828] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-04 23:07:26,829] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-04 23:07:26,831] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:07:26,831] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:07:26,831] INFO Kafka startTimeMs: 1670195246831 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:07:26,876] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-04 23:07:26,877] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-04 23:07:26,880] INFO Kafka Connect standalone worker initialization took 1086ms (org.apache.kafka.connect.cli.ConnectStandalone:99)
[2022-12-04 23:07:26,880] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2022-12-04 23:07:26,881] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:94)
[2022-12-04 23:07:26,881] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:191)
[2022-12-04 23:07:26,881] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2022-12-04 23:07:26,886] INFO Worker started (org.apache.kafka.connect.runtime.Worker:198)
[2022-12-04 23:07:26,886] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:97)
[2022-12-04 23:07:26,886] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:224)
[2022-12-04 23:07:26,903] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:241)
[2022-12-04 23:07:26,941] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2022-12-04 23:07:26,942] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2022-12-04 23:07:26,942] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session:132)
[2022-12-04 23:07:27,126] INFO Started o.e.j.s.ServletContextHandler@3be4f71{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:915)
[2022-12-04 23:07:27,127] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:319)
[2022-12-04 23:07:27,127] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2022-12-04 23:07:27,141] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2022-12-04 23:07:27,144] ERROR Failed to create job for config/sink-results.properties (org.apache.kafka.connect.cli.ConnectStandalone:107)
[2022-12-04 23:07:27,144] ERROR Stopping after connector error (org.apache.kafka.connect.cli.ConnectStandalone:117)
java.util.concurrent.ExecutionException: org.apache.kafka.connect.runtime.rest.errors.BadRequestException: Connector configuration is invalid and contains the following 1 error(s):
Invalid value id for configuration pk.mode: Invalid enumerator
You can also find the above list of errors at the endpoint `/connector-plugins/{connectorType}/config/validate`
	at org.apache.kafka.connect.util.ConvertingFutureCallback.result(ConvertingFutureCallback.java:115)
	at org.apache.kafka.connect.util.ConvertingFutureCallback.get(ConvertingFutureCallback.java:99)
	at org.apache.kafka.connect.cli.ConnectStandalone.main(ConnectStandalone.java:114)
Caused by: org.apache.kafka.connect.runtime.rest.errors.BadRequestException: Connector configuration is invalid and contains the following 1 error(s):
Invalid value id for configuration pk.mode: Invalid enumerator
You can also find the above list of errors at the endpoint `/connector-plugins/{connectorType}/config/validate`
	at org.apache.kafka.connect.runtime.AbstractHerder.maybeAddConfigErrors(AbstractHerder.java:638)
	at org.apache.kafka.connect.runtime.standalone.StandaloneHerder.putConnectorConfig(StandaloneHerder.java:203)
	at org.apache.kafka.connect.runtime.standalone.StandaloneHerder.lambda$null$0(StandaloneHerder.java:189)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1589)
[2022-12-04 23:07:27,146] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2022-12-04 23:07:27,146] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:327)
[2022-12-04 23:07:27,149] INFO Stopped http_8083@66d23e4a{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:381)
[2022-12-04 23:07:27,149] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:149)
[2022-12-04 23:07:27,150] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:344)
[2022-12-04 23:07:27,150] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:102)
[2022-12-04 23:07:27,150] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:205)
[2022-12-04 23:07:27,151] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2022-12-04 23:07:27,151] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-04 23:07:27,151] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-04 23:07:27,151] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-04 23:07:27,151] INFO App info kafka.connect for 192.168.1.123:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-04 23:07:27,151] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:226)
[2022-12-04 23:07:27,151] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:120)
[2022-12-04 23:07:27,152] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2022-12-04 23:08:05,062] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:68)
[2022-12-04 23:08:05,066] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Private Build, OpenJDK 64-Bit Server VM, 19.0.1, 19.0.1+10-Ubuntu-1ubuntu122.04
	jvm.classpath = /home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/activation-1.1.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/argparse4j-0.7.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/audience-annotations-0.5.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/commons-cli-1.4.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/commons-lang3-3.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-api-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-basic-auth-extension-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-file-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-json-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-mirror-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-mirror-client-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-runtime-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-transforms-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/hk2-api-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/hk2-locator-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/hk2-utils-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-annotations-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-core-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-databind-2.10.5.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-module-paranamer-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.inject-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/javassist-3.27.0-GA.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/javax.servlet-api-3.1.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jaxb-api-2.3.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-client-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-common-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-container-servlet-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-hk2-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-server-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jline-3.12.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jopt-simple-5.0.4.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka_2.13-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka_2.13-2.8.1-sources.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-clients-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-connect-jdbc-10.6.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-log4j-appender-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-metadata-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-raft-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-shell-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-streams-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-streams-examples-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-streams-scala_2.13-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-streams-test-utils-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-tools-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/log4j-1.2.17.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/lz4-java-1.7.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/maven-artifact-3.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/metrics-core-2.2.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-buffer-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-codec-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-common-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-handler-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-resolver-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-transport-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-transport-native-epoll-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-transport-native-unix-common-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/paranamer-2.8.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/plexus-utils-3.2.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/postgresql-42.5.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/reflections-0.9.12.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/rocksdbjni-5.18.4.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-collection-compat_2.13-2.3.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-library-2.13.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-logging_2.13-3.9.2.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-reflect-2.13.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/slf4j-api-1.7.30.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/snappy-java-1.1.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/zookeeper-3.5.9.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/zookeeper-jute-3.5.9.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/zstd-jni-1.4.9-1.jar
	os.spec = Linux, amd64, 6.0.0-1006-oem
	os.vcpus = 20
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2022-12-04 23:08:05,067] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:77)
[2022-12-04 23:08:05,806] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@251a69d7 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:269)
[2022-12-04 23:08:05,806] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,806] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,806] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,807] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,807] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,807] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,807] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,807] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,807] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,807] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,807] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,807] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,807] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,807] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,807] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,807] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,808] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,808] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,808] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,808] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,808] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,808] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,808] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,808] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,809] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,809] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,809] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,809] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,809] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,809] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,809] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,809] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,809] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,809] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,809] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,809] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,809] INFO Added plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,809] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,810] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,810] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,810] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,810] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,810] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,810] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,810] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,810] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,810] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,810] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,810] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,810] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,810] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,810] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,810] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:05,813] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:05,813] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:05,813] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:05,813] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:05,813] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:05,813] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:05,813] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:05,813] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:05,813] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:05,814] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:05,814] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:05,814] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:05,814] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:05,814] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:05,814] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:05,814] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:05,814] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:05,814] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:05,814] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:05,814] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:05,814] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:05,814] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:05,814] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:05,814] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:05,814] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:05,814] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:05,815] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:05,815] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:05,815] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:08:05,815] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:05,815] INFO Added aliases 'PredicatedTransformation' and 'Predicated' to plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:05,815] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:08:05,815] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:08:05,815] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:08:05,815] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:08:05,815] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:08:05,815] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:08:05,815] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:08:05,815] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:08:05,815] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:05,815] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:05,815] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:05,824] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = null
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:372)
[2022-12-04 23:08:05,824] WARN Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results. (org.apache.kafka.connect.runtime.WorkerConfig:420)
[2022-12-04 23:08:05,825] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:49)
[2022-12-04 23:08:05,826] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2022-12-04 23:08:05,860] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:08:05,860] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:08:05,860] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:08:05,860] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:08:05,860] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:08:05,860] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:08:05,860] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:08:05,860] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:08:05,860] INFO Kafka startTimeMs: 1670195285860 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:08:05,974] INFO Kafka cluster ID: uYYJbbgfRseD3C81aqQl8w (org.apache.kafka.connect.util.ConnectUtils:65)
[2022-12-04 23:08:05,975] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-04 23:08:05,977] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-04 23:08:05,977] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-04 23:08:05,977] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-04 23:08:05,983] INFO Logging initialized @1134ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2022-12-04 23:08:05,998] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:132)
[2022-12-04 23:08:05,998] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:204)
[2022-12-04 23:08:06,000] INFO jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 19.0.1+10-Ubuntu-1ubuntu122.04 (org.eclipse.jetty.server.Server:375)
[2022-12-04 23:08:06,013] INFO Started http_8083@66d23e4a{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:331)
[2022-12-04 23:08:06,013] INFO Started @1164ms (org.eclipse.jetty.server.Server:415)
[2022-12-04 23:08:06,023] INFO Advertised URI: http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:371)
[2022-12-04 23:08:06,023] INFO REST server listening at http://192.168.1.123:8083/, advertising URL http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2022-12-04 23:08:06,023] INFO Advertised URI: http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:371)
[2022-12-04 23:08:06,023] INFO REST admin endpoints at http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:220)
[2022-12-04 23:08:06,024] INFO Advertised URI: http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:371)
[2022-12-04 23:08:06,025] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2022-12-04 23:08:06,028] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:49)
[2022-12-04 23:08:06,029] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2022-12-04 23:08:06,031] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:08:06,031] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:08:06,031] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:08:06,031] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:08:06,031] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:08:06,031] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:08:06,031] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:08:06,031] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:08:06,031] INFO Kafka startTimeMs: 1670195286031 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:08:06,037] INFO Kafka cluster ID: uYYJbbgfRseD3C81aqQl8w (org.apache.kafka.connect.util.ConnectUtils:65)
[2022-12-04 23:08:06,038] INFO App info kafka.admin.client for adminclient-2 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-04 23:08:06,039] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-04 23:08:06,039] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-04 23:08:06,039] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-04 23:08:06,041] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:08:06,042] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:08:06,042] INFO Kafka startTimeMs: 1670195286041 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:08:06,087] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-04 23:08:06,088] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-04 23:08:06,091] INFO Kafka Connect standalone worker initialization took 1027ms (org.apache.kafka.connect.cli.ConnectStandalone:99)
[2022-12-04 23:08:06,091] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2022-12-04 23:08:06,091] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:94)
[2022-12-04 23:08:06,091] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:191)
[2022-12-04 23:08:06,092] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2022-12-04 23:08:06,095] INFO Worker started (org.apache.kafka.connect.runtime.Worker:198)
[2022-12-04 23:08:06,095] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:97)
[2022-12-04 23:08:06,095] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:224)
[2022-12-04 23:08:06,116] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:241)
[2022-12-04 23:08:06,148] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2022-12-04 23:08:06,148] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2022-12-04 23:08:06,148] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session:132)
[2022-12-04 23:08:06,324] INFO Started o.e.j.s.ServletContextHandler@3be4f71{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:915)
[2022-12-04 23:08:06,324] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:319)
[2022-12-04 23:08:06,324] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2022-12-04 23:08:06,338] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2022-12-04 23:08:06,343] INFO Creating connector sink-results of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:271)
[2022-12-04 23:08:06,343] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2022-12-04 23:08:06,343] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:08:06,345] INFO Instantiated connector sink-results with version 10.6.0 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:281)
[2022-12-04 23:08:06,345] INFO Finished creating connector sink-results (org.apache.kafka.connect.runtime.Worker:306)
[2022-12-04 23:08:06,347] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2022-12-04 23:08:06,347] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:08:06,347] INFO Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:51)
[2022-12-04 23:08:06,348] INFO Creating task sink-results-0 (org.apache.kafka.connect.runtime.Worker:505)
[2022-12-04 23:08:06,348] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2022-12-04 23:08:06,349] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:08:06,349] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2022-12-04 23:08:06,349] INFO Instantiated task sink-results-0 with version 10.6.0 of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:520)
[2022-12-04 23:08:06,350] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:372)
[2022-12-04 23:08:06,350] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-04 23:08:06,350] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task sink-results-0 using the connector config (org.apache.kafka.connect.runtime.Worker:535)
[2022-12-04 23:08:06,350] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task sink-results-0 using the connector config (org.apache.kafka.connect.runtime.Worker:541)
[2022-12-04 23:08:06,350] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task sink-results-0 using the worker config (org.apache.kafka.connect.runtime.Worker:546)
[2022-12-04 23:08:06,351] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:626)
[2022-12-04 23:08:06,352] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2022-12-04 23:08:06,352] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:08:06,355] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-sink-results-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-sink-results
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2022-12-04 23:08:06,371] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-04 23:08:06,371] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:08:06,372] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:08:06,372] INFO Kafka startTimeMs: 1670195286371 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:08:06,376] INFO Created connector sink-results (org.apache.kafka.connect.cli.ConnectStandalone:109)
[2022-12-04 23:08:06,377] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Subscribed to topic(s): ResultsWeather, ResultsAlert, ResultsLocation (org.apache.kafka.clients.consumer.KafkaConsumer:965)
[2022-12-04 23:08:06,377] INFO Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:48)
[2022-12-04 23:08:06,377] INFO JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:postgresql://localhost:5432/kafka
	connection.user = postgres
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = upsert
	max.retries = 10
	pk.fields = [id]
	pk.mode = none
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:372)
[2022-12-04 23:08:06,378] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:postgresql://localhost:5432/kafka
	connection.user = postgres
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = SELECT * FROM stations;
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = DBInfo
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:372)
[2022-12-04 23:08:06,378] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2022-12-04 23:08:06,379] INFO Creating connector source-dbinfo of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:271)
[2022-12-04 23:08:06,379] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2022-12-04 23:08:06,379] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:08:06,380] INFO Initializing writer using SQL dialect: PostgreSqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2022-12-04 23:08:06,380] INFO Instantiated connector source-dbinfo with version 10.6.0 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:281)
[2022-12-04 23:08:06,380] INFO Finished creating connector source-dbinfo (org.apache.kafka.connect.runtime.Worker:306)
[2022-12-04 23:08:06,380] INFO WorkerSinkTask{id=sink-results-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:310)
[2022-12-04 23:08:06,380] INFO WorkerSinkTask{id=sink-results-0} Executing sink task (org.apache.kafka.connect.runtime.WorkerSinkTask:196)
[2022-12-04 23:08:06,380] INFO Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:71)
[2022-12-04 23:08:06,381] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:postgresql://localhost:5432/kafka
	connection.user = postgres
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = SELECT * FROM stations;
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = DBInfo
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:372)
[2022-12-04 23:08:06,381] INFO Attempting to open connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:79)
[2022-12-04 23:08:06,387] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Cluster ID: uYYJbbgfRseD3C81aqQl8w (org.apache.kafka.clients.Metadata:279)
[2022-12-04 23:08:06,387] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Discovered group coordinator localhost:9092 (id: 2147483646 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:850)
[2022-12-04 23:08:06,388] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2022-12-04 23:08:06,401] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2022-12-04 23:08:06,436] INFO Maximum table name length for database is 63 bytes (io.confluent.connect.jdbc.dialect.PostgreSqlDatabaseDialect:130)
[2022-12-04 23:08:06,437] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2022-12-04 23:08:06,437] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:08:06,438] INFO Creating task source-dbinfo-0 (org.apache.kafka.connect.runtime.Worker:505)
[2022-12-04 23:08:06,438] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2022-12-04 23:08:06,438] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:08:06,439] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.source.JdbcSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2022-12-04 23:08:06,439] INFO Instantiated task source-dbinfo-0 with version 10.6.0 of type io.confluent.connect.jdbc.source.JdbcSourceTask (org.apache.kafka.connect.runtime.Worker:520)
[2022-12-04 23:08:06,439] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-04 23:08:06,439] INFO Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task source-dbinfo-0 using the worker config (org.apache.kafka.connect.runtime.Worker:533)
[2022-12-04 23:08:06,439] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-04 23:08:06,439] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task source-dbinfo-0 using the worker config (org.apache.kafka.connect.runtime.Worker:539)
[2022-12-04 23:08:06,439] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task source-dbinfo-0 using the worker config (org.apache.kafka.connect.runtime.Worker:546)
[2022-12-04 23:08:06,440] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2022-12-04 23:08:06,440] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:08:06,440] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:600)
[2022-12-04 23:08:06,442] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-source-dbinfo-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2022-12-04 23:08:06,448] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-04 23:08:06,448] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:08:06,448] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:08:06,448] INFO Kafka startTimeMs: 1670195286448 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:08:06,450] INFO [Producer clientId=connector-producer-source-dbinfo-0] Cluster ID: uYYJbbgfRseD3C81aqQl8w (org.apache.kafka.clients.Metadata:279)
[2022-12-04 23:08:06,450] INFO Starting JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:92)
[2022-12-04 23:08:06,450] INFO Created connector source-dbinfo (org.apache.kafka.connect.cli.ConnectStandalone:109)
[2022-12-04 23:08:06,450] INFO JdbcSourceTaskConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:postgresql://localhost:5432/kafka
	connection.user = postgres
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = SELECT * FROM stations;
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	tables = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = DBInfo
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceTaskConfig:372)
[2022-12-04 23:08:06,450] INFO Using JDBC dialect PostgreSql (io.confluent.connect.jdbc.source.JdbcSourceTask:127)
[2022-12-04 23:08:06,451] INFO Attempting to open connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:79)
[2022-12-04 23:08:06,455] INFO Maximum table name length for database is 63 bytes (io.confluent.connect.jdbc.dialect.PostgreSqlDatabaseDialect:130)
[2022-12-04 23:08:06,457] INFO Started JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:296)
[2022-12-04 23:08:06,457] INFO WorkerSourceTask{id=source-dbinfo-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:232)
[2022-12-04 23:08:06,457] INFO WorkerSourceTask{id=source-dbinfo-0} Executing source task (org.apache.kafka.connect.runtime.WorkerSourceTask:238)
[2022-12-04 23:08:06,464] INFO Begin using SQL query: SELECT * FROM stations; (io.confluent.connect.jdbc.source.TableQuerier:181)
[2022-12-04 23:08:09,404] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Successfully joined group with generation Generation{generationId=9, memberId='connector-consumer-sink-results-0-8d2b4bd0-7873-4db7-96b0-ab7bd3979207', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2022-12-04 23:08:09,405] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Finished assignment for group at generation 9: {connector-consumer-sink-results-0-8d2b4bd0-7873-4db7-96b0-ab7bd3979207=Assignment(partitions=[ResultsLocation-0, ResultsWeather-0, ResultsAlert-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:626)
[2022-12-04 23:08:09,408] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Successfully synced group in generation Generation{generationId=9, memberId='connector-consumer-sink-results-0-8d2b4bd0-7873-4db7-96b0-ab7bd3979207', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:760)
[2022-12-04 23:08:09,409] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Notifying assignor about the new Assignment(partitions=[ResultsLocation-0, ResultsWeather-0, ResultsAlert-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:276)
[2022-12-04 23:08:09,409] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Adding newly assigned partitions: ResultsLocation-0, ResultsWeather-0, ResultsAlert-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:288)
[2022-12-04 23:08:09,413] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Found no committed offset for partition ResultsLocation-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1362)
[2022-12-04 23:08:09,413] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Found no committed offset for partition ResultsWeather-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1362)
[2022-12-04 23:08:09,413] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Found no committed offset for partition ResultsAlert-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1362)
[2022-12-04 23:08:09,417] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Resetting offset for partition ResultsLocation-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: r1)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-04 23:08:09,417] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Resetting offset for partition ResultsWeather-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: r1)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-04 23:08:09,418] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Resetting offset for partition ResultsAlert-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: r1)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-04 23:08:09,440] INFO Attempting to open connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:79)
[2022-12-04 23:08:09,444] INFO Maximum table name length for database is 63 bytes (io.confluent.connect.jdbc.dialect.PostgreSqlDatabaseDialect:130)
[2022-12-04 23:08:09,444] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2022-12-04 23:08:09,450] INFO Checking PostgreSql dialect for existence of TABLE "ResultsWeather" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:586)
[2022-12-04 23:08:09,453] INFO Using PostgreSql dialect TABLE "ResultsWeather" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:594)
[2022-12-04 23:08:09,457] INFO Checking PostgreSql dialect for type of TABLE "ResultsWeather" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:880)
[2022-12-04 23:08:09,459] INFO Setting metadata for table "ResultsWeather" to Table{name='"ResultsWeather"', type=TABLE columns=[Column{'count', isPrimaryKey=false, allowsNull=false, sqlType=int8}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=text}, Column{'station', isPrimaryKey=false, allowsNull=false, sqlType=text}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2022-12-04 23:08:09,459] ERROR WorkerSinkTask{id=sink-results-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted. Error: Write to table '"ResultsWeather"' in UPSERT mode requires key field names to be known, check the primary key configuration (org.apache.kafka.connect.runtime.WorkerSinkTask:608)
org.apache.kafka.connect.errors.ConnectException: Write to table '"ResultsWeather"' in UPSERT mode requires key field names to be known, check the primary key configuration
	at io.confluent.connect.jdbc.sink.BufferedRecords.getInsertSql(BufferedRecords.java:244)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:128)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:582)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:330)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:188)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1589)
[2022-12-04 23:08:09,460] ERROR WorkerSinkTask{id=sink-results-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:190)
org.apache.kafka.connect.errors.ConnectException: Exiting WorkerSinkTask due to unrecoverable exception.
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:610)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:330)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:188)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1589)
Caused by: org.apache.kafka.connect.errors.ConnectException: Write to table '"ResultsWeather"' in UPSERT mode requires key field names to be known, check the primary key configuration
	at io.confluent.connect.jdbc.sink.BufferedRecords.getInsertSql(BufferedRecords.java:244)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:128)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:582)
	... 10 more
[2022-12-04 23:08:09,461] INFO Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:161)
[2022-12-04 23:08:09,461] INFO Closing connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:105)
[2022-12-04 23:08:09,461] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Revoke previously assigned partitions ResultsLocation-0, ResultsWeather-0, ResultsAlert-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:307)
[2022-12-04 23:08:09,461] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Member connector-consumer-sink-results-0-8d2b4bd0-7873-4db7-96b0-ab7bd3979207 sending LeaveGroup request to coordinator localhost:9092 (id: 2147483646 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:1045)
[2022-12-04 23:08:09,463] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-04 23:08:09,463] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-04 23:08:09,463] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-04 23:08:09,464] INFO App info kafka.consumer for connector-consumer-sink-results-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-04 23:08:16,450] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:08:26,453] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:08:36,456] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:08:46,431] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2022-12-04 23:08:46,431] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:327)
[2022-12-04 23:08:46,436] INFO Stopped http_8083@66d23e4a{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:381)
[2022-12-04 23:08:46,437] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:149)
[2022-12-04 23:08:46,437] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:344)
[2022-12-04 23:08:46,437] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:102)
[2022-12-04 23:08:46,438] INFO Stopping task source-dbinfo-0 (org.apache.kafka.connect.runtime.Worker:830)
[2022-12-04 23:08:46,497] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 7 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:08:46,503] INFO Stopping JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:354)
[2022-12-04 23:08:46,504] INFO Closing resources for JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:366)
[2022-12-04 23:08:46,505] INFO Closing connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:105)
[2022-12-04 23:08:46,506] INFO [Producer clientId=connector-producer-source-dbinfo-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1204)
[2022-12-04 23:08:46,511] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-04 23:08:46,511] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-04 23:08:46,512] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-04 23:08:46,513] INFO App info kafka.producer for connector-producer-source-dbinfo-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-04 23:08:46,516] INFO Stopping connector source-dbinfo (org.apache.kafka.connect.runtime.Worker:382)
[2022-12-04 23:08:46,516] INFO Scheduled shutdown for WorkerConnector{id=source-dbinfo} (org.apache.kafka.connect.runtime.WorkerConnector:248)
[2022-12-04 23:08:46,516] INFO Stopping table monitoring thread (io.confluent.connect.jdbc.JdbcSourceConnector:200)
[2022-12-04 23:08:46,517] INFO Shutting down thread monitoring tables. (io.confluent.connect.jdbc.source.TableMonitorThread:168)
[2022-12-04 23:08:46,517] INFO Closing connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:105)
[2022-12-04 23:08:46,517] INFO Completed shutdown for WorkerConnector{id=source-dbinfo} (org.apache.kafka.connect.runtime.WorkerConnector:268)
[2022-12-04 23:08:46,518] INFO Stopping task sink-results-0 (org.apache.kafka.connect.runtime.Worker:830)
[2022-12-04 23:08:46,519] INFO Stopping connector sink-results (org.apache.kafka.connect.runtime.Worker:382)
[2022-12-04 23:08:46,519] INFO Scheduled shutdown for WorkerConnector{id=sink-results} (org.apache.kafka.connect.runtime.WorkerConnector:248)
[2022-12-04 23:08:46,519] INFO Completed shutdown for WorkerConnector{id=sink-results} (org.apache.kafka.connect.runtime.WorkerConnector:268)
[2022-12-04 23:08:46,520] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:205)
[2022-12-04 23:08:46,521] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2022-12-04 23:08:46,521] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-04 23:08:46,522] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-04 23:08:46,522] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-04 23:08:46,522] INFO App info kafka.connect for 192.168.1.123:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-04 23:08:46,522] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:226)
[2022-12-04 23:08:46,523] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:120)
[2022-12-04 23:08:46,523] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2022-12-04 23:08:47,448] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:68)
[2022-12-04 23:08:47,452] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Private Build, OpenJDK 64-Bit Server VM, 19.0.1, 19.0.1+10-Ubuntu-1ubuntu122.04
	jvm.classpath = /home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/activation-1.1.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/argparse4j-0.7.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/audience-annotations-0.5.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/commons-cli-1.4.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/commons-lang3-3.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-api-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-basic-auth-extension-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-file-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-json-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-mirror-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-mirror-client-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-runtime-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-transforms-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/hk2-api-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/hk2-locator-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/hk2-utils-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-annotations-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-core-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-databind-2.10.5.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-module-paranamer-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.inject-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/javassist-3.27.0-GA.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/javax.servlet-api-3.1.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jaxb-api-2.3.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-client-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-common-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-container-servlet-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-hk2-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-server-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jline-3.12.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jopt-simple-5.0.4.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka_2.13-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka_2.13-2.8.1-sources.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-clients-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-connect-jdbc-10.6.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-log4j-appender-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-metadata-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-raft-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-shell-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-streams-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-streams-examples-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-streams-scala_2.13-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-streams-test-utils-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-tools-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/log4j-1.2.17.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/lz4-java-1.7.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/maven-artifact-3.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/metrics-core-2.2.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-buffer-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-codec-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-common-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-handler-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-resolver-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-transport-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-transport-native-epoll-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-transport-native-unix-common-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/paranamer-2.8.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/plexus-utils-3.2.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/postgresql-42.5.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/reflections-0.9.12.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/rocksdbjni-5.18.4.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-collection-compat_2.13-2.3.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-library-2.13.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-logging_2.13-3.9.2.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-reflect-2.13.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/slf4j-api-1.7.30.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/snappy-java-1.1.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/zookeeper-3.5.9.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/zookeeper-jute-3.5.9.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/zstd-jni-1.4.9-1.jar
	os.spec = Linux, amd64, 6.0.0-1006-oem
	os.vcpus = 20
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2022-12-04 23:08:47,453] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:77)
[2022-12-04 23:08:48,099] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@251a69d7 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:269)
[2022-12-04 23:08:48,099] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,099] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,100] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,100] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,100] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,100] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,100] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,100] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,100] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,100] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,100] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,100] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,101] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,101] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,101] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,101] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,101] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,102] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,102] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,102] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,103] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,103] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,103] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,103] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,103] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,103] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,103] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,103] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,104] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,104] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,104] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,104] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,104] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,104] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,104] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,104] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,104] INFO Added plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,104] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,104] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,105] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,105] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,105] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,105] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,105] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,105] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,105] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,105] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,105] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,105] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,105] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,105] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,105] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,105] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:08:48,108] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:48,108] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:48,108] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:48,108] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:48,108] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:48,108] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:48,108] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:48,108] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:48,108] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:48,108] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:48,109] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:48,109] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:48,109] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:48,109] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:48,109] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:48,109] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:48,109] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:48,109] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:48,109] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:48,109] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:48,109] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:48,109] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:48,109] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:48,109] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:48,109] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:48,109] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:48,109] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:48,109] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:48,109] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:08:48,110] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:48,110] INFO Added aliases 'PredicatedTransformation' and 'Predicated' to plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:48,110] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:08:48,110] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:08:48,110] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:08:48,110] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:08:48,110] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:08:48,110] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:08:48,110] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:08:48,110] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:08:48,110] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:48,110] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:48,110] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:08:48,119] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = null
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:372)
[2022-12-04 23:08:48,119] WARN Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results. (org.apache.kafka.connect.runtime.WorkerConfig:420)
[2022-12-04 23:08:48,119] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:49)
[2022-12-04 23:08:48,121] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2022-12-04 23:08:48,155] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:08:48,155] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:08:48,155] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:08:48,155] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:08:48,155] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:08:48,155] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:08:48,155] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:08:48,155] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:08:48,155] INFO Kafka startTimeMs: 1670195328155 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:08:48,281] INFO Kafka cluster ID: uYYJbbgfRseD3C81aqQl8w (org.apache.kafka.connect.util.ConnectUtils:65)
[2022-12-04 23:08:48,282] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-04 23:08:48,285] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-04 23:08:48,285] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-04 23:08:48,285] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-04 23:08:48,291] INFO Logging initialized @1051ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2022-12-04 23:08:48,308] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:132)
[2022-12-04 23:08:48,308] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:204)
[2022-12-04 23:08:48,311] INFO jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 19.0.1+10-Ubuntu-1ubuntu122.04 (org.eclipse.jetty.server.Server:375)
[2022-12-04 23:08:48,324] INFO Started http_8083@66d23e4a{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:331)
[2022-12-04 23:08:48,325] INFO Started @1084ms (org.eclipse.jetty.server.Server:415)
[2022-12-04 23:08:48,333] INFO Advertised URI: http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:371)
[2022-12-04 23:08:48,334] INFO REST server listening at http://192.168.1.123:8083/, advertising URL http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2022-12-04 23:08:48,334] INFO Advertised URI: http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:371)
[2022-12-04 23:08:48,334] INFO REST admin endpoints at http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:220)
[2022-12-04 23:08:48,334] INFO Advertised URI: http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:371)
[2022-12-04 23:08:48,335] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2022-12-04 23:08:48,340] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:49)
[2022-12-04 23:08:48,340] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2022-12-04 23:08:48,342] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:08:48,343] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:08:48,343] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:08:48,343] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:08:48,343] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:08:48,343] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:08:48,343] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:08:48,343] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:08:48,343] INFO Kafka startTimeMs: 1670195328343 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:08:48,348] INFO Kafka cluster ID: uYYJbbgfRseD3C81aqQl8w (org.apache.kafka.connect.util.ConnectUtils:65)
[2022-12-04 23:08:48,349] INFO App info kafka.admin.client for adminclient-2 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-04 23:08:48,350] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-04 23:08:48,350] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-04 23:08:48,350] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-04 23:08:48,353] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:08:48,353] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:08:48,353] INFO Kafka startTimeMs: 1670195328353 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:08:48,401] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-04 23:08:48,402] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-04 23:08:48,406] INFO Kafka Connect standalone worker initialization took 955ms (org.apache.kafka.connect.cli.ConnectStandalone:99)
[2022-12-04 23:08:48,406] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2022-12-04 23:08:48,406] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:94)
[2022-12-04 23:08:48,406] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:191)
[2022-12-04 23:08:48,407] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2022-12-04 23:08:48,412] INFO Worker started (org.apache.kafka.connect.runtime.Worker:198)
[2022-12-04 23:08:48,412] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:97)
[2022-12-04 23:08:48,412] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:224)
[2022-12-04 23:08:48,431] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:241)
[2022-12-04 23:08:48,467] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2022-12-04 23:08:48,467] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2022-12-04 23:08:48,468] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session:132)
[2022-12-04 23:08:48,653] INFO Started o.e.j.s.ServletContextHandler@3be4f71{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:915)
[2022-12-04 23:08:48,653] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:319)
[2022-12-04 23:08:48,653] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2022-12-04 23:08:48,666] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2022-12-04 23:08:48,670] INFO Creating connector sink-results of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:271)
[2022-12-04 23:08:48,671] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2022-12-04 23:08:48,671] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:08:48,672] INFO Instantiated connector sink-results with version 10.6.0 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:281)
[2022-12-04 23:08:48,673] INFO Finished creating connector sink-results (org.apache.kafka.connect.runtime.Worker:306)
[2022-12-04 23:08:48,674] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2022-12-04 23:08:48,674] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:08:48,675] INFO Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:51)
[2022-12-04 23:08:48,675] INFO Creating task sink-results-0 (org.apache.kafka.connect.runtime.Worker:505)
[2022-12-04 23:08:48,676] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2022-12-04 23:08:48,676] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:08:48,677] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2022-12-04 23:08:48,677] INFO Instantiated task sink-results-0 with version 10.6.0 of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:520)
[2022-12-04 23:08:48,677] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:372)
[2022-12-04 23:08:48,677] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-04 23:08:48,677] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task sink-results-0 using the connector config (org.apache.kafka.connect.runtime.Worker:535)
[2022-12-04 23:08:48,677] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task sink-results-0 using the connector config (org.apache.kafka.connect.runtime.Worker:541)
[2022-12-04 23:08:48,678] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task sink-results-0 using the worker config (org.apache.kafka.connect.runtime.Worker:546)
[2022-12-04 23:08:48,679] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:626)
[2022-12-04 23:08:48,679] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2022-12-04 23:08:48,679] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:08:48,684] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-sink-results-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-sink-results
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2022-12-04 23:08:48,701] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-04 23:08:48,701] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:08:48,701] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:08:48,701] INFO Kafka startTimeMs: 1670195328701 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:08:48,705] INFO Created connector sink-results (org.apache.kafka.connect.cli.ConnectStandalone:109)
[2022-12-04 23:08:48,706] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Subscribed to topic(s): ResultsWeather, ResultsAlert, ResultsLocation (org.apache.kafka.clients.consumer.KafkaConsumer:965)
[2022-12-04 23:08:48,706] INFO Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:48)
[2022-12-04 23:08:48,706] INFO JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:postgresql://localhost:5432/kafka
	connection.user = postgres
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = upsert
	max.retries = 10
	pk.fields = [id]
	pk.mode = record_key
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:372)
[2022-12-04 23:08:48,706] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:postgresql://localhost:5432/kafka
	connection.user = postgres
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = SELECT * FROM stations;
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = DBInfo
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:372)
[2022-12-04 23:08:48,707] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2022-12-04 23:08:48,707] INFO Creating connector source-dbinfo of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:271)
[2022-12-04 23:08:48,708] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2022-12-04 23:08:48,708] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:08:48,708] INFO Initializing writer using SQL dialect: PostgreSqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2022-12-04 23:08:48,709] INFO WorkerSinkTask{id=sink-results-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:310)
[2022-12-04 23:08:48,709] INFO Instantiated connector source-dbinfo with version 10.6.0 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:281)
[2022-12-04 23:08:48,709] INFO WorkerSinkTask{id=sink-results-0} Executing sink task (org.apache.kafka.connect.runtime.WorkerSinkTask:196)
[2022-12-04 23:08:48,709] INFO Finished creating connector source-dbinfo (org.apache.kafka.connect.runtime.Worker:306)
[2022-12-04 23:08:48,710] INFO Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:71)
[2022-12-04 23:08:48,710] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:postgresql://localhost:5432/kafka
	connection.user = postgres
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = SELECT * FROM stations;
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = DBInfo
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:372)
[2022-12-04 23:08:48,710] INFO Attempting to open connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:79)
[2022-12-04 23:08:48,717] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Cluster ID: uYYJbbgfRseD3C81aqQl8w (org.apache.kafka.clients.Metadata:279)
[2022-12-04 23:08:48,717] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Discovered group coordinator localhost:9092 (id: 2147483646 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:850)
[2022-12-04 23:08:48,719] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2022-12-04 23:08:48,727] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2022-12-04 23:08:48,764] INFO Maximum table name length for database is 63 bytes (io.confluent.connect.jdbc.dialect.PostgreSqlDatabaseDialect:130)
[2022-12-04 23:08:48,765] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2022-12-04 23:08:48,766] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:08:48,767] INFO Creating task source-dbinfo-0 (org.apache.kafka.connect.runtime.Worker:505)
[2022-12-04 23:08:48,768] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2022-12-04 23:08:48,768] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:08:48,769] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.source.JdbcSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2022-12-04 23:08:48,769] INFO Instantiated task source-dbinfo-0 with version 10.6.0 of type io.confluent.connect.jdbc.source.JdbcSourceTask (org.apache.kafka.connect.runtime.Worker:520)
[2022-12-04 23:08:48,769] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-04 23:08:48,769] INFO Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task source-dbinfo-0 using the worker config (org.apache.kafka.connect.runtime.Worker:533)
[2022-12-04 23:08:48,770] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-04 23:08:48,770] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task source-dbinfo-0 using the worker config (org.apache.kafka.connect.runtime.Worker:539)
[2022-12-04 23:08:48,770] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task source-dbinfo-0 using the worker config (org.apache.kafka.connect.runtime.Worker:546)
[2022-12-04 23:08:48,770] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2022-12-04 23:08:48,770] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:08:48,770] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:600)
[2022-12-04 23:08:48,772] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-source-dbinfo-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2022-12-04 23:08:48,780] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-04 23:08:48,780] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:08:48,780] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:08:48,780] INFO Kafka startTimeMs: 1670195328780 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:08:48,783] INFO [Producer clientId=connector-producer-source-dbinfo-0] Cluster ID: uYYJbbgfRseD3C81aqQl8w (org.apache.kafka.clients.Metadata:279)
[2022-12-04 23:08:48,783] INFO Starting JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:92)
[2022-12-04 23:08:48,784] INFO Created connector source-dbinfo (org.apache.kafka.connect.cli.ConnectStandalone:109)
[2022-12-04 23:08:48,784] INFO JdbcSourceTaskConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:postgresql://localhost:5432/kafka
	connection.user = postgres
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = SELECT * FROM stations;
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	tables = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = DBInfo
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceTaskConfig:372)
[2022-12-04 23:08:48,784] INFO Using JDBC dialect PostgreSql (io.confluent.connect.jdbc.source.JdbcSourceTask:127)
[2022-12-04 23:08:48,784] INFO Attempting to open connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:79)
[2022-12-04 23:08:48,789] INFO Maximum table name length for database is 63 bytes (io.confluent.connect.jdbc.dialect.PostgreSqlDatabaseDialect:130)
[2022-12-04 23:08:48,790] INFO Started JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:296)
[2022-12-04 23:08:48,790] INFO WorkerSourceTask{id=source-dbinfo-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:232)
[2022-12-04 23:08:48,790] INFO WorkerSourceTask{id=source-dbinfo-0} Executing source task (org.apache.kafka.connect.runtime.WorkerSourceTask:238)
[2022-12-04 23:08:48,796] INFO Begin using SQL query: SELECT * FROM stations; (io.confluent.connect.jdbc.source.TableQuerier:181)
[2022-12-04 23:08:51,730] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Successfully joined group with generation Generation{generationId=11, memberId='connector-consumer-sink-results-0-e950a720-feba-491f-9841-7756a3815063', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2022-12-04 23:08:51,731] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Finished assignment for group at generation 11: {connector-consumer-sink-results-0-e950a720-feba-491f-9841-7756a3815063=Assignment(partitions=[ResultsLocation-0, ResultsWeather-0, ResultsAlert-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:626)
[2022-12-04 23:08:51,736] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Successfully synced group in generation Generation{generationId=11, memberId='connector-consumer-sink-results-0-e950a720-feba-491f-9841-7756a3815063', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:760)
[2022-12-04 23:08:51,736] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Notifying assignor about the new Assignment(partitions=[ResultsLocation-0, ResultsWeather-0, ResultsAlert-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:276)
[2022-12-04 23:08:51,737] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Adding newly assigned partitions: ResultsLocation-0, ResultsWeather-0, ResultsAlert-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:288)
[2022-12-04 23:08:51,742] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Found no committed offset for partition ResultsLocation-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1362)
[2022-12-04 23:08:51,742] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Found no committed offset for partition ResultsWeather-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1362)
[2022-12-04 23:08:51,742] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Found no committed offset for partition ResultsAlert-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1362)
[2022-12-04 23:08:51,749] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Resetting offset for partition ResultsLocation-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: r1)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-04 23:08:51,749] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Resetting offset for partition ResultsWeather-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: r1)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-04 23:08:51,750] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Resetting offset for partition ResultsAlert-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: r1)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-04 23:08:51,777] INFO Attempting to open connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:79)
[2022-12-04 23:08:51,784] INFO Maximum table name length for database is 63 bytes (io.confluent.connect.jdbc.dialect.PostgreSqlDatabaseDialect:130)
[2022-12-04 23:08:51,784] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2022-12-04 23:08:51,793] INFO Checking PostgreSql dialect for existence of TABLE "ResultsWeather" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:586)
[2022-12-04 23:08:51,796] INFO Using PostgreSql dialect TABLE "ResultsWeather" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:594)
[2022-12-04 23:08:51,801] INFO Checking PostgreSql dialect for type of TABLE "ResultsWeather" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:880)
[2022-12-04 23:08:51,803] INFO Setting metadata for table "ResultsWeather" to Table{name='"ResultsWeather"', type=TABLE columns=[Column{'count', isPrimaryKey=false, allowsNull=false, sqlType=int8}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=text}, Column{'station', isPrimaryKey=false, allowsNull=false, sqlType=text}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2022-12-04 23:08:51,815] WARN Write of 98 records failed, remainingRetries=10 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('LA',5675) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).  Call getNextException to see other errors in the batch.
	at org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2367)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:560)
	at org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:893)
	at org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:916)
	at org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1684)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:196)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:186)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:582)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:330)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:188)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1589)
Caused by: org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2676)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2366)
	... 19 more
[2022-12-04 23:08:51,817] INFO Closing connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:105)
[2022-12-04 23:08:51,818] INFO Initializing writer using SQL dialect: PostgreSqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2022-12-04 23:08:51,818] ERROR WorkerSinkTask{id=sink-results-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:601)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('LA',5675) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).  Call getNextException to see other errors in the batch.
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:582)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:330)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:188)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1589)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('LA',5675) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).  Call getNextException to see other errors in the batch.
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2022-12-04 23:08:54,819] INFO Attempting to open connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:79)
[2022-12-04 23:08:54,829] INFO Maximum table name length for database is 63 bytes (io.confluent.connect.jdbc.dialect.PostgreSqlDatabaseDialect:130)
[2022-12-04 23:08:54,830] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2022-12-04 23:08:54,837] INFO Checking PostgreSql dialect for existence of TABLE "ResultsWeather" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:586)
[2022-12-04 23:08:54,840] INFO Using PostgreSql dialect TABLE "ResultsWeather" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:594)
[2022-12-04 23:08:54,848] INFO Checking PostgreSql dialect for type of TABLE "ResultsWeather" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:880)
[2022-12-04 23:08:54,849] INFO Setting metadata for table "ResultsWeather" to Table{name='"ResultsWeather"', type=TABLE columns=[Column{'count', isPrimaryKey=false, allowsNull=false, sqlType=int8}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=text}, Column{'station', isPrimaryKey=false, allowsNull=false, sqlType=text}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2022-12-04 23:08:54,854] WARN Write of 98 records failed, remainingRetries=9 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('LA',5675) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).  Call getNextException to see other errors in the batch.
	at org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2367)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:560)
	at org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:893)
	at org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:916)
	at org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1684)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:196)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:186)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:582)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:330)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:188)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1589)
Caused by: org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2676)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2366)
	... 19 more
[2022-12-04 23:08:54,855] INFO Closing connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:105)
[2022-12-04 23:08:54,855] INFO Initializing writer using SQL dialect: PostgreSqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2022-12-04 23:08:54,855] ERROR WorkerSinkTask{id=sink-results-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:601)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('LA',5675) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).  Call getNextException to see other errors in the batch.
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:582)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:330)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:188)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1589)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('LA',5675) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).  Call getNextException to see other errors in the batch.
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2022-12-04 23:08:57,857] INFO Attempting to open connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:79)
[2022-12-04 23:08:57,869] INFO Maximum table name length for database is 63 bytes (io.confluent.connect.jdbc.dialect.PostgreSqlDatabaseDialect:130)
[2022-12-04 23:08:57,869] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2022-12-04 23:08:57,877] INFO Checking PostgreSql dialect for existence of TABLE "ResultsWeather" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:586)
[2022-12-04 23:08:57,880] INFO Using PostgreSql dialect TABLE "ResultsWeather" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:594)
[2022-12-04 23:08:57,885] INFO Checking PostgreSql dialect for type of TABLE "ResultsWeather" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:880)
[2022-12-04 23:08:57,886] INFO Setting metadata for table "ResultsWeather" to Table{name='"ResultsWeather"', type=TABLE columns=[Column{'count', isPrimaryKey=false, allowsNull=false, sqlType=int8}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=text}, Column{'station', isPrimaryKey=false, allowsNull=false, sqlType=text}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2022-12-04 23:08:57,890] WARN Write of 98 records failed, remainingRetries=8 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('LA',5675) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).  Call getNextException to see other errors in the batch.
	at org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2367)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:560)
	at org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:893)
	at org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:916)
	at org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1684)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:196)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:186)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:582)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:330)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:188)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1589)
Caused by: org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2676)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2366)
	... 19 more
[2022-12-04 23:08:57,890] INFO Closing connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:105)
[2022-12-04 23:08:57,891] INFO Initializing writer using SQL dialect: PostgreSqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2022-12-04 23:08:57,891] ERROR WorkerSinkTask{id=sink-results-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:601)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('LA',5675) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).  Call getNextException to see other errors in the batch.
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:582)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:330)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:188)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1589)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('LA',5675) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).  Call getNextException to see other errors in the batch.
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2022-12-04 23:08:58,705] INFO Attempting to open connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:79)
[2022-12-04 23:08:58,717] INFO Maximum table name length for database is 63 bytes (io.confluent.connect.jdbc.dialect.PostgreSqlDatabaseDialect:130)
[2022-12-04 23:08:58,717] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2022-12-04 23:08:58,726] INFO Checking PostgreSql dialect for existence of TABLE "ResultsWeather" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:586)
[2022-12-04 23:08:58,730] INFO Using PostgreSql dialect TABLE "ResultsWeather" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:594)
[2022-12-04 23:08:58,735] INFO Checking PostgreSql dialect for type of TABLE "ResultsWeather" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:880)
[2022-12-04 23:08:58,737] INFO Setting metadata for table "ResultsWeather" to Table{name='"ResultsWeather"', type=TABLE columns=[Column{'count', isPrimaryKey=false, allowsNull=false, sqlType=int8}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=text}, Column{'station', isPrimaryKey=false, allowsNull=false, sqlType=text}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2022-12-04 23:08:58,742] WARN Write of 98 records failed, remainingRetries=7 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('LA',5675) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).  Call getNextException to see other errors in the batch.
	at org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2367)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:560)
	at org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:893)
	at org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:916)
	at org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1684)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:196)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:186)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:582)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:330)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:188)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1589)
Caused by: org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2676)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2366)
	... 19 more
[2022-12-04 23:08:58,742] INFO Closing connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:105)
[2022-12-04 23:08:58,743] INFO Initializing writer using SQL dialect: PostgreSqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2022-12-04 23:08:58,743] ERROR WorkerSinkTask{id=sink-results-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:601)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('LA',5675) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).  Call getNextException to see other errors in the batch.
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:582)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:330)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:188)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1589)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('LA',5675) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).  Call getNextException to see other errors in the batch.
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2022-12-04 23:08:58,784] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:09:01,745] INFO Attempting to open connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:79)
[2022-12-04 23:09:01,757] INFO Maximum table name length for database is 63 bytes (io.confluent.connect.jdbc.dialect.PostgreSqlDatabaseDialect:130)
[2022-12-04 23:09:01,757] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2022-12-04 23:09:01,765] INFO Checking PostgreSql dialect for existence of TABLE "ResultsWeather" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:586)
[2022-12-04 23:09:01,768] INFO Using PostgreSql dialect TABLE "ResultsWeather" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:594)
[2022-12-04 23:09:01,772] INFO Checking PostgreSql dialect for type of TABLE "ResultsWeather" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:880)
[2022-12-04 23:09:01,774] INFO Setting metadata for table "ResultsWeather" to Table{name='"ResultsWeather"', type=TABLE columns=[Column{'count', isPrimaryKey=false, allowsNull=false, sqlType=int8}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=text}, Column{'station', isPrimaryKey=false, allowsNull=false, sqlType=text}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2022-12-04 23:09:01,779] WARN Write of 98 records failed, remainingRetries=6 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('LA',5675) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).  Call getNextException to see other errors in the batch.
	at org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2367)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:560)
	at org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:893)
	at org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:916)
	at org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1684)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:196)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:186)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:582)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:330)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:188)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1589)
Caused by: org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2676)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2366)
	... 19 more
[2022-12-04 23:09:01,779] INFO Closing connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:105)
[2022-12-04 23:09:01,779] INFO Initializing writer using SQL dialect: PostgreSqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2022-12-04 23:09:01,779] ERROR WorkerSinkTask{id=sink-results-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:601)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('LA',5675) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).  Call getNextException to see other errors in the batch.
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:582)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:330)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:188)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1589)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('LA',5675) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).  Call getNextException to see other errors in the batch.
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2022-12-04 23:09:04,781] INFO Attempting to open connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:79)
[2022-12-04 23:09:04,793] INFO Maximum table name length for database is 63 bytes (io.confluent.connect.jdbc.dialect.PostgreSqlDatabaseDialect:130)
[2022-12-04 23:09:04,793] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2022-12-04 23:09:04,800] INFO Checking PostgreSql dialect for existence of TABLE "ResultsWeather" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:586)
[2022-12-04 23:09:04,802] INFO Using PostgreSql dialect TABLE "ResultsWeather" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:594)
[2022-12-04 23:09:04,808] INFO Checking PostgreSql dialect for type of TABLE "ResultsWeather" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:880)
[2022-12-04 23:09:04,809] INFO Setting metadata for table "ResultsWeather" to Table{name='"ResultsWeather"', type=TABLE columns=[Column{'count', isPrimaryKey=false, allowsNull=false, sqlType=int8}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=text}, Column{'station', isPrimaryKey=false, allowsNull=false, sqlType=text}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2022-12-04 23:09:04,812] WARN Write of 98 records failed, remainingRetries=5 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('LA',5675) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).  Call getNextException to see other errors in the batch.
	at org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2367)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:560)
	at org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:893)
	at org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:916)
	at org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1684)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:196)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:186)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:582)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:330)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:188)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1589)
Caused by: org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2676)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2366)
	... 19 more
[2022-12-04 23:09:04,812] INFO Closing connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:105)
[2022-12-04 23:09:04,812] INFO Initializing writer using SQL dialect: PostgreSqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2022-12-04 23:09:04,812] ERROR WorkerSinkTask{id=sink-results-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:601)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('LA',5675) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).  Call getNextException to see other errors in the batch.
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:582)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:330)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:188)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1589)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('LA',5675) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).  Call getNextException to see other errors in the batch.
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2022-12-04 23:09:05,556] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2022-12-04 23:09:05,557] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:327)
[2022-12-04 23:09:05,563] INFO Stopped http_8083@66d23e4a{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:381)
[2022-12-04 23:09:05,563] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:149)
[2022-12-04 23:09:05,565] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:344)
[2022-12-04 23:09:05,565] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:102)
[2022-12-04 23:09:05,566] INFO Stopping task source-dbinfo-0 (org.apache.kafka.connect.runtime.Worker:830)
[2022-12-04 23:09:07,813] INFO Attempting to open connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:79)
[2022-12-04 23:09:07,824] INFO Maximum table name length for database is 63 bytes (io.confluent.connect.jdbc.dialect.PostgreSqlDatabaseDialect:130)
[2022-12-04 23:09:07,824] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2022-12-04 23:09:07,832] INFO Checking PostgreSql dialect for existence of TABLE "ResultsWeather" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:586)
[2022-12-04 23:09:07,834] INFO Using PostgreSql dialect TABLE "ResultsWeather" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:594)
[2022-12-04 23:09:07,837] INFO Checking PostgreSql dialect for type of TABLE "ResultsWeather" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:880)
[2022-12-04 23:09:07,838] INFO Setting metadata for table "ResultsWeather" to Table{name='"ResultsWeather"', type=TABLE columns=[Column{'count', isPrimaryKey=false, allowsNull=false, sqlType=int8}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=text}, Column{'station', isPrimaryKey=false, allowsNull=false, sqlType=text}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2022-12-04 23:09:07,841] WARN Write of 98 records failed, remainingRetries=4 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('LA',5675) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).  Call getNextException to see other errors in the batch.
	at org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2367)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:560)
	at org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:893)
	at org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:916)
	at org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1684)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:196)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:186)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:582)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:330)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:188)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1589)
Caused by: org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2676)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2366)
	... 19 more
[2022-12-04 23:09:07,841] INFO Closing connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:105)
[2022-12-04 23:09:07,841] INFO Initializing writer using SQL dialect: PostgreSqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2022-12-04 23:09:07,841] ERROR WorkerSinkTask{id=sink-results-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:601)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('LA',5675) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).  Call getNextException to see other errors in the batch.
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:582)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:330)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:188)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1589)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('LA',5675) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).  Call getNextException to see other errors in the batch.
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2022-12-04 23:09:08,745] INFO Attempting to open connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:79)
[2022-12-04 23:09:08,756] INFO Maximum table name length for database is 63 bytes (io.confluent.connect.jdbc.dialect.PostgreSqlDatabaseDialect:130)
[2022-12-04 23:09:08,757] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2022-12-04 23:09:08,764] INFO Checking PostgreSql dialect for existence of TABLE "ResultsWeather" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:586)
[2022-12-04 23:09:08,766] INFO Using PostgreSql dialect TABLE "ResultsWeather" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:594)
[2022-12-04 23:09:08,771] INFO Checking PostgreSql dialect for type of TABLE "ResultsWeather" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:880)
[2022-12-04 23:09:08,773] INFO Setting metadata for table "ResultsWeather" to Table{name='"ResultsWeather"', type=TABLE columns=[Column{'count', isPrimaryKey=false, allowsNull=false, sqlType=int8}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=text}, Column{'station', isPrimaryKey=false, allowsNull=false, sqlType=text}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2022-12-04 23:09:08,776] WARN Write of 98 records failed, remainingRetries=3 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('LA',5675) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).  Call getNextException to see other errors in the batch.
	at org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2367)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:560)
	at org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:893)
	at org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:916)
	at org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1684)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:196)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:186)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:582)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:330)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:188)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1589)
Caused by: org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2676)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2366)
	... 19 more
[2022-12-04 23:09:08,776] INFO Closing connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:105)
[2022-12-04 23:09:08,777] INFO Initializing writer using SQL dialect: PostgreSqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2022-12-04 23:09:08,777] ERROR WorkerSinkTask{id=sink-results-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:601)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('LA',5675) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).  Call getNextException to see other errors in the batch.
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:582)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:330)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:188)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1589)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('LA',5675) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).  Call getNextException to see other errors in the batch.
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2022-12-04 23:09:08,818] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 7 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:09:08,824] INFO Stopping JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:354)
[2022-12-04 23:09:08,824] INFO Closing resources for JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:366)
[2022-12-04 23:09:08,824] INFO Closing connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:105)
[2022-12-04 23:09:08,824] INFO [Producer clientId=connector-producer-source-dbinfo-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1204)
[2022-12-04 23:09:08,827] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-04 23:09:08,828] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-04 23:09:08,828] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-04 23:09:08,828] INFO App info kafka.producer for connector-producer-source-dbinfo-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-04 23:09:08,831] INFO Stopping connector source-dbinfo (org.apache.kafka.connect.runtime.Worker:382)
[2022-12-04 23:09:08,831] INFO Scheduled shutdown for WorkerConnector{id=source-dbinfo} (org.apache.kafka.connect.runtime.WorkerConnector:248)
[2022-12-04 23:09:08,831] INFO Stopping table monitoring thread (io.confluent.connect.jdbc.JdbcSourceConnector:200)
[2022-12-04 23:09:08,831] INFO Shutting down thread monitoring tables. (io.confluent.connect.jdbc.source.TableMonitorThread:168)
[2022-12-04 23:09:08,831] INFO Closing connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:105)
[2022-12-04 23:09:08,831] INFO Completed shutdown for WorkerConnector{id=source-dbinfo} (org.apache.kafka.connect.runtime.WorkerConnector:268)
[2022-12-04 23:09:08,831] INFO Stopping task sink-results-0 (org.apache.kafka.connect.runtime.Worker:830)
[2022-12-04 23:09:08,832] INFO Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:161)
[2022-12-04 23:09:08,832] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Revoke previously assigned partitions ResultsLocation-0, ResultsWeather-0, ResultsAlert-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:307)
[2022-12-04 23:09:08,832] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Member connector-consumer-sink-results-0-e950a720-feba-491f-9841-7756a3815063 sending LeaveGroup request to coordinator localhost:9092 (id: 2147483646 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:1045)
[2022-12-04 23:09:08,835] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-04 23:09:08,835] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-04 23:09:08,836] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-04 23:09:08,839] INFO App info kafka.consumer for connector-consumer-sink-results-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-04 23:09:08,841] INFO Stopping connector sink-results (org.apache.kafka.connect.runtime.Worker:382)
[2022-12-04 23:09:08,842] INFO Scheduled shutdown for WorkerConnector{id=sink-results} (org.apache.kafka.connect.runtime.WorkerConnector:248)
[2022-12-04 23:09:08,842] INFO Completed shutdown for WorkerConnector{id=sink-results} (org.apache.kafka.connect.runtime.WorkerConnector:268)
[2022-12-04 23:09:08,843] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:205)
[2022-12-04 23:09:08,844] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2022-12-04 23:09:08,844] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-04 23:09:08,844] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-04 23:09:08,845] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-04 23:09:08,845] INFO App info kafka.connect for 192.168.1.123:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-04 23:09:08,845] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:226)
[2022-12-04 23:09:08,846] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:120)
[2022-12-04 23:09:08,846] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2022-12-04 23:09:27,595] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:68)
[2022-12-04 23:09:27,599] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Private Build, OpenJDK 64-Bit Server VM, 19.0.1, 19.0.1+10-Ubuntu-1ubuntu122.04
	jvm.classpath = /home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/activation-1.1.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/argparse4j-0.7.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/audience-annotations-0.5.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/commons-cli-1.4.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/commons-lang3-3.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-api-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-basic-auth-extension-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-file-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-json-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-mirror-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-mirror-client-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-runtime-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-transforms-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/hk2-api-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/hk2-locator-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/hk2-utils-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-annotations-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-core-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-databind-2.10.5.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-module-paranamer-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.inject-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/javassist-3.27.0-GA.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/javax.servlet-api-3.1.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jaxb-api-2.3.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-client-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-common-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-container-servlet-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-hk2-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-server-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jline-3.12.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jopt-simple-5.0.4.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka_2.13-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka_2.13-2.8.1-sources.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-clients-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-connect-jdbc-10.6.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-log4j-appender-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-metadata-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-raft-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-shell-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-streams-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-streams-examples-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-streams-scala_2.13-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-streams-test-utils-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-tools-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/log4j-1.2.17.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/lz4-java-1.7.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/maven-artifact-3.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/metrics-core-2.2.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-buffer-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-codec-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-common-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-handler-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-resolver-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-transport-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-transport-native-epoll-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-transport-native-unix-common-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/paranamer-2.8.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/plexus-utils-3.2.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/postgresql-42.5.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/reflections-0.9.12.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/rocksdbjni-5.18.4.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-collection-compat_2.13-2.3.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-library-2.13.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-logging_2.13-3.9.2.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-reflect-2.13.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/slf4j-api-1.7.30.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/snappy-java-1.1.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/zookeeper-3.5.9.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/zookeeper-jute-3.5.9.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/zstd-jni-1.4.9-1.jar
	os.spec = Linux, amd64, 6.0.0-1006-oem
	os.vcpus = 20
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2022-12-04 23:09:27,600] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:77)
[2022-12-04 23:09:28,384] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@251a69d7 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:269)
[2022-12-04 23:09:28,385] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,385] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,385] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,385] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,385] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,385] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,385] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,385] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,385] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,385] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,385] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,385] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,386] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,386] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,386] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,386] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,386] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,386] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,386] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,387] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,387] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,387] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,387] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,387] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,387] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,387] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,387] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,387] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,387] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,387] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,388] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,388] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,388] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,388] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,388] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,388] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,388] INFO Added plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,388] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,388] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,388] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,388] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,388] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,388] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,388] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,389] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,389] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,389] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,389] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,389] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,389] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,389] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,389] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,389] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:09:28,392] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:09:28,392] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:09:28,392] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:09:28,392] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:09:28,392] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:09:28,392] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:09:28,392] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:09:28,392] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:09:28,393] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:09:28,393] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:09:28,393] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:09:28,393] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:09:28,393] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:09:28,393] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:09:28,393] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:09:28,393] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:09:28,393] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:09:28,393] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:09:28,393] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:09:28,393] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:09:28,393] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:09:28,393] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:09:28,393] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:09:28,393] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:09:28,394] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:09:28,394] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:09:28,394] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:09:28,394] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:09:28,394] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:09:28,394] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:09:28,394] INFO Added aliases 'PredicatedTransformation' and 'Predicated' to plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:09:28,394] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:09:28,394] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:09:28,394] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:09:28,394] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:09:28,394] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:09:28,394] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:09:28,394] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:09:28,394] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:09:28,394] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:09:28,394] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:09:28,394] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:09:28,405] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = null
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:372)
[2022-12-04 23:09:28,405] WARN Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results. (org.apache.kafka.connect.runtime.WorkerConfig:420)
[2022-12-04 23:09:28,406] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:49)
[2022-12-04 23:09:28,407] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2022-12-04 23:09:28,443] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:09:28,443] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:09:28,443] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:09:28,443] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:09:28,443] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:09:28,443] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:09:28,443] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:09:28,443] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:09:28,443] INFO Kafka startTimeMs: 1670195368443 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:09:28,563] INFO Kafka cluster ID: uYYJbbgfRseD3C81aqQl8w (org.apache.kafka.connect.util.ConnectUtils:65)
[2022-12-04 23:09:28,563] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-04 23:09:28,566] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-04 23:09:28,567] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-04 23:09:28,567] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-04 23:09:28,573] INFO Logging initialized @1196ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2022-12-04 23:09:28,591] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:132)
[2022-12-04 23:09:28,592] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:204)
[2022-12-04 23:09:28,596] INFO jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 19.0.1+10-Ubuntu-1ubuntu122.04 (org.eclipse.jetty.server.Server:375)
[2022-12-04 23:09:28,608] INFO Started http_8083@66d23e4a{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:331)
[2022-12-04 23:09:28,608] INFO Started @1231ms (org.eclipse.jetty.server.Server:415)
[2022-12-04 23:09:28,617] INFO Advertised URI: http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:371)
[2022-12-04 23:09:28,617] INFO REST server listening at http://192.168.1.123:8083/, advertising URL http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2022-12-04 23:09:28,618] INFO Advertised URI: http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:371)
[2022-12-04 23:09:28,618] INFO REST admin endpoints at http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:220)
[2022-12-04 23:09:28,618] INFO Advertised URI: http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:371)
[2022-12-04 23:09:28,619] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2022-12-04 23:09:28,623] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:49)
[2022-12-04 23:09:28,624] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2022-12-04 23:09:28,627] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:09:28,627] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:09:28,627] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:09:28,628] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:09:28,628] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:09:28,628] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:09:28,628] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:09:28,628] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:09:28,628] INFO Kafka startTimeMs: 1670195368628 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:09:28,635] INFO Kafka cluster ID: uYYJbbgfRseD3C81aqQl8w (org.apache.kafka.connect.util.ConnectUtils:65)
[2022-12-04 23:09:28,636] INFO App info kafka.admin.client for adminclient-2 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-04 23:09:28,638] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-04 23:09:28,638] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-04 23:09:28,638] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-04 23:09:28,640] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:09:28,640] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:09:28,641] INFO Kafka startTimeMs: 1670195368640 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:09:28,686] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-04 23:09:28,687] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-04 23:09:28,690] INFO Kafka Connect standalone worker initialization took 1094ms (org.apache.kafka.connect.cli.ConnectStandalone:99)
[2022-12-04 23:09:28,690] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2022-12-04 23:09:28,690] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:94)
[2022-12-04 23:09:28,690] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:191)
[2022-12-04 23:09:28,691] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2022-12-04 23:09:28,694] INFO Worker started (org.apache.kafka.connect.runtime.Worker:198)
[2022-12-04 23:09:28,694] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:97)
[2022-12-04 23:09:28,694] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:224)
[2022-12-04 23:09:28,712] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:241)
[2022-12-04 23:09:28,751] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2022-12-04 23:09:28,751] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2022-12-04 23:09:28,752] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session:132)
[2022-12-04 23:09:28,960] INFO Started o.e.j.s.ServletContextHandler@3be4f71{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:915)
[2022-12-04 23:09:28,960] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:319)
[2022-12-04 23:09:28,960] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2022-12-04 23:09:28,973] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2022-12-04 23:09:28,978] INFO Creating connector sink-results of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:271)
[2022-12-04 23:09:28,978] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2022-12-04 23:09:28,979] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:09:28,980] INFO Instantiated connector sink-results with version 10.6.0 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:281)
[2022-12-04 23:09:28,980] INFO Finished creating connector sink-results (org.apache.kafka.connect.runtime.Worker:306)
[2022-12-04 23:09:28,982] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2022-12-04 23:09:28,982] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:09:28,982] INFO Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:51)
[2022-12-04 23:09:28,983] INFO Creating task sink-results-0 (org.apache.kafka.connect.runtime.Worker:505)
[2022-12-04 23:09:28,984] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2022-12-04 23:09:28,984] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:09:28,985] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2022-12-04 23:09:28,985] INFO Instantiated task sink-results-0 with version 10.6.0 of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:520)
[2022-12-04 23:09:28,985] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:372)
[2022-12-04 23:09:28,986] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-04 23:09:28,986] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task sink-results-0 using the connector config (org.apache.kafka.connect.runtime.Worker:535)
[2022-12-04 23:09:28,986] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task sink-results-0 using the connector config (org.apache.kafka.connect.runtime.Worker:541)
[2022-12-04 23:09:28,986] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task sink-results-0 using the worker config (org.apache.kafka.connect.runtime.Worker:546)
[2022-12-04 23:09:28,987] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:626)
[2022-12-04 23:09:28,988] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2022-12-04 23:09:28,988] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:09:28,992] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-sink-results-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-sink-results
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2022-12-04 23:09:29,010] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-04 23:09:29,010] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:09:29,011] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:09:29,011] INFO Kafka startTimeMs: 1670195369010 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:09:29,016] INFO Created connector sink-results (org.apache.kafka.connect.cli.ConnectStandalone:109)
[2022-12-04 23:09:29,017] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Subscribed to topic(s): ResultsWeather, ResultsAlert, ResultsLocation (org.apache.kafka.clients.consumer.KafkaConsumer:965)
[2022-12-04 23:09:29,017] INFO Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:48)
[2022-12-04 23:09:29,017] INFO JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:postgresql://localhost:5432/kafka
	connection.user = postgres
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = upsert
	max.retries = 10
	pk.fields = [id]
	pk.mode = record_key
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:372)
[2022-12-04 23:09:29,018] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:postgresql://localhost:5432/kafka
	connection.user = postgres
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = SELECT * FROM stations;
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = DBInfo
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:372)
[2022-12-04 23:09:29,018] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2022-12-04 23:09:29,019] INFO Creating connector source-dbinfo of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:271)
[2022-12-04 23:09:29,019] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2022-12-04 23:09:29,019] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:09:29,020] INFO Initializing writer using SQL dialect: PostgreSqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2022-12-04 23:09:29,020] INFO Instantiated connector source-dbinfo with version 10.6.0 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:281)
[2022-12-04 23:09:29,020] INFO Finished creating connector source-dbinfo (org.apache.kafka.connect.runtime.Worker:306)
[2022-12-04 23:09:29,020] INFO Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:71)
[2022-12-04 23:09:29,020] INFO WorkerSinkTask{id=sink-results-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:310)
[2022-12-04 23:09:29,021] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:postgresql://localhost:5432/kafka
	connection.user = postgres
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = SELECT * FROM stations;
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = DBInfo
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:372)
[2022-12-04 23:09:29,021] INFO WorkerSinkTask{id=sink-results-0} Executing sink task (org.apache.kafka.connect.runtime.WorkerSinkTask:196)
[2022-12-04 23:09:29,021] INFO Attempting to open connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:79)
[2022-12-04 23:09:29,029] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Cluster ID: uYYJbbgfRseD3C81aqQl8w (org.apache.kafka.clients.Metadata:279)
[2022-12-04 23:09:29,030] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Discovered group coordinator localhost:9092 (id: 2147483646 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:850)
[2022-12-04 23:09:29,031] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2022-12-04 23:09:29,039] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2022-12-04 23:09:29,073] INFO Maximum table name length for database is 63 bytes (io.confluent.connect.jdbc.dialect.PostgreSqlDatabaseDialect:130)
[2022-12-04 23:09:29,074] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2022-12-04 23:09:29,075] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:09:29,075] INFO Creating task source-dbinfo-0 (org.apache.kafka.connect.runtime.Worker:505)
[2022-12-04 23:09:29,076] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2022-12-04 23:09:29,077] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:09:29,077] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.source.JdbcSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2022-12-04 23:09:29,078] INFO Instantiated task source-dbinfo-0 with version 10.6.0 of type io.confluent.connect.jdbc.source.JdbcSourceTask (org.apache.kafka.connect.runtime.Worker:520)
[2022-12-04 23:09:29,078] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-04 23:09:29,078] INFO Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task source-dbinfo-0 using the worker config (org.apache.kafka.connect.runtime.Worker:533)
[2022-12-04 23:09:29,078] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-04 23:09:29,078] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task source-dbinfo-0 using the worker config (org.apache.kafka.connect.runtime.Worker:539)
[2022-12-04 23:09:29,078] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task source-dbinfo-0 using the worker config (org.apache.kafka.connect.runtime.Worker:546)
[2022-12-04 23:09:29,079] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2022-12-04 23:09:29,079] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:09:29,079] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:600)
[2022-12-04 23:09:29,081] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-source-dbinfo-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2022-12-04 23:09:29,089] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-04 23:09:29,090] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:09:29,090] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:09:29,090] INFO Kafka startTimeMs: 1670195369090 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:09:29,093] INFO Starting JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:92)
[2022-12-04 23:09:29,093] INFO Created connector source-dbinfo (org.apache.kafka.connect.cli.ConnectStandalone:109)
[2022-12-04 23:09:29,093] INFO JdbcSourceTaskConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:postgresql://localhost:5432/kafka
	connection.user = postgres
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = SELECT * FROM stations;
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	tables = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = DBInfo
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceTaskConfig:372)
[2022-12-04 23:09:29,094] INFO Using JDBC dialect PostgreSql (io.confluent.connect.jdbc.source.JdbcSourceTask:127)
[2022-12-04 23:09:29,094] INFO Attempting to open connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:79)
[2022-12-04 23:09:29,094] INFO [Producer clientId=connector-producer-source-dbinfo-0] Cluster ID: uYYJbbgfRseD3C81aqQl8w (org.apache.kafka.clients.Metadata:279)
[2022-12-04 23:09:29,097] INFO Maximum table name length for database is 63 bytes (io.confluent.connect.jdbc.dialect.PostgreSqlDatabaseDialect:130)
[2022-12-04 23:09:29,098] INFO Started JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:296)
[2022-12-04 23:09:29,098] INFO WorkerSourceTask{id=source-dbinfo-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:232)
[2022-12-04 23:09:29,098] INFO WorkerSourceTask{id=source-dbinfo-0} Executing source task (org.apache.kafka.connect.runtime.WorkerSourceTask:238)
[2022-12-04 23:09:29,104] INFO Begin using SQL query: SELECT * FROM stations; (io.confluent.connect.jdbc.source.TableQuerier:181)
[2022-12-04 23:09:32,041] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Successfully joined group with generation Generation{generationId=13, memberId='connector-consumer-sink-results-0-3579fbbb-a116-413e-b6e6-8d5851a2956c', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2022-12-04 23:09:32,042] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Finished assignment for group at generation 13: {connector-consumer-sink-results-0-3579fbbb-a116-413e-b6e6-8d5851a2956c=Assignment(partitions=[ResultsLocation-0, ResultsWeather-0, ResultsAlert-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:626)
[2022-12-04 23:09:32,045] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Successfully synced group in generation Generation{generationId=13, memberId='connector-consumer-sink-results-0-3579fbbb-a116-413e-b6e6-8d5851a2956c', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:760)
[2022-12-04 23:09:32,046] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Notifying assignor about the new Assignment(partitions=[ResultsLocation-0, ResultsWeather-0, ResultsAlert-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:276)
[2022-12-04 23:09:32,047] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Adding newly assigned partitions: ResultsLocation-0, ResultsWeather-0, ResultsAlert-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:288)
[2022-12-04 23:09:32,050] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Found no committed offset for partition ResultsLocation-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1362)
[2022-12-04 23:09:32,050] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Found no committed offset for partition ResultsWeather-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1362)
[2022-12-04 23:09:32,050] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Found no committed offset for partition ResultsAlert-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1362)
[2022-12-04 23:09:32,058] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Resetting offset for partition ResultsLocation-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: r1)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-04 23:09:32,058] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Resetting offset for partition ResultsWeather-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: r1)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-04 23:09:32,058] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Resetting offset for partition ResultsAlert-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: r1)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-04 23:09:32,086] INFO Attempting to open connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:79)
[2022-12-04 23:09:32,092] INFO Maximum table name length for database is 63 bytes (io.confluent.connect.jdbc.dialect.PostgreSqlDatabaseDialect:130)
[2022-12-04 23:09:32,092] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2022-12-04 23:09:32,099] INFO Checking PostgreSql dialect for existence of TABLE "ResultsWeather" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:586)
[2022-12-04 23:09:32,101] INFO Using PostgreSql dialect TABLE "ResultsWeather" absent (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:594)
[2022-12-04 23:09:32,102] INFO Creating table with sql: CREATE TABLE "ResultsWeather" (
"station" TEXT NOT NULL,
"count" BIGINT NOT NULL,
"id" TEXT NOT NULL,
PRIMARY KEY("id")) (io.confluent.connect.jdbc.sink.DbStructure:122)
[2022-12-04 23:09:32,120] INFO Checking PostgreSql dialect for existence of TABLE "ResultsWeather" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:586)
[2022-12-04 23:09:32,121] INFO Using PostgreSql dialect TABLE "ResultsWeather" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:594)
[2022-12-04 23:09:32,127] INFO Checking PostgreSql dialect for type of TABLE "ResultsWeather" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:880)
[2022-12-04 23:09:32,129] INFO Setting metadata for table "ResultsWeather" to Table{name='"ResultsWeather"', type=TABLE columns=[Column{'count', isPrimaryKey=false, allowsNull=false, sqlType=int8}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=text}, Column{'station', isPrimaryKey=false, allowsNull=false, sqlType=text}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2022-12-04 23:09:32,139] WARN Write of 104 records failed, remainingRetries=10 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('LA',5675) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).  Call getNextException to see other errors in the batch.
	at org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2367)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:560)
	at org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:893)
	at org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:916)
	at org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1684)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:196)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:186)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:582)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:330)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:188)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1589)
Caused by: org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2676)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2366)
	... 19 more
[2022-12-04 23:09:32,141] INFO Closing connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:105)
[2022-12-04 23:09:32,141] INFO Initializing writer using SQL dialect: PostgreSqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2022-12-04 23:09:32,142] ERROR WorkerSinkTask{id=sink-results-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:601)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('LA',5675) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).  Call getNextException to see other errors in the batch.
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:582)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:330)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:188)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1589)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('LA',5675) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).  Call getNextException to see other errors in the batch.
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2022-12-04 23:09:35,143] INFO Attempting to open connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:79)
[2022-12-04 23:09:35,154] INFO Maximum table name length for database is 63 bytes (io.confluent.connect.jdbc.dialect.PostgreSqlDatabaseDialect:130)
[2022-12-04 23:09:35,154] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2022-12-04 23:09:35,162] INFO Checking PostgreSql dialect for existence of TABLE "ResultsWeather" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:586)
[2022-12-04 23:09:35,166] INFO Using PostgreSql dialect TABLE "ResultsWeather" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:594)
[2022-12-04 23:09:35,173] INFO Checking PostgreSql dialect for type of TABLE "ResultsWeather" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:880)
[2022-12-04 23:09:35,175] INFO Setting metadata for table "ResultsWeather" to Table{name='"ResultsWeather"', type=TABLE columns=[Column{'count', isPrimaryKey=false, allowsNull=false, sqlType=int8}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=text}, Column{'station', isPrimaryKey=false, allowsNull=false, sqlType=text}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2022-12-04 23:09:35,178] WARN Write of 104 records failed, remainingRetries=9 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('LA',5675) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).  Call getNextException to see other errors in the batch.
	at org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2367)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:560)
	at org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:893)
	at org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:916)
	at org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1684)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:196)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:186)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:582)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:330)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:188)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1589)
Caused by: org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2676)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2366)
	... 19 more
[2022-12-04 23:09:35,179] INFO Closing connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:105)
[2022-12-04 23:09:35,179] INFO Initializing writer using SQL dialect: PostgreSqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2022-12-04 23:09:35,179] ERROR WorkerSinkTask{id=sink-results-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:601)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('LA',5675) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).  Call getNextException to see other errors in the batch.
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:582)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:330)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:188)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1589)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('LA',5675) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).  Call getNextException to see other errors in the batch.
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2022-12-04 23:09:38,181] INFO Attempting to open connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:79)
[2022-12-04 23:09:38,192] INFO Maximum table name length for database is 63 bytes (io.confluent.connect.jdbc.dialect.PostgreSqlDatabaseDialect:130)
[2022-12-04 23:09:38,192] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2022-12-04 23:09:38,199] INFO Checking PostgreSql dialect for existence of TABLE "ResultsWeather" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:586)
[2022-12-04 23:09:38,201] INFO Using PostgreSql dialect TABLE "ResultsWeather" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:594)
[2022-12-04 23:09:38,205] INFO Checking PostgreSql dialect for type of TABLE "ResultsWeather" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:880)
[2022-12-04 23:09:38,206] INFO Setting metadata for table "ResultsWeather" to Table{name='"ResultsWeather"', type=TABLE columns=[Column{'count', isPrimaryKey=false, allowsNull=false, sqlType=int8}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=text}, Column{'station', isPrimaryKey=false, allowsNull=false, sqlType=text}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2022-12-04 23:09:38,211] WARN Write of 104 records failed, remainingRetries=8 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('LA',5675) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).  Call getNextException to see other errors in the batch.
	at org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2367)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:560)
	at org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:893)
	at org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:916)
	at org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1684)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:196)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:186)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:582)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:330)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:188)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1589)
Caused by: org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2676)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2366)
	... 19 more
[2022-12-04 23:09:38,211] INFO Closing connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:105)
[2022-12-04 23:09:38,211] INFO Initializing writer using SQL dialect: PostgreSqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2022-12-04 23:09:38,211] ERROR WorkerSinkTask{id=sink-results-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:601)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('LA',5675) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).  Call getNextException to see other errors in the batch.
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:582)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:330)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:188)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1589)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('LA',5675) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).  Call getNextException to see other errors in the batch.
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2022-12-04 23:09:39,016] INFO Attempting to open connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:79)
[2022-12-04 23:09:39,028] INFO Maximum table name length for database is 63 bytes (io.confluent.connect.jdbc.dialect.PostgreSqlDatabaseDialect:130)
[2022-12-04 23:09:39,028] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2022-12-04 23:09:39,036] INFO Checking PostgreSql dialect for existence of TABLE "ResultsWeather" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:586)
[2022-12-04 23:09:39,039] INFO Using PostgreSql dialect TABLE "ResultsWeather" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:594)
[2022-12-04 23:09:39,046] INFO Checking PostgreSql dialect for type of TABLE "ResultsWeather" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:880)
[2022-12-04 23:09:39,048] INFO Setting metadata for table "ResultsWeather" to Table{name='"ResultsWeather"', type=TABLE columns=[Column{'count', isPrimaryKey=false, allowsNull=false, sqlType=int8}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=text}, Column{'station', isPrimaryKey=false, allowsNull=false, sqlType=text}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2022-12-04 23:09:39,052] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2022-12-04 23:09:39,052] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:327)
[2022-12-04 23:09:39,052] WARN Write of 104 records failed, remainingRetries=7 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('LA',5675) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).  Call getNextException to see other errors in the batch.
	at org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2367)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:560)
	at org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:893)
	at org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:916)
	at org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1684)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:196)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:186)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:582)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:330)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:188)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1589)
Caused by: org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2676)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2366)
	... 19 more
[2022-12-04 23:09:39,053] INFO Closing connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:105)
[2022-12-04 23:09:39,053] INFO Initializing writer using SQL dialect: PostgreSqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2022-12-04 23:09:39,053] ERROR WorkerSinkTask{id=sink-results-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:601)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('LA',5675) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).  Call getNextException to see other errors in the batch.
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:582)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:330)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:188)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1589)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('LA',5675) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).  Call getNextException to see other errors in the batch.
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).
org.postgresql.util.PSQLException: ERROR: null value in column "station" violates not-null constraint
  Detail: Failing row contains (null, 5675, LA).

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2022-12-04 23:09:39,055] INFO Stopped http_8083@66d23e4a{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:381)
[2022-12-04 23:09:39,055] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:149)
[2022-12-04 23:09:39,056] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:344)
[2022-12-04 23:09:39,056] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:102)
[2022-12-04 23:09:39,057] INFO Stopping task source-dbinfo-0 (org.apache.kafka.connect.runtime.Worker:830)
[2022-12-04 23:09:39,121] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 7 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:09:39,130] INFO Stopping JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:354)
[2022-12-04 23:09:39,130] INFO Closing resources for JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:366)
[2022-12-04 23:09:39,130] INFO Closing connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:105)
[2022-12-04 23:09:39,130] INFO [Producer clientId=connector-producer-source-dbinfo-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1204)
[2022-12-04 23:09:39,132] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-04 23:09:39,132] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-04 23:09:39,132] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-04 23:09:39,132] INFO App info kafka.producer for connector-producer-source-dbinfo-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-04 23:09:39,135] INFO Stopping connector source-dbinfo (org.apache.kafka.connect.runtime.Worker:382)
[2022-12-04 23:09:39,135] INFO Scheduled shutdown for WorkerConnector{id=source-dbinfo} (org.apache.kafka.connect.runtime.WorkerConnector:248)
[2022-12-04 23:09:39,135] INFO Stopping table monitoring thread (io.confluent.connect.jdbc.JdbcSourceConnector:200)
[2022-12-04 23:09:39,136] INFO Shutting down thread monitoring tables. (io.confluent.connect.jdbc.source.TableMonitorThread:168)
[2022-12-04 23:09:39,136] INFO Closing connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:105)
[2022-12-04 23:09:39,136] INFO Completed shutdown for WorkerConnector{id=source-dbinfo} (org.apache.kafka.connect.runtime.WorkerConnector:268)
[2022-12-04 23:09:39,136] INFO Stopping task sink-results-0 (org.apache.kafka.connect.runtime.Worker:830)
[2022-12-04 23:09:39,137] INFO Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:161)
[2022-12-04 23:09:39,138] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Revoke previously assigned partitions ResultsLocation-0, ResultsWeather-0, ResultsAlert-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:307)
[2022-12-04 23:09:39,138] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Member connector-consumer-sink-results-0-3579fbbb-a116-413e-b6e6-8d5851a2956c sending LeaveGroup request to coordinator localhost:9092 (id: 2147483646 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:1045)
[2022-12-04 23:09:39,144] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-04 23:09:39,144] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-04 23:09:39,145] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-04 23:09:39,147] INFO App info kafka.consumer for connector-consumer-sink-results-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-04 23:09:39,149] INFO Stopping connector sink-results (org.apache.kafka.connect.runtime.Worker:382)
[2022-12-04 23:09:39,149] INFO Scheduled shutdown for WorkerConnector{id=sink-results} (org.apache.kafka.connect.runtime.WorkerConnector:248)
[2022-12-04 23:09:39,149] INFO Completed shutdown for WorkerConnector{id=sink-results} (org.apache.kafka.connect.runtime.WorkerConnector:268)
[2022-12-04 23:09:39,150] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:205)
[2022-12-04 23:09:39,152] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2022-12-04 23:09:39,152] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-04 23:09:39,152] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-04 23:09:39,152] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-04 23:09:39,153] INFO App info kafka.connect for 192.168.1.123:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-04 23:09:39,153] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:226)
[2022-12-04 23:09:39,155] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:120)
[2022-12-04 23:09:39,155] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2022-12-04 23:12:10,848] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:68)
[2022-12-04 23:12:10,852] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Private Build, OpenJDK 64-Bit Server VM, 19.0.1, 19.0.1+10-Ubuntu-1ubuntu122.04
	jvm.classpath = /home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/activation-1.1.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/argparse4j-0.7.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/audience-annotations-0.5.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/commons-cli-1.4.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/commons-lang3-3.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-api-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-basic-auth-extension-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-file-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-json-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-mirror-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-mirror-client-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-runtime-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-transforms-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/hk2-api-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/hk2-locator-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/hk2-utils-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-annotations-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-core-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-databind-2.10.5.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-module-paranamer-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.inject-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/javassist-3.27.0-GA.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/javax.servlet-api-3.1.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jaxb-api-2.3.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-client-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-common-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-container-servlet-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-hk2-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-server-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jline-3.12.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jopt-simple-5.0.4.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka_2.13-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka_2.13-2.8.1-sources.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-clients-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-connect-jdbc-10.6.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-log4j-appender-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-metadata-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-raft-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-shell-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-streams-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-streams-examples-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-streams-scala_2.13-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-streams-test-utils-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-tools-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/log4j-1.2.17.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/lz4-java-1.7.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/maven-artifact-3.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/metrics-core-2.2.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-buffer-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-codec-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-common-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-handler-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-resolver-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-transport-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-transport-native-epoll-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-transport-native-unix-common-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/paranamer-2.8.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/plexus-utils-3.2.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/postgresql-42.5.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/reflections-0.9.12.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/rocksdbjni-5.18.4.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-collection-compat_2.13-2.3.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-library-2.13.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-logging_2.13-3.9.2.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-reflect-2.13.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/slf4j-api-1.7.30.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/snappy-java-1.1.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/zookeeper-3.5.9.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/zookeeper-jute-3.5.9.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/zstd-jni-1.4.9-1.jar
	os.spec = Linux, amd64, 6.0.0-1006-oem
	os.vcpus = 20
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2022-12-04 23:12:10,853] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:77)
[2022-12-04 23:12:11,465] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@251a69d7 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:269)
[2022-12-04 23:12:11,465] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,465] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,465] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,465] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,465] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,465] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,465] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,465] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,466] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,466] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,466] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,466] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,466] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,466] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,467] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,467] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,467] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,467] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,468] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,468] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,468] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,468] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,468] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,469] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,469] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,469] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,469] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,469] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,469] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,469] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,469] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,469] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,469] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,469] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,469] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,469] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,469] INFO Added plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,470] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,470] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,470] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,470] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,470] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,470] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,470] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,470] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,470] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,470] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,470] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,470] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,470] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,470] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,471] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,471] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:12:11,474] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:12:11,474] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:12:11,474] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:12:11,474] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:12:11,474] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:12:11,474] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:12:11,474] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:12:11,474] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:12:11,474] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:12:11,474] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:12:11,475] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:12:11,475] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:12:11,475] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:12:11,475] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:12:11,475] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:12:11,475] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:12:11,475] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:12:11,475] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:12:11,475] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:12:11,475] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:12:11,475] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:12:11,475] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:12:11,475] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:12:11,475] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:12:11,475] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:12:11,475] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:12:11,475] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:12:11,476] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:12:11,476] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:12:11,476] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:12:11,476] INFO Added aliases 'PredicatedTransformation' and 'Predicated' to plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:12:11,476] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:12:11,476] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:12:11,476] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:12:11,476] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:12:11,476] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:12:11,476] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:12:11,476] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:12:11,476] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:12:11,476] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:12:11,476] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:12:11,476] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:12:11,488] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = null
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:372)
[2022-12-04 23:12:11,488] WARN Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results. (org.apache.kafka.connect.runtime.WorkerConfig:420)
[2022-12-04 23:12:11,489] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:49)
[2022-12-04 23:12:11,491] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2022-12-04 23:12:11,529] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:12:11,529] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:12:11,529] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:12:11,529] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:12:11,529] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:12:11,529] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:12:11,529] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:12:11,529] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:12:11,529] INFO Kafka startTimeMs: 1670195531529 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:12:11,660] INFO Kafka cluster ID: uYYJbbgfRseD3C81aqQl8w (org.apache.kafka.connect.util.ConnectUtils:65)
[2022-12-04 23:12:11,660] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-04 23:12:11,663] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-04 23:12:11,663] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-04 23:12:11,663] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-04 23:12:11,669] INFO Logging initialized @1022ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2022-12-04 23:12:11,687] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:132)
[2022-12-04 23:12:11,687] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:204)
[2022-12-04 23:12:11,691] INFO jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 19.0.1+10-Ubuntu-1ubuntu122.04 (org.eclipse.jetty.server.Server:375)
[2022-12-04 23:12:11,704] INFO Started http_8083@66d23e4a{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:331)
[2022-12-04 23:12:11,704] INFO Started @1057ms (org.eclipse.jetty.server.Server:415)
[2022-12-04 23:12:11,713] INFO Advertised URI: http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:371)
[2022-12-04 23:12:11,713] INFO REST server listening at http://192.168.1.123:8083/, advertising URL http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2022-12-04 23:12:11,713] INFO Advertised URI: http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:371)
[2022-12-04 23:12:11,714] INFO REST admin endpoints at http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:220)
[2022-12-04 23:12:11,714] INFO Advertised URI: http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:371)
[2022-12-04 23:12:11,715] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2022-12-04 23:12:11,718] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:49)
[2022-12-04 23:12:11,719] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2022-12-04 23:12:11,721] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:12:11,721] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:12:11,721] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:12:11,721] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:12:11,722] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:12:11,722] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:12:11,722] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:12:11,722] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:12:11,722] INFO Kafka startTimeMs: 1670195531722 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:12:11,729] INFO Kafka cluster ID: uYYJbbgfRseD3C81aqQl8w (org.apache.kafka.connect.util.ConnectUtils:65)
[2022-12-04 23:12:11,730] INFO App info kafka.admin.client for adminclient-2 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-04 23:12:11,731] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-04 23:12:11,732] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-04 23:12:11,732] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-04 23:12:11,733] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:12:11,733] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:12:11,733] INFO Kafka startTimeMs: 1670195531733 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:12:11,777] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-04 23:12:11,778] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-04 23:12:11,782] INFO Kafka Connect standalone worker initialization took 932ms (org.apache.kafka.connect.cli.ConnectStandalone:99)
[2022-12-04 23:12:11,782] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2022-12-04 23:12:11,782] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:94)
[2022-12-04 23:12:11,782] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:191)
[2022-12-04 23:12:11,782] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2022-12-04 23:12:11,787] INFO Worker started (org.apache.kafka.connect.runtime.Worker:198)
[2022-12-04 23:12:11,787] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:97)
[2022-12-04 23:12:11,787] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:224)
[2022-12-04 23:12:11,805] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:241)
[2022-12-04 23:12:11,837] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2022-12-04 23:12:11,837] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2022-12-04 23:12:11,838] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session:132)
[2022-12-04 23:12:12,022] INFO Started o.e.j.s.ServletContextHandler@3be4f71{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:915)
[2022-12-04 23:12:12,022] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:319)
[2022-12-04 23:12:12,022] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2022-12-04 23:12:12,035] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2022-12-04 23:12:12,041] INFO Creating connector sink-results of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:271)
[2022-12-04 23:12:12,042] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2022-12-04 23:12:12,043] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:12:12,045] INFO Instantiated connector sink-results with version 10.6.0 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:281)
[2022-12-04 23:12:12,045] INFO Finished creating connector sink-results (org.apache.kafka.connect.runtime.Worker:306)
[2022-12-04 23:12:12,047] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2022-12-04 23:12:12,048] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:12:12,048] INFO Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:51)
[2022-12-04 23:12:12,048] INFO Creating task sink-results-0 (org.apache.kafka.connect.runtime.Worker:505)
[2022-12-04 23:12:12,050] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2022-12-04 23:12:12,050] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:12:12,050] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2022-12-04 23:12:12,050] INFO Instantiated task sink-results-0 with version 10.6.0 of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:520)
[2022-12-04 23:12:12,051] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:372)
[2022-12-04 23:12:12,051] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-04 23:12:12,051] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task sink-results-0 using the connector config (org.apache.kafka.connect.runtime.Worker:535)
[2022-12-04 23:12:12,051] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task sink-results-0 using the connector config (org.apache.kafka.connect.runtime.Worker:541)
[2022-12-04 23:12:12,051] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task sink-results-0 using the worker config (org.apache.kafka.connect.runtime.Worker:546)
[2022-12-04 23:12:12,053] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:626)
[2022-12-04 23:12:12,053] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2022-12-04 23:12:12,054] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:12:12,059] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-sink-results-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-sink-results
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2022-12-04 23:12:12,076] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-04 23:12:12,076] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:12:12,076] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:12:12,077] INFO Kafka startTimeMs: 1670195532076 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:12:12,082] INFO Created connector sink-results (org.apache.kafka.connect.cli.ConnectStandalone:109)
[2022-12-04 23:12:12,082] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Subscribed to topic(s): ResultsWeather, ResultsAlert, ResultsLocation (org.apache.kafka.clients.consumer.KafkaConsumer:965)
[2022-12-04 23:12:12,082] INFO Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:48)
[2022-12-04 23:12:12,083] INFO JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:postgresql://localhost:5432/kafka
	connection.user = postgres
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = upsert
	max.retries = 10
	pk.fields = [id]
	pk.mode = record_key
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:372)
[2022-12-04 23:12:12,084] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:postgresql://localhost:5432/kafka
	connection.user = postgres
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = SELECT * FROM stations;
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = DBInfo
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:372)
[2022-12-04 23:12:12,085] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2022-12-04 23:12:12,085] INFO Creating connector source-dbinfo of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:271)
[2022-12-04 23:12:12,085] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2022-12-04 23:12:12,085] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:12:12,085] INFO Initializing writer using SQL dialect: PostgreSqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2022-12-04 23:12:12,086] INFO WorkerSinkTask{id=sink-results-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:310)
[2022-12-04 23:12:12,086] INFO WorkerSinkTask{id=sink-results-0} Executing sink task (org.apache.kafka.connect.runtime.WorkerSinkTask:196)
[2022-12-04 23:12:12,086] INFO Instantiated connector source-dbinfo with version 10.6.0 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:281)
[2022-12-04 23:12:12,086] INFO Finished creating connector source-dbinfo (org.apache.kafka.connect.runtime.Worker:306)
[2022-12-04 23:12:12,087] INFO Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:71)
[2022-12-04 23:12:12,087] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:postgresql://localhost:5432/kafka
	connection.user = postgres
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = SELECT * FROM stations;
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = DBInfo
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:372)
[2022-12-04 23:12:12,087] INFO Attempting to open connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:79)
[2022-12-04 23:12:12,094] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Cluster ID: uYYJbbgfRseD3C81aqQl8w (org.apache.kafka.clients.Metadata:279)
[2022-12-04 23:12:12,095] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Discovered group coordinator localhost:9092 (id: 2147483646 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:850)
[2022-12-04 23:12:12,097] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2022-12-04 23:12:12,103] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2022-12-04 23:12:12,137] INFO Maximum table name length for database is 63 bytes (io.confluent.connect.jdbc.dialect.PostgreSqlDatabaseDialect:130)
[2022-12-04 23:12:12,139] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2022-12-04 23:12:12,139] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:12:12,140] INFO Creating task source-dbinfo-0 (org.apache.kafka.connect.runtime.Worker:505)
[2022-12-04 23:12:12,140] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2022-12-04 23:12:12,140] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:12:12,141] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.source.JdbcSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2022-12-04 23:12:12,141] INFO Instantiated task source-dbinfo-0 with version 10.6.0 of type io.confluent.connect.jdbc.source.JdbcSourceTask (org.apache.kafka.connect.runtime.Worker:520)
[2022-12-04 23:12:12,141] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-04 23:12:12,141] INFO Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task source-dbinfo-0 using the worker config (org.apache.kafka.connect.runtime.Worker:533)
[2022-12-04 23:12:12,142] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-04 23:12:12,142] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task source-dbinfo-0 using the worker config (org.apache.kafka.connect.runtime.Worker:539)
[2022-12-04 23:12:12,142] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task source-dbinfo-0 using the worker config (org.apache.kafka.connect.runtime.Worker:546)
[2022-12-04 23:12:12,142] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2022-12-04 23:12:12,142] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:12:12,142] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:600)
[2022-12-04 23:12:12,144] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-source-dbinfo-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2022-12-04 23:12:12,152] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-04 23:12:12,152] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:12:12,153] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:12:12,153] INFO Kafka startTimeMs: 1670195532152 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:12:12,155] INFO Starting JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:92)
[2022-12-04 23:12:12,155] INFO Created connector source-dbinfo (org.apache.kafka.connect.cli.ConnectStandalone:109)
[2022-12-04 23:12:12,155] INFO JdbcSourceTaskConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:postgresql://localhost:5432/kafka
	connection.user = postgres
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = SELECT * FROM stations;
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	tables = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = DBInfo
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceTaskConfig:372)
[2022-12-04 23:12:12,155] INFO [Producer clientId=connector-producer-source-dbinfo-0] Cluster ID: uYYJbbgfRseD3C81aqQl8w (org.apache.kafka.clients.Metadata:279)
[2022-12-04 23:12:12,155] INFO Using JDBC dialect PostgreSql (io.confluent.connect.jdbc.source.JdbcSourceTask:127)
[2022-12-04 23:12:12,156] INFO Attempting to open connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:79)
[2022-12-04 23:12:12,161] INFO Maximum table name length for database is 63 bytes (io.confluent.connect.jdbc.dialect.PostgreSqlDatabaseDialect:130)
[2022-12-04 23:12:12,162] INFO Started JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:296)
[2022-12-04 23:12:12,162] INFO WorkerSourceTask{id=source-dbinfo-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:232)
[2022-12-04 23:12:12,163] INFO WorkerSourceTask{id=source-dbinfo-0} Executing source task (org.apache.kafka.connect.runtime.WorkerSourceTask:238)
[2022-12-04 23:12:12,169] INFO Begin using SQL query: SELECT * FROM stations; (io.confluent.connect.jdbc.source.TableQuerier:181)
[2022-12-04 23:12:15,107] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Successfully joined group with generation Generation{generationId=1, memberId='connector-consumer-sink-results-0-4c5ef23a-45b4-491d-b845-63e3bea063be', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2022-12-04 23:12:15,109] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Finished assignment for group at generation 1: {connector-consumer-sink-results-0-4c5ef23a-45b4-491d-b845-63e3bea063be=Assignment(partitions=[ResultsLocation-0, ResultsWeather-0, ResultsAlert-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:626)
[2022-12-04 23:12:15,115] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Successfully synced group in generation Generation{generationId=1, memberId='connector-consumer-sink-results-0-4c5ef23a-45b4-491d-b845-63e3bea063be', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:760)
[2022-12-04 23:12:15,115] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Notifying assignor about the new Assignment(partitions=[ResultsLocation-0, ResultsWeather-0, ResultsAlert-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:276)
[2022-12-04 23:12:15,117] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Adding newly assigned partitions: ResultsLocation-0, ResultsWeather-0, ResultsAlert-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:288)
[2022-12-04 23:12:15,122] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Found no committed offset for partition ResultsLocation-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1362)
[2022-12-04 23:12:15,122] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Found no committed offset for partition ResultsWeather-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1362)
[2022-12-04 23:12:15,122] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Found no committed offset for partition ResultsAlert-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1362)
[2022-12-04 23:12:15,126] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Resetting offset for partition ResultsLocation-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: r1)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-04 23:12:15,126] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Resetting offset for partition ResultsWeather-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: r1)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-04 23:12:15,126] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Resetting offset for partition ResultsAlert-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: r1)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-04 23:12:15,139] INFO Attempting to open connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:79)
[2022-12-04 23:12:15,145] INFO Maximum table name length for database is 63 bytes (io.confluent.connect.jdbc.dialect.PostgreSqlDatabaseDialect:130)
[2022-12-04 23:12:15,146] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2022-12-04 23:12:15,154] INFO Checking PostgreSql dialect for existence of TABLE "ResultsWeather" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:586)
[2022-12-04 23:12:15,157] INFO Using PostgreSql dialect TABLE "ResultsWeather" absent (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:594)
[2022-12-04 23:12:15,158] INFO Creating table with sql: CREATE TABLE "ResultsWeather" (
"id" TEXT NOT NULL,
"count" BIGINT NOT NULL,
PRIMARY KEY("id")) (io.confluent.connect.jdbc.sink.DbStructure:122)
[2022-12-04 23:12:15,185] INFO Checking PostgreSql dialect for existence of TABLE "ResultsWeather" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:586)
[2022-12-04 23:12:15,187] INFO Using PostgreSql dialect TABLE "ResultsWeather" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:594)
[2022-12-04 23:12:15,194] INFO Checking PostgreSql dialect for type of TABLE "ResultsWeather" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:880)
[2022-12-04 23:12:15,196] INFO Setting metadata for table "ResultsWeather" to Table{name='"ResultsWeather"', type=TABLE columns=[Column{'count', isPrimaryKey=false, allowsNull=false, sqlType=int8}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=text}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2022-12-04 23:12:22,155] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:12:32,163] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:12:33,943] WARN Write of 6 records failed, remainingRetries=10 (io.confluent.connect.jdbc.sink.JdbcSinkTask:92)
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('C',6452) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: relation "ResultsWeather" does not exist
  Position: 13  Call getNextException to see other errors in the batch.
	at org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
	at org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2367)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:560)
	at org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:893)
	at org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:916)
	at org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1684)
	at io.confluent.connect.jdbc.sink.BufferedRecords.executeUpdates(BufferedRecords.java:196)
	at io.confluent.connect.jdbc.sink.BufferedRecords.flush(BufferedRecords.java:186)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:80)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:84)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:582)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:330)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:188)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1589)
Caused by: org.postgresql.util.PSQLException: ERROR: relation "ResultsWeather" does not exist
  Position: 13
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2676)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2366)
	... 19 more
[2022-12-04 23:12:33,945] INFO Closing connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:105)
[2022-12-04 23:12:33,945] INFO Initializing writer using SQL dialect: PostgreSqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2022-12-04 23:12:33,945] ERROR WorkerSinkTask{id=sink-results-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:601)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('C',6452) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: relation "ResultsWeather" does not exist
  Position: 13  Call getNextException to see other errors in the batch.
org.postgresql.util.PSQLException: ERROR: relation "ResultsWeather" does not exist
  Position: 13
org.postgresql.util.PSQLException: ERROR: relation "ResultsWeather" does not exist
  Position: 13

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:582)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:330)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:232)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:201)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:188)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1589)
Caused by: java.sql.SQLException: Exception chain:
java.sql.BatchUpdateException: Batch entry 0 INSERT INTO "ResultsWeather" ("id","count") VALUES ('C',6452) ON CONFLICT ("id") DO UPDATE SET "count"=EXCLUDED."count" was aborted: ERROR: relation "ResultsWeather" does not exist
  Position: 13  Call getNextException to see other errors in the batch.
org.postgresql.util.PSQLException: ERROR: relation "ResultsWeather" does not exist
  Position: 13
org.postgresql.util.PSQLException: ERROR: relation "ResultsWeather" does not exist
  Position: 13

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:150)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:102)
	... 11 more
[2022-12-04 23:12:36,947] INFO Attempting to open connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:79)
[2022-12-04 23:12:36,959] INFO Maximum table name length for database is 63 bytes (io.confluent.connect.jdbc.dialect.PostgreSqlDatabaseDialect:130)
[2022-12-04 23:12:36,959] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2022-12-04 23:12:36,967] INFO Checking PostgreSql dialect for existence of TABLE "ResultsWeather" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:586)
[2022-12-04 23:12:36,971] INFO Using PostgreSql dialect TABLE "ResultsWeather" absent (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:594)
[2022-12-04 23:12:36,971] INFO Creating table with sql: CREATE TABLE "ResultsWeather" (
"id" TEXT NOT NULL,
"count" BIGINT NOT NULL,
PRIMARY KEY("id")) (io.confluent.connect.jdbc.sink.DbStructure:122)
[2022-12-04 23:12:36,990] INFO Checking PostgreSql dialect for existence of TABLE "ResultsWeather" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:586)
[2022-12-04 23:12:36,994] INFO Using PostgreSql dialect TABLE "ResultsWeather" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:594)
[2022-12-04 23:12:37,002] INFO Checking PostgreSql dialect for type of TABLE "ResultsWeather" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:880)
[2022-12-04 23:12:37,005] INFO Setting metadata for table "ResultsWeather" to Table{name='"ResultsWeather"', type=TABLE columns=[Column{'count', isPrimaryKey=false, allowsNull=false, sqlType=int8}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=text}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2022-12-04 23:12:42,165] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:12:52,168] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:13:02,171] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:13:12,174] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:13:22,177] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:13:32,179] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:13:42,183] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:13:52,185] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:14:02,187] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:14:12,189] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:14:22,190] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:14:32,192] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:14:42,194] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:14:52,196] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:15:02,199] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:15:12,201] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:15:22,204] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:15:32,207] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:15:42,211] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:15:52,214] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:16:02,217] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:16:12,219] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:16:22,222] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:16:32,224] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:16:42,227] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:16:52,231] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:17:02,233] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:17:12,236] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:17:22,239] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:17:32,241] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:17:42,245] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:17:52,248] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:18:02,251] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:18:12,253] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:18:22,256] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:18:32,258] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:18:42,260] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:18:52,262] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:19:02,265] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:19:12,267] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:19:22,269] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:19:32,271] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:19:42,274] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:19:52,276] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:20:02,278] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:20:12,280] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:20:22,281] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:20:32,283] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:20:42,285] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:20:52,288] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:21:02,291] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:21:12,293] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:21:22,295] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:21:32,298] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:21:42,300] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:21:52,302] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:22:02,305] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:22:12,307] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:22:22,309] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:22:32,311] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:22:42,313] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:22:52,315] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:23:02,317] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:23:12,319] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:23:22,322] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:23:32,325] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:23:42,327] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:23:52,329] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:24:02,331] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:24:12,334] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:24:22,336] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:24:32,338] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:24:42,339] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:24:52,341] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:25:02,343] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:25:12,345] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:25:22,346] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:25:32,348] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:25:42,352] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:25:52,354] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:26:02,357] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:26:12,359] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:26:22,361] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:26:32,363] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:26:42,365] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:26:52,368] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:27:02,370] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:27:12,371] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:27:22,374] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:27:32,377] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:27:42,379] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:27:52,381] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:28:02,382] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:28:12,385] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:28:22,386] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:28:32,389] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:28:42,391] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:28:52,392] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:29:02,394] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:29:12,397] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:29:22,399] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:29:32,401] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:29:42,404] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:29:52,407] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:30:02,410] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:30:12,413] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:30:22,416] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:30:32,418] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:30:42,419] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:30:52,421] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:31:02,424] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:31:12,426] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:31:18,285] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2022-12-04 23:31:18,285] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:327)
[2022-12-04 23:31:18,289] INFO Stopped http_8083@66d23e4a{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:381)
[2022-12-04 23:31:18,289] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:149)
[2022-12-04 23:31:18,291] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:344)
[2022-12-04 23:31:18,291] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:102)
[2022-12-04 23:31:18,291] INFO Stopping task source-dbinfo-0 (org.apache.kafka.connect.runtime.Worker:830)
[2022-12-04 23:31:22,852] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 6 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:31:22,855] INFO Stopping JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:354)
[2022-12-04 23:31:22,855] INFO Closing resources for JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:366)
[2022-12-04 23:31:22,855] INFO Closing connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:105)
[2022-12-04 23:31:22,856] INFO [Producer clientId=connector-producer-source-dbinfo-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1204)
[2022-12-04 23:31:22,858] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-04 23:31:22,858] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-04 23:31:22,858] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-04 23:31:22,858] INFO App info kafka.producer for connector-producer-source-dbinfo-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-04 23:31:22,861] INFO Stopping connector source-dbinfo (org.apache.kafka.connect.runtime.Worker:382)
[2022-12-04 23:31:22,861] INFO Scheduled shutdown for WorkerConnector{id=source-dbinfo} (org.apache.kafka.connect.runtime.WorkerConnector:248)
[2022-12-04 23:31:22,861] INFO Stopping table monitoring thread (io.confluent.connect.jdbc.JdbcSourceConnector:200)
[2022-12-04 23:31:22,861] INFO Shutting down thread monitoring tables. (io.confluent.connect.jdbc.source.TableMonitorThread:168)
[2022-12-04 23:31:22,861] INFO Closing connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:105)
[2022-12-04 23:31:22,862] INFO Completed shutdown for WorkerConnector{id=source-dbinfo} (org.apache.kafka.connect.runtime.WorkerConnector:268)
[2022-12-04 23:31:22,862] INFO Stopping task sink-results-0 (org.apache.kafka.connect.runtime.Worker:830)
[2022-12-04 23:31:22,862] INFO Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:161)
[2022-12-04 23:31:22,863] INFO Closing connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:105)
[2022-12-04 23:31:22,863] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Revoke previously assigned partitions ResultsLocation-0, ResultsWeather-0, ResultsAlert-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:307)
[2022-12-04 23:31:22,863] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Member connector-consumer-sink-results-0-4c5ef23a-45b4-491d-b845-63e3bea063be sending LeaveGroup request to coordinator localhost:9092 (id: 2147483646 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:1045)
[2022-12-04 23:31:22,866] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-04 23:31:22,866] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-04 23:31:22,866] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-04 23:31:22,867] INFO App info kafka.consumer for connector-consumer-sink-results-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-04 23:31:22,868] INFO Stopping connector sink-results (org.apache.kafka.connect.runtime.Worker:382)
[2022-12-04 23:31:22,869] INFO Scheduled shutdown for WorkerConnector{id=sink-results} (org.apache.kafka.connect.runtime.WorkerConnector:248)
[2022-12-04 23:31:22,869] INFO Completed shutdown for WorkerConnector{id=sink-results} (org.apache.kafka.connect.runtime.WorkerConnector:268)
[2022-12-04 23:31:22,869] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:205)
[2022-12-04 23:31:22,870] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2022-12-04 23:31:22,870] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-04 23:31:22,870] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-04 23:31:22,870] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-04 23:31:22,870] INFO App info kafka.connect for 192.168.1.123:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-04 23:31:22,870] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:226)
[2022-12-04 23:31:22,871] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:120)
[2022-12-04 23:31:22,871] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2022-12-04 23:32:16,473] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:68)
[2022-12-04 23:32:16,477] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Private Build, OpenJDK 64-Bit Server VM, 19.0.1, 19.0.1+10-Ubuntu-1ubuntu122.04
	jvm.classpath = /home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/activation-1.1.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/argparse4j-0.7.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/audience-annotations-0.5.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/commons-cli-1.4.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/commons-lang3-3.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-api-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-basic-auth-extension-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-file-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-json-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-mirror-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-mirror-client-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-runtime-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-transforms-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/hk2-api-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/hk2-locator-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/hk2-utils-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-annotations-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-core-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-databind-2.10.5.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-module-paranamer-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.inject-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/javassist-3.27.0-GA.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/javax.servlet-api-3.1.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jaxb-api-2.3.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-client-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-common-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-container-servlet-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-hk2-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-server-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jline-3.12.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jopt-simple-5.0.4.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka_2.13-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka_2.13-2.8.1-sources.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-clients-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-connect-jdbc-10.6.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-log4j-appender-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-metadata-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-raft-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-shell-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-streams-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-streams-examples-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-streams-scala_2.13-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-streams-test-utils-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-tools-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/log4j-1.2.17.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/lz4-java-1.7.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/maven-artifact-3.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/metrics-core-2.2.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-buffer-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-codec-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-common-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-handler-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-resolver-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-transport-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-transport-native-epoll-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-transport-native-unix-common-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/paranamer-2.8.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/plexus-utils-3.2.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/postgresql-42.5.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/reflections-0.9.12.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/rocksdbjni-5.18.4.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-collection-compat_2.13-2.3.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-library-2.13.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-logging_2.13-3.9.2.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-reflect-2.13.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/slf4j-api-1.7.30.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/snappy-java-1.1.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/zookeeper-3.5.9.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/zookeeper-jute-3.5.9.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/zstd-jni-1.4.9-1.jar
	os.spec = Linux, amd64, 6.0.0-1006-oem
	os.vcpus = 20
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2022-12-04 23:32:16,477] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:77)
[2022-12-04 23:32:17,252] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@251a69d7 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:269)
[2022-12-04 23:32:17,252] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,252] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,252] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,253] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,253] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,253] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,253] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,253] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,253] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,253] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,253] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,253] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,254] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,254] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,254] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,254] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,254] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,254] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,255] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,255] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,255] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,255] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,255] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,255] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,255] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,255] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,255] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,255] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,255] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,255] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,255] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,256] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,256] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,256] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,256] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,256] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,256] INFO Added plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,256] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,256] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,256] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,256] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,256] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,256] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,256] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,256] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,257] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,257] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,257] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,257] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,257] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,257] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,257] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,257] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:17,259] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:17,259] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:17,259] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:17,259] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:17,259] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:17,260] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:17,260] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:17,260] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:17,260] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:17,260] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:17,260] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:17,260] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:17,260] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:17,260] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:17,260] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:17,260] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:17,260] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:17,260] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:17,260] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:17,261] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:17,261] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:17,261] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:17,261] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:17,261] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:17,261] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:17,261] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:17,261] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:17,261] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:17,261] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:32:17,261] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:17,261] INFO Added aliases 'PredicatedTransformation' and 'Predicated' to plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:17,261] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:32:17,261] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:32:17,261] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:32:17,261] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:32:17,261] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:32:17,262] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:32:17,262] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:32:17,262] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:32:17,262] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:17,262] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:17,262] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:17,270] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = null
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:372)
[2022-12-04 23:32:17,270] WARN Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results. (org.apache.kafka.connect.runtime.WorkerConfig:420)
[2022-12-04 23:32:17,271] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:49)
[2022-12-04 23:32:17,272] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2022-12-04 23:32:17,302] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:32:17,302] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:32:17,302] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:32:17,302] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:32:17,302] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:32:17,302] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:32:17,302] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:32:17,303] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:32:17,303] INFO Kafka startTimeMs: 1670196737302 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:32:17,423] INFO Kafka cluster ID: uYYJbbgfRseD3C81aqQl8w (org.apache.kafka.connect.util.ConnectUtils:65)
[2022-12-04 23:32:17,423] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-04 23:32:17,426] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-04 23:32:17,426] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-04 23:32:17,426] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-04 23:32:17,432] INFO Logging initialized @1164ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2022-12-04 23:32:17,447] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:132)
[2022-12-04 23:32:17,448] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:204)
[2022-12-04 23:32:17,450] INFO jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 19.0.1+10-Ubuntu-1ubuntu122.04 (org.eclipse.jetty.server.Server:375)
[2022-12-04 23:32:17,463] INFO Started http_8083@344561e0{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:331)
[2022-12-04 23:32:17,464] INFO Started @1197ms (org.eclipse.jetty.server.Server:415)
[2022-12-04 23:32:17,472] INFO Advertised URI: http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:371)
[2022-12-04 23:32:17,472] INFO REST server listening at http://192.168.1.123:8083/, advertising URL http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2022-12-04 23:32:17,473] INFO Advertised URI: http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:371)
[2022-12-04 23:32:17,473] INFO REST admin endpoints at http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:220)
[2022-12-04 23:32:17,473] INFO Advertised URI: http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:371)
[2022-12-04 23:32:17,474] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2022-12-04 23:32:17,477] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:49)
[2022-12-04 23:32:17,478] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2022-12-04 23:32:17,480] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:32:17,480] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:32:17,480] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:32:17,480] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:32:17,480] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:32:17,480] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:32:17,480] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:32:17,480] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:32:17,480] INFO Kafka startTimeMs: 1670196737480 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:32:17,487] INFO Kafka cluster ID: uYYJbbgfRseD3C81aqQl8w (org.apache.kafka.connect.util.ConnectUtils:65)
[2022-12-04 23:32:17,488] INFO App info kafka.admin.client for adminclient-2 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-04 23:32:17,490] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-04 23:32:17,490] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-04 23:32:17,490] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-04 23:32:17,493] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:32:17,493] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:32:17,493] INFO Kafka startTimeMs: 1670196737493 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:32:17,535] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-04 23:32:17,536] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-04 23:32:17,539] INFO Kafka Connect standalone worker initialization took 1065ms (org.apache.kafka.connect.cli.ConnectStandalone:99)
[2022-12-04 23:32:17,539] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2022-12-04 23:32:17,539] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:94)
[2022-12-04 23:32:17,539] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:191)
[2022-12-04 23:32:17,540] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2022-12-04 23:32:17,543] INFO Worker started (org.apache.kafka.connect.runtime.Worker:198)
[2022-12-04 23:32:17,543] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:97)
[2022-12-04 23:32:17,543] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:224)
[2022-12-04 23:32:17,561] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:241)
[2022-12-04 23:32:17,593] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2022-12-04 23:32:17,593] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2022-12-04 23:32:17,593] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session:132)
[2022-12-04 23:32:17,772] INFO Started o.e.j.s.ServletContextHandler@26ae880a{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:915)
[2022-12-04 23:32:17,772] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:319)
[2022-12-04 23:32:17,772] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2022-12-04 23:32:17,789] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2022-12-04 23:32:17,793] INFO Creating connector sink-results of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:271)
[2022-12-04 23:32:17,794] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2022-12-04 23:32:17,794] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:32:17,795] INFO Instantiated connector sink-results with version 10.6.0 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:281)
[2022-12-04 23:32:17,796] INFO Finished creating connector sink-results (org.apache.kafka.connect.runtime.Worker:306)
[2022-12-04 23:32:17,797] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2022-12-04 23:32:17,798] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:32:17,798] INFO Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:51)
[2022-12-04 23:32:17,798] INFO Creating task sink-results-0 (org.apache.kafka.connect.runtime.Worker:505)
[2022-12-04 23:32:17,799] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2022-12-04 23:32:17,799] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:32:17,800] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2022-12-04 23:32:17,800] INFO Instantiated task sink-results-0 with version 10.6.0 of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:520)
[2022-12-04 23:32:17,800] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:372)
[2022-12-04 23:32:17,801] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-04 23:32:17,801] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task sink-results-0 using the connector config (org.apache.kafka.connect.runtime.Worker:535)
[2022-12-04 23:32:17,801] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task sink-results-0 using the connector config (org.apache.kafka.connect.runtime.Worker:541)
[2022-12-04 23:32:17,801] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task sink-results-0 using the worker config (org.apache.kafka.connect.runtime.Worker:546)
[2022-12-04 23:32:17,802] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:626)
[2022-12-04 23:32:17,802] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2022-12-04 23:32:17,803] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:32:17,806] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-sink-results-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-sink-results
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2022-12-04 23:32:17,824] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-04 23:32:17,824] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:32:17,825] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:32:17,825] INFO Kafka startTimeMs: 1670196737824 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:32:17,829] INFO Created connector sink-results (org.apache.kafka.connect.cli.ConnectStandalone:109)
[2022-12-04 23:32:17,830] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Subscribed to topic(s): ResultsWeather, ResultsAlert, ResultsLocation (org.apache.kafka.clients.consumer.KafkaConsumer:965)
[2022-12-04 23:32:17,830] INFO Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:48)
[2022-12-04 23:32:17,830] INFO JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:postgresql://localhost:5432/kafka
	connection.user = postgres
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = upsert
	max.retries = 10
	pk.fields = [id]
	pk.mode = record_key
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:372)
[2022-12-04 23:32:17,831] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:postgresql://localhost:5432/kafka
	connection.user = postgres
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = SELECT * FROM stations;
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = DBInfo
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:372)
[2022-12-04 23:32:17,831] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2022-12-04 23:32:17,832] INFO Creating connector source-dbinfo of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:271)
[2022-12-04 23:32:17,832] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2022-12-04 23:32:17,832] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:32:17,832] INFO Initializing writer using SQL dialect: PostgreSqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2022-12-04 23:32:17,833] INFO Instantiated connector source-dbinfo with version 10.6.0 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:281)
[2022-12-04 23:32:17,833] INFO Finished creating connector source-dbinfo (org.apache.kafka.connect.runtime.Worker:306)
[2022-12-04 23:32:17,833] INFO WorkerSinkTask{id=sink-results-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:310)
[2022-12-04 23:32:17,833] INFO Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:71)
[2022-12-04 23:32:17,833] INFO WorkerSinkTask{id=sink-results-0} Executing sink task (org.apache.kafka.connect.runtime.WorkerSinkTask:196)
[2022-12-04 23:32:17,833] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:postgresql://localhost:5432/kafka
	connection.user = postgres
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = SELECT * FROM stations;
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = DBInfo
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:372)
[2022-12-04 23:32:17,833] INFO Attempting to open connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:79)
[2022-12-04 23:32:17,865] WARN [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Error while fetching metadata with correlation id 2 : {ResultsWeather=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1100)
[2022-12-04 23:32:17,866] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Cluster ID: uYYJbbgfRseD3C81aqQl8w (org.apache.kafka.clients.Metadata:279)
[2022-12-04 23:32:17,867] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Discovered group coordinator localhost:9092 (id: 2147483646 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:850)
[2022-12-04 23:32:17,868] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2022-12-04 23:32:17,880] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2022-12-04 23:32:17,893] INFO Maximum table name length for database is 63 bytes (io.confluent.connect.jdbc.dialect.PostgreSqlDatabaseDialect:130)
[2022-12-04 23:32:17,894] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2022-12-04 23:32:17,894] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:32:17,896] INFO Creating task source-dbinfo-0 (org.apache.kafka.connect.runtime.Worker:505)
[2022-12-04 23:32:17,896] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2022-12-04 23:32:17,896] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:32:17,896] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.source.JdbcSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2022-12-04 23:32:17,897] INFO Instantiated task source-dbinfo-0 with version 10.6.0 of type io.confluent.connect.jdbc.source.JdbcSourceTask (org.apache.kafka.connect.runtime.Worker:520)
[2022-12-04 23:32:17,897] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-04 23:32:17,897] INFO Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task source-dbinfo-0 using the worker config (org.apache.kafka.connect.runtime.Worker:533)
[2022-12-04 23:32:17,897] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-04 23:32:17,897] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task source-dbinfo-0 using the worker config (org.apache.kafka.connect.runtime.Worker:539)
[2022-12-04 23:32:17,897] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task source-dbinfo-0 using the worker config (org.apache.kafka.connect.runtime.Worker:546)
[2022-12-04 23:32:17,898] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2022-12-04 23:32:17,898] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:32:17,898] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:600)
[2022-12-04 23:32:17,899] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-source-dbinfo-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2022-12-04 23:32:17,908] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-04 23:32:17,908] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:32:17,908] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:32:17,908] INFO Kafka startTimeMs: 1670196737908 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:32:17,910] INFO Starting JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:92)
[2022-12-04 23:32:17,910] INFO [Producer clientId=connector-producer-source-dbinfo-0] Cluster ID: uYYJbbgfRseD3C81aqQl8w (org.apache.kafka.clients.Metadata:279)
[2022-12-04 23:32:17,911] INFO Created connector source-dbinfo (org.apache.kafka.connect.cli.ConnectStandalone:109)
[2022-12-04 23:32:17,911] INFO JdbcSourceTaskConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:postgresql://localhost:5432/kafka
	connection.user = postgres
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = SELECT * FROM stations;
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	tables = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = DBInfo
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceTaskConfig:372)
[2022-12-04 23:32:17,911] INFO Using JDBC dialect PostgreSql (io.confluent.connect.jdbc.source.JdbcSourceTask:127)
[2022-12-04 23:32:17,911] INFO Attempting to open connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:79)
[2022-12-04 23:32:17,916] INFO Maximum table name length for database is 63 bytes (io.confluent.connect.jdbc.dialect.PostgreSqlDatabaseDialect:130)
[2022-12-04 23:32:17,917] INFO Started JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:296)
[2022-12-04 23:32:17,917] INFO WorkerSourceTask{id=source-dbinfo-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:232)
[2022-12-04 23:32:17,917] INFO WorkerSourceTask{id=source-dbinfo-0} Executing source task (org.apache.kafka.connect.runtime.WorkerSourceTask:238)
[2022-12-04 23:32:17,924] INFO Begin using SQL query: SELECT * FROM stations; (io.confluent.connect.jdbc.source.TableQuerier:181)
[2022-12-04 23:32:20,416] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:68)
[2022-12-04 23:32:20,421] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Private Build, OpenJDK 64-Bit Server VM, 19.0.1, 19.0.1+10-Ubuntu-1ubuntu122.04
	jvm.classpath = /home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/activation-1.1.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/argparse4j-0.7.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/audience-annotations-0.5.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/commons-cli-1.4.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/commons-lang3-3.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-api-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-basic-auth-extension-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-file-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-json-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-mirror-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-mirror-client-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-runtime-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-transforms-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/hk2-api-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/hk2-locator-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/hk2-utils-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-annotations-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-core-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-databind-2.10.5.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-module-paranamer-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.inject-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/javassist-3.27.0-GA.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/javax.servlet-api-3.1.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jaxb-api-2.3.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-client-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-common-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-container-servlet-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-hk2-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-server-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jline-3.12.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jopt-simple-5.0.4.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka_2.13-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka_2.13-2.8.1-sources.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-clients-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-connect-jdbc-10.6.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-log4j-appender-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-metadata-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-raft-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-shell-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-streams-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-streams-examples-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-streams-scala_2.13-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-streams-test-utils-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-tools-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/log4j-1.2.17.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/lz4-java-1.7.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/maven-artifact-3.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/metrics-core-2.2.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-buffer-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-codec-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-common-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-handler-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-resolver-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-transport-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-transport-native-epoll-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-transport-native-unix-common-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/paranamer-2.8.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/plexus-utils-3.2.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/postgresql-42.5.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/reflections-0.9.12.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/rocksdbjni-5.18.4.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-collection-compat_2.13-2.3.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-library-2.13.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-logging_2.13-3.9.2.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-reflect-2.13.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/slf4j-api-1.7.30.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/snappy-java-1.1.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/zookeeper-3.5.9.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/zookeeper-jute-3.5.9.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/zstd-jni-1.4.9-1.jar
	os.spec = Linux, amd64, 6.0.0-1006-oem
	os.vcpus = 20
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2022-12-04 23:32:20,422] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:77)
[2022-12-04 23:32:20,882] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Successfully joined group with generation Generation{generationId=3, memberId='connector-consumer-sink-results-0-910e01f6-5893-457c-af7c-ff74e868c0ad', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2022-12-04 23:32:20,883] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Finished assignment for group at generation 3: {connector-consumer-sink-results-0-910e01f6-5893-457c-af7c-ff74e868c0ad=Assignment(partitions=[ResultsLocation-0, ResultsWeather-0, ResultsAlert-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:626)
[2022-12-04 23:32:20,887] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Successfully synced group in generation Generation{generationId=3, memberId='connector-consumer-sink-results-0-910e01f6-5893-457c-af7c-ff74e868c0ad', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:760)
[2022-12-04 23:32:20,887] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Notifying assignor about the new Assignment(partitions=[ResultsLocation-0, ResultsWeather-0, ResultsAlert-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:276)
[2022-12-04 23:32:20,888] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Adding newly assigned partitions: ResultsLocation-0, ResultsWeather-0, ResultsAlert-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:288)
[2022-12-04 23:32:20,892] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Found no committed offset for partition ResultsWeather-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1362)
[2022-12-04 23:32:20,893] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Setting offset for partition ResultsAlert-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: r1)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:820)
[2022-12-04 23:32:20,893] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Setting offset for partition ResultsLocation-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: r1)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:820)
[2022-12-04 23:32:20,897] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Resetting offset for partition ResultsWeather-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: r1)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-04 23:32:21,062] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@251a69d7 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:269)
[2022-12-04 23:32:21,062] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,062] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,062] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,062] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,063] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,063] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,063] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,063] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,063] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,063] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,063] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,063] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,064] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,064] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,064] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,064] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,064] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,065] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,065] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,065] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,065] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,065] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,065] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,065] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,066] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,066] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,066] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,066] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,066] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,066] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,066] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,066] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,066] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,066] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,066] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,066] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,066] INFO Added plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,067] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,067] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,067] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,067] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,067] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,067] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,067] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,067] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,067] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,067] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,067] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,067] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,067] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,067] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,067] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,067] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:32:21,070] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:21,070] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:21,070] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:21,070] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:21,071] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:21,071] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:21,071] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:21,072] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:21,072] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:21,072] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:21,072] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:21,072] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:21,072] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:21,072] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:21,072] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:21,072] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:21,072] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:21,072] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:21,072] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:21,072] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:21,072] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:21,072] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:21,073] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:21,073] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:21,073] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:21,073] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:21,073] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:21,073] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:21,073] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:32:21,073] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:21,073] INFO Added aliases 'PredicatedTransformation' and 'Predicated' to plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:21,073] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:32:21,073] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:32:21,073] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:32:21,073] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:32:21,073] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:32:21,073] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:32:21,073] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:32:21,074] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:32:21,074] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:21,074] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:21,074] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:32:21,084] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = null
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:372)
[2022-12-04 23:32:21,085] WARN Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results. (org.apache.kafka.connect.runtime.WorkerConfig:420)
[2022-12-04 23:32:21,085] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:49)
[2022-12-04 23:32:21,088] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2022-12-04 23:32:21,125] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:32:21,125] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:32:21,125] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:32:21,125] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:32:21,125] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:32:21,125] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:32:21,125] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:32:21,126] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:32:21,126] INFO Kafka startTimeMs: 1670196741125 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:32:21,257] INFO Kafka cluster ID: uYYJbbgfRseD3C81aqQl8w (org.apache.kafka.connect.util.ConnectUtils:65)
[2022-12-04 23:32:21,258] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-04 23:32:21,261] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-04 23:32:21,261] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-04 23:32:21,261] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-04 23:32:21,267] INFO Logging initialized @1078ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2022-12-04 23:32:21,288] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:132)
[2022-12-04 23:32:21,288] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:204)
[2022-12-04 23:32:21,291] INFO jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 19.0.1+10-Ubuntu-1ubuntu122.04 (org.eclipse.jetty.server.Server:375)
[2022-12-04 23:32:21,299] ERROR Stopping due to error (org.apache.kafka.connect.cli.ConnectStandalone:126)
org.apache.kafka.connect.errors.ConnectException: Unable to initialize REST server
	at org.apache.kafka.connect.runtime.rest.RestServer.initializeServer(RestServer.java:216)
	at org.apache.kafka.connect.cli.ConnectStandalone.main(ConnectStandalone.java:86)
Caused by: java.io.IOException: Failed to bind to 0.0.0.0/0.0.0.0:8083
	at org.eclipse.jetty.server.ServerConnector.openAcceptChannel(ServerConnector.java:349)
	at org.eclipse.jetty.server.ServerConnector.open(ServerConnector.java:310)
	at org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)
	at org.eclipse.jetty.server.Server.doStart(Server.java:401)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)
	at org.apache.kafka.connect.runtime.rest.RestServer.initializeServer(RestServer.java:214)
	... 1 more
Caused by: java.net.BindException: Address already in use
	at java.base/sun.nio.ch.Net.bind0(Native Method)
	at java.base/sun.nio.ch.Net.bind(Net.java:555)
	at java.base/sun.nio.ch.ServerSocketChannelImpl.netBind(ServerSocketChannelImpl.java:344)
	at java.base/sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:301)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:89)
	at org.eclipse.jetty.server.ServerConnector.openAcceptChannel(ServerConnector.java:344)
	... 8 more
[2022-12-04 23:32:27,911] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:32:37,756] WARN [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Received unknown topic or partition error in fetch for partition ResultsWeather-0 (org.apache.kafka.clients.consumer.internals.Fetcher:1306)
[2022-12-04 23:32:37,759] WARN [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Error while fetching metadata with correlation id 51 : {ResultsWeather=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1100)
[2022-12-04 23:32:37,759] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Requesting to re-join the group and trigger rebalance since the assignment metadata has changed from (version3: {ResultsLocation=1, ResultsWeather=1, ResultsAlert=1}) to (version4: {ResultsLocation=1, ResultsAlert=1}) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:772)
[2022-12-04 23:32:37,759] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Requesting to re-join the group and trigger rebalance since the assignment metadata has changed from (version3: {ResultsLocation=1, ResultsWeather=1, ResultsAlert=1}) to (version4: {ResultsLocation=1, ResultsAlert=1}) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:772)
[2022-12-04 23:32:37,759] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Revoke previously assigned partitions ResultsLocation-0, ResultsWeather-0, ResultsAlert-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:307)
[2022-12-04 23:32:37,759] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2022-12-04 23:32:37,760] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Successfully joined group with generation Generation{generationId=4, memberId='connector-consumer-sink-results-0-910e01f6-5893-457c-af7c-ff74e868c0ad', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2022-12-04 23:32:37,919] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:32:38,280] WARN [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Error while fetching metadata with correlation id 53 : {ResultsWeather=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1100)
[2022-12-04 23:32:38,281] WARN [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] The following subscribed topics are not assigned to any members: [ResultsWeather]  (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:611)
[2022-12-04 23:32:38,281] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Finished assignment for group at generation 4: {connector-consumer-sink-results-0-910e01f6-5893-457c-af7c-ff74e868c0ad=Assignment(partitions=[ResultsLocation-0, ResultsAlert-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:626)
[2022-12-04 23:32:38,283] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Successfully synced group in generation Generation{generationId=4, memberId='connector-consumer-sink-results-0-910e01f6-5893-457c-af7c-ff74e868c0ad', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:760)
[2022-12-04 23:32:38,283] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Notifying assignor about the new Assignment(partitions=[ResultsLocation-0, ResultsAlert-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:276)
[2022-12-04 23:32:38,283] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Adding newly assigned partitions: ResultsLocation-0, ResultsAlert-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:288)
[2022-12-04 23:32:38,284] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Setting offset for partition ResultsAlert-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: r1)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:820)
[2022-12-04 23:32:38,284] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Setting offset for partition ResultsLocation-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: r1)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:820)
[2022-12-04 23:32:38,790] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Requesting to re-join the group and trigger rebalance since the assignment metadata has changed from (version5: {ResultsLocation=1, ResultsAlert=1}) to (version6: {ResultsLocation=1, ResultsWeather=1, ResultsAlert=1}) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:772)
[2022-12-04 23:32:38,790] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Requesting to re-join the group and trigger rebalance since the assignment metadata has changed from (version5: {ResultsLocation=1, ResultsAlert=1}) to (version6: {ResultsLocation=1, ResultsWeather=1, ResultsAlert=1}) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:772)
[2022-12-04 23:32:38,790] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Revoke previously assigned partitions ResultsLocation-0, ResultsAlert-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:307)
[2022-12-04 23:32:38,791] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2022-12-04 23:32:38,793] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Successfully joined group with generation Generation{generationId=5, memberId='connector-consumer-sink-results-0-910e01f6-5893-457c-af7c-ff74e868c0ad', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2022-12-04 23:32:38,793] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Finished assignment for group at generation 5: {connector-consumer-sink-results-0-910e01f6-5893-457c-af7c-ff74e868c0ad=Assignment(partitions=[ResultsLocation-0, ResultsWeather-0, ResultsAlert-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:626)
[2022-12-04 23:32:38,796] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Successfully synced group in generation Generation{generationId=5, memberId='connector-consumer-sink-results-0-910e01f6-5893-457c-af7c-ff74e868c0ad', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:760)
[2022-12-04 23:32:38,797] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Notifying assignor about the new Assignment(partitions=[ResultsLocation-0, ResultsWeather-0, ResultsAlert-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:276)
[2022-12-04 23:32:38,797] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Adding newly assigned partitions: ResultsLocation-0, ResultsWeather-0, ResultsAlert-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:288)
[2022-12-04 23:32:38,799] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Found no committed offset for partition ResultsWeather-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1362)
[2022-12-04 23:32:38,799] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Setting offset for partition ResultsAlert-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: r1)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:820)
[2022-12-04 23:32:38,799] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Setting offset for partition ResultsLocation-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: r1)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:820)
[2022-12-04 23:32:39,293] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Resetting offset for partition ResultsWeather-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: r1)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-04 23:32:47,922] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:32:57,923] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:33:07,925] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:33:17,929] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:33:27,931] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:33:37,933] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:33:47,935] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:33:57,937] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:34:04,607] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2022-12-04 23:34:04,608] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:327)
[2022-12-04 23:34:04,613] INFO Stopped http_8083@344561e0{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:381)
[2022-12-04 23:34:04,613] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:149)
[2022-12-04 23:34:04,615] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:344)
[2022-12-04 23:34:04,615] INFO Herder stopping (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:102)
[2022-12-04 23:34:04,615] INFO Stopping task source-dbinfo-0 (org.apache.kafka.connect.runtime.Worker:830)
[2022-12-04 23:34:07,995] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 6 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:34:07,999] INFO Stopping JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:354)
[2022-12-04 23:34:07,999] INFO Closing resources for JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:366)
[2022-12-04 23:34:08,000] INFO Closing connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:105)
[2022-12-04 23:34:08,000] INFO [Producer clientId=connector-producer-source-dbinfo-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1204)
[2022-12-04 23:34:08,002] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-04 23:34:08,003] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-04 23:34:08,003] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-04 23:34:08,003] INFO App info kafka.producer for connector-producer-source-dbinfo-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-04 23:34:08,005] INFO Stopping connector source-dbinfo (org.apache.kafka.connect.runtime.Worker:382)
[2022-12-04 23:34:08,006] INFO Scheduled shutdown for WorkerConnector{id=source-dbinfo} (org.apache.kafka.connect.runtime.WorkerConnector:248)
[2022-12-04 23:34:08,006] INFO Stopping table monitoring thread (io.confluent.connect.jdbc.JdbcSourceConnector:200)
[2022-12-04 23:34:08,006] INFO Shutting down thread monitoring tables. (io.confluent.connect.jdbc.source.TableMonitorThread:168)
[2022-12-04 23:34:08,006] INFO Closing connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:105)
[2022-12-04 23:34:08,006] INFO Completed shutdown for WorkerConnector{id=source-dbinfo} (org.apache.kafka.connect.runtime.WorkerConnector:268)
[2022-12-04 23:34:08,006] INFO Stopping task sink-results-0 (org.apache.kafka.connect.runtime.Worker:830)
[2022-12-04 23:34:08,007] INFO Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:161)
[2022-12-04 23:34:08,008] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Revoke previously assigned partitions ResultsLocation-0, ResultsWeather-0, ResultsAlert-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:307)
[2022-12-04 23:34:08,008] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Member connector-consumer-sink-results-0-910e01f6-5893-457c-af7c-ff74e868c0ad sending LeaveGroup request to coordinator localhost:9092 (id: 2147483646 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:1045)
[2022-12-04 23:34:08,010] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-04 23:34:08,010] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-04 23:34:08,010] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-04 23:34:08,011] INFO App info kafka.consumer for connector-consumer-sink-results-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-04 23:34:08,012] INFO Stopping connector sink-results (org.apache.kafka.connect.runtime.Worker:382)
[2022-12-04 23:34:08,012] INFO Scheduled shutdown for WorkerConnector{id=sink-results} (org.apache.kafka.connect.runtime.WorkerConnector:248)
[2022-12-04 23:34:08,012] INFO Completed shutdown for WorkerConnector{id=sink-results} (org.apache.kafka.connect.runtime.WorkerConnector:268)
[2022-12-04 23:34:08,012] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:205)
[2022-12-04 23:34:08,013] INFO Stopped FileOffsetBackingStore (org.apache.kafka.connect.storage.FileOffsetBackingStore:66)
[2022-12-04 23:34:08,013] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-04 23:34:08,013] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-04 23:34:08,013] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-04 23:34:08,013] INFO App info kafka.connect for 192.168.1.123:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-04 23:34:08,013] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:226)
[2022-12-04 23:34:08,014] INFO Herder stopped (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:120)
[2022-12-04 23:34:08,014] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2022-12-04 23:34:09,679] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:68)
[2022-12-04 23:34:09,683] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Private Build, OpenJDK 64-Bit Server VM, 19.0.1, 19.0.1+10-Ubuntu-1ubuntu122.04
	jvm.classpath = /home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/activation-1.1.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/argparse4j-0.7.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/audience-annotations-0.5.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/commons-cli-1.4.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/commons-lang3-3.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-api-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-basic-auth-extension-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-file-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-json-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-mirror-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-mirror-client-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-runtime-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/connect-transforms-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/hk2-api-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/hk2-locator-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/hk2-utils-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-annotations-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-core-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-databind-2.10.5.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-module-paranamer-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.inject-2.6.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/javassist-3.27.0-GA.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/javax.servlet-api-3.1.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jaxb-api-2.3.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-client-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-common-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-container-servlet-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-hk2-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jersey-server-2.34.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jline-3.12.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/jopt-simple-5.0.4.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka_2.13-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka_2.13-2.8.1-sources.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-clients-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-connect-jdbc-10.6.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-log4j-appender-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-metadata-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-raft-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-shell-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-streams-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-streams-examples-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-streams-scala_2.13-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-streams-test-utils-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/kafka-tools-2.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/log4j-1.2.17.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/lz4-java-1.7.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/maven-artifact-3.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/metrics-core-2.2.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-buffer-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-codec-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-common-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-handler-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-resolver-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-transport-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-transport-native-epoll-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/netty-transport-native-unix-common-4.1.62.Final.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/paranamer-2.8.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/plexus-utils-3.2.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/postgresql-42.5.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/reflections-0.9.12.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/rocksdbjni-5.18.4.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-collection-compat_2.13-2.3.0.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-library-2.13.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-logging_2.13-3.9.2.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/scala-reflect-2.13.5.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/slf4j-api-1.7.30.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/snappy-java-1.1.8.1.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/zookeeper-3.5.9.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/zookeeper-jute-3.5.9.jar:/home/pedro/Documents/dev/IS-Project/src/Assignment-3/kafka-connect/bin/../libs/zstd-jni-1.4.9-1.jar
	os.spec = Linux, amd64, 6.0.0-1006-oem
	os.vcpus = 20
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2022-12-04 23:34:09,684] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectStandalone:77)
[2022-12-04 23:34:10,362] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@251a69d7 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:269)
[2022-12-04 23:34:10,362] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,362] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,362] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,362] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,362] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,362] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,362] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,363] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,363] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,363] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,363] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,363] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,363] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,363] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,363] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,364] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,364] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,365] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,365] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,365] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,366] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,367] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,367] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,367] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,367] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,367] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,367] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,367] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,367] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,367] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,368] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,368] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,368] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,368] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,368] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,368] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,368] INFO Added plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,369] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,369] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,369] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,369] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,369] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,369] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,369] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,369] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,369] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,369] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,370] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,370] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,370] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,370] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,371] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,371] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-04 23:34:10,376] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:34:10,376] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:34:10,376] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:34:10,376] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:34:10,376] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:34:10,376] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:34:10,377] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:34:10,377] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:34:10,377] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:34:10,377] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:34:10,377] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:34:10,377] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:34:10,377] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:34:10,378] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:34:10,378] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:34:10,378] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:34:10,378] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:34:10,378] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:34:10,378] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:34:10,378] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:34:10,378] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:34:10,378] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:34:10,378] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:34:10,378] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:34:10,378] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:34:10,378] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:34:10,378] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:34:10,379] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:34:10,379] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:34:10,379] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:34:10,379] INFO Added aliases 'PredicatedTransformation' and 'Predicated' to plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:34:10,379] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:34:10,379] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:34:10,379] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:34:10,379] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:34:10,379] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:34:10,380] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:34:10,380] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:34:10,380] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-04 23:34:10,380] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:34:10,381] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:34:10,381] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-04 23:34:10,403] INFO StandaloneConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	config.providers = []
	connector.client.config.override.policy = None
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = null
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.file.filename = /tmp/connect.offsets
	plugin.path = null
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = null
	rest.port = 8083
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.standalone.StandaloneConfig:372)
[2022-12-04 23:34:10,404] WARN Variables cannot be used in the 'plugin.path' property, since the property is used by plugin scanning before the config providers that replace the variables are initialized. The raw value 'null' was used for plugin scanning, as opposed to the transformed value 'null', and this may cause unexpected results. (org.apache.kafka.connect.runtime.WorkerConfig:420)
[2022-12-04 23:34:10,405] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:49)
[2022-12-04 23:34:10,408] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2022-12-04 23:34:10,473] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:34:10,473] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:34:10,473] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:34:10,473] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:34:10,473] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:34:10,474] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:34:10,474] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:34:10,474] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:34:10,474] INFO Kafka startTimeMs: 1670196850474 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:34:10,704] INFO Kafka cluster ID: uYYJbbgfRseD3C81aqQl8w (org.apache.kafka.connect.util.ConnectUtils:65)
[2022-12-04 23:34:10,704] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-04 23:34:10,708] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-04 23:34:10,709] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-04 23:34:10,709] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-04 23:34:10,723] INFO Logging initialized @1259ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2022-12-04 23:34:10,750] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:132)
[2022-12-04 23:34:10,751] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:204)
[2022-12-04 23:34:10,757] INFO jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 19.0.1+10-Ubuntu-1ubuntu122.04 (org.eclipse.jetty.server.Server:375)
[2022-12-04 23:34:10,786] INFO Started http_8083@344561e0{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:331)
[2022-12-04 23:34:10,786] INFO Started @1323ms (org.eclipse.jetty.server.Server:415)
[2022-12-04 23:34:10,800] INFO Advertised URI: http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:371)
[2022-12-04 23:34:10,800] INFO REST server listening at http://192.168.1.123:8083/, advertising URL http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2022-12-04 23:34:10,800] INFO Advertised URI: http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:371)
[2022-12-04 23:34:10,801] INFO REST admin endpoints at http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:220)
[2022-12-04 23:34:10,801] INFO Advertised URI: http://192.168.1.123:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:371)
[2022-12-04 23:34:10,803] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2022-12-04 23:34:10,809] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:49)
[2022-12-04 23:34:10,809] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2022-12-04 23:34:10,812] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:34:10,812] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:34:10,812] WARN The configuration 'offset.storage.file.filename' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:34:10,812] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:34:10,812] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:34:10,812] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-04 23:34:10,812] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:34:10,812] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:34:10,812] INFO Kafka startTimeMs: 1670196850812 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:34:10,819] INFO Kafka cluster ID: uYYJbbgfRseD3C81aqQl8w (org.apache.kafka.connect.util.ConnectUtils:65)
[2022-12-04 23:34:10,819] INFO App info kafka.admin.client for adminclient-2 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-04 23:34:10,821] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-04 23:34:10,821] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-04 23:34:10,821] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-04 23:34:10,823] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:34:10,823] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:34:10,823] INFO Kafka startTimeMs: 1670196850823 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:34:10,878] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-04 23:34:10,879] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-04 23:34:10,882] INFO Kafka Connect standalone worker initialization took 1202ms (org.apache.kafka.connect.cli.ConnectStandalone:99)
[2022-12-04 23:34:10,882] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2022-12-04 23:34:10,883] INFO Herder starting (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:94)
[2022-12-04 23:34:10,883] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:191)
[2022-12-04 23:34:10,883] INFO Starting FileOffsetBackingStore with file /tmp/connect.offsets (org.apache.kafka.connect.storage.FileOffsetBackingStore:58)
[2022-12-04 23:34:10,887] INFO Worker started (org.apache.kafka.connect.runtime.Worker:198)
[2022-12-04 23:34:10,888] INFO Herder started (org.apache.kafka.connect.runtime.standalone.StandaloneHerder:97)
[2022-12-04 23:34:10,888] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:224)
[2022-12-04 23:34:10,908] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:241)
[2022-12-04 23:34:10,945] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2022-12-04 23:34:10,945] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2022-12-04 23:34:10,946] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session:132)
[2022-12-04 23:34:11,316] INFO Started o.e.j.s.ServletContextHandler@26ae880a{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:915)
[2022-12-04 23:34:11,317] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:319)
[2022-12-04 23:34:11,317] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2022-12-04 23:34:11,348] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2022-12-04 23:34:11,369] INFO Creating connector sink-results of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:271)
[2022-12-04 23:34:11,370] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2022-12-04 23:34:11,371] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:34:11,378] INFO Instantiated connector sink-results with version 10.6.0 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:281)
[2022-12-04 23:34:11,380] INFO Finished creating connector sink-results (org.apache.kafka.connect.runtime.Worker:306)
[2022-12-04 23:34:11,384] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2022-12-04 23:34:11,385] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:34:11,387] INFO Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:51)
[2022-12-04 23:34:11,389] INFO Creating task sink-results-0 (org.apache.kafka.connect.runtime.Worker:505)
[2022-12-04 23:34:11,391] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2022-12-04 23:34:11,392] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:34:11,393] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2022-12-04 23:34:11,393] INFO Instantiated task sink-results-0 with version 10.6.0 of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:520)
[2022-12-04 23:34:11,394] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:372)
[2022-12-04 23:34:11,394] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-04 23:34:11,394] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task sink-results-0 using the connector config (org.apache.kafka.connect.runtime.Worker:535)
[2022-12-04 23:34:11,394] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task sink-results-0 using the connector config (org.apache.kafka.connect.runtime.Worker:541)
[2022-12-04 23:34:11,395] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task sink-results-0 using the worker config (org.apache.kafka.connect.runtime.Worker:546)
[2022-12-04 23:34:11,400] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:626)
[2022-12-04 23:34:11,401] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2022-12-04 23:34:11,401] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = sink-results
	predicates = []
	tasks.max = 1
	topics = [ResultsWeather, ResultsAlert, ResultsLocation]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:34:11,411] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-sink-results-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-sink-results
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2022-12-04 23:34:11,444] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-04 23:34:11,444] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:34:11,445] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:34:11,445] INFO Kafka startTimeMs: 1670196851444 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:34:11,450] INFO Created connector sink-results (org.apache.kafka.connect.cli.ConnectStandalone:109)
[2022-12-04 23:34:11,451] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Subscribed to topic(s): ResultsWeather, ResultsAlert, ResultsLocation (org.apache.kafka.clients.consumer.KafkaConsumer:965)
[2022-12-04 23:34:11,451] INFO Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:48)
[2022-12-04 23:34:11,451] INFO JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:postgresql://localhost:5432/kafka
	connection.user = postgres
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = upsert
	max.retries = 10
	pk.fields = [id]
	pk.mode = record_key
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:372)
[2022-12-04 23:34:11,454] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:postgresql://localhost:5432/kafka
	connection.user = postgres
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = SELECT * FROM stations;
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = DBInfo
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:372)
[2022-12-04 23:34:11,455] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2022-12-04 23:34:11,456] INFO Creating connector source-dbinfo of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:271)
[2022-12-04 23:34:11,456] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2022-12-04 23:34:11,456] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:34:11,457] INFO Initializing writer using SQL dialect: PostgreSqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:67)
[2022-12-04 23:34:11,458] INFO Instantiated connector source-dbinfo with version 10.6.0 of type class io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:281)
[2022-12-04 23:34:11,458] INFO Finished creating connector source-dbinfo (org.apache.kafka.connect.runtime.Worker:306)
[2022-12-04 23:34:11,458] INFO WorkerSinkTask{id=sink-results-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:310)
[2022-12-04 23:34:11,458] INFO WorkerSinkTask{id=sink-results-0} Executing sink task (org.apache.kafka.connect.runtime.WorkerSinkTask:196)
[2022-12-04 23:34:11,458] INFO Starting JDBC Source Connector (io.confluent.connect.jdbc.JdbcSourceConnector:71)
[2022-12-04 23:34:11,458] INFO JdbcSourceConnectorConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:postgresql://localhost:5432/kafka
	connection.user = postgres
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = SELECT * FROM stations;
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = DBInfo
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceConnectorConfig:372)
[2022-12-04 23:34:11,459] INFO Attempting to open connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:79)
[2022-12-04 23:34:11,467] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Cluster ID: uYYJbbgfRseD3C81aqQl8w (org.apache.kafka.clients.Metadata:279)
[2022-12-04 23:34:11,468] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Discovered group coordinator localhost:9092 (id: 2147483646 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:850)
[2022-12-04 23:34:11,469] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2022-12-04 23:34:11,481] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2022-12-04 23:34:11,529] INFO Maximum table name length for database is 63 bytes (io.confluent.connect.jdbc.dialect.PostgreSqlDatabaseDialect:130)
[2022-12-04 23:34:11,531] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2022-12-04 23:34:11,532] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:34:11,533] INFO Creating task source-dbinfo-0 (org.apache.kafka.connect.runtime.Worker:505)
[2022-12-04 23:34:11,533] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2022-12-04 23:34:11,533] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:34:11,534] INFO TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.source.JdbcSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2022-12-04 23:34:11,534] INFO Instantiated task source-dbinfo-0 with version 10.6.0 of type io.confluent.connect.jdbc.source.JdbcSourceTask (org.apache.kafka.connect.runtime.Worker:520)
[2022-12-04 23:34:11,534] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-04 23:34:11,534] INFO Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task source-dbinfo-0 using the worker config (org.apache.kafka.connect.runtime.Worker:533)
[2022-12-04 23:34:11,534] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-04 23:34:11,534] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task source-dbinfo-0 using the worker config (org.apache.kafka.connect.runtime.Worker:539)
[2022-12-04 23:34:11,534] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task source-dbinfo-0 using the worker config (org.apache.kafka.connect.runtime.Worker:546)
[2022-12-04 23:34:11,535] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2022-12-04 23:34:11,535] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = source-dbinfo
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-04 23:34:11,535] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:600)
[2022-12-04 23:34:11,539] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-source-dbinfo-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2022-12-04 23:34:11,549] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-04 23:34:11,549] INFO Kafka version: 2.8.1 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-04 23:34:11,549] INFO Kafka commitId: 839b886f9b732b15 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-04 23:34:11,549] INFO Kafka startTimeMs: 1670196851549 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-04 23:34:11,551] INFO Starting JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:92)
[2022-12-04 23:34:11,552] INFO Created connector source-dbinfo (org.apache.kafka.connect.cli.ConnectStandalone:109)
[2022-12-04 23:34:11,552] INFO JdbcSourceTaskConfig values: 
	batch.max.rows = 100
	catalog.pattern = null
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:postgresql://localhost:5432/kafka
	connection.user = postgres
	db.timezone = UTC
	dialect.name = 
	incrementing.column.name = 
	mode = bulk
	numeric.mapping = null
	numeric.precision.mapping = false
	poll.interval.ms = 5000
	query = SELECT * FROM stations;
	query.retry.attempts = -1
	query.suffix = 
	quote.sql.identifiers = ALWAYS
	schema.pattern = null
	table.blacklist = []
	table.monitoring.startup.polling.limit.ms = 10000
	table.poll.interval.ms = 60000
	table.types = [TABLE]
	table.whitelist = []
	tables = []
	timestamp.column.name = []
	timestamp.delay.interval.ms = 0
	timestamp.granularity = connect_logical
	timestamp.initial = null
	topic.prefix = DBInfo
	transaction.isolation.mode = DEFAULT
	validate.non.null = true
 (io.confluent.connect.jdbc.source.JdbcSourceTaskConfig:372)
[2022-12-04 23:34:11,552] INFO Using JDBC dialect PostgreSql (io.confluent.connect.jdbc.source.JdbcSourceTask:127)
[2022-12-04 23:34:11,552] INFO Attempting to open connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:79)
[2022-12-04 23:34:11,552] INFO [Producer clientId=connector-producer-source-dbinfo-0] Cluster ID: uYYJbbgfRseD3C81aqQl8w (org.apache.kafka.clients.Metadata:279)
[2022-12-04 23:34:11,557] INFO Maximum table name length for database is 63 bytes (io.confluent.connect.jdbc.dialect.PostgreSqlDatabaseDialect:130)
[2022-12-04 23:34:11,558] INFO Started JDBC source task (io.confluent.connect.jdbc.source.JdbcSourceTask:296)
[2022-12-04 23:34:11,558] INFO WorkerSourceTask{id=source-dbinfo-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:232)
[2022-12-04 23:34:11,558] INFO WorkerSourceTask{id=source-dbinfo-0} Executing source task (org.apache.kafka.connect.runtime.WorkerSourceTask:238)
[2022-12-04 23:34:11,571] INFO Begin using SQL query: SELECT * FROM stations; (io.confluent.connect.jdbc.source.TableQuerier:181)
[2022-12-04 23:34:14,484] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Successfully joined group with generation Generation{generationId=7, memberId='connector-consumer-sink-results-0-aba31e6c-0b3f-4f37-89e0-1fc9c2d77b36', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2022-12-04 23:34:14,487] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Finished assignment for group at generation 7: {connector-consumer-sink-results-0-aba31e6c-0b3f-4f37-89e0-1fc9c2d77b36=Assignment(partitions=[ResultsLocation-0, ResultsWeather-0, ResultsAlert-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:626)
[2022-12-04 23:34:14,491] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Successfully synced group in generation Generation{generationId=7, memberId='connector-consumer-sink-results-0-aba31e6c-0b3f-4f37-89e0-1fc9c2d77b36', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:760)
[2022-12-04 23:34:14,491] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Notifying assignor about the new Assignment(partitions=[ResultsLocation-0, ResultsWeather-0, ResultsAlert-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:276)
[2022-12-04 23:34:14,491] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Adding newly assigned partitions: ResultsLocation-0, ResultsWeather-0, ResultsAlert-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:288)
[2022-12-04 23:34:14,494] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Found no committed offset for partition ResultsWeather-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1362)
[2022-12-04 23:34:14,495] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Setting offset for partition ResultsAlert-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: r1)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:820)
[2022-12-04 23:34:14,495] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Setting offset for partition ResultsLocation-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: r1)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:820)
[2022-12-04 23:34:14,498] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Resetting offset for partition ResultsWeather-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: r1)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-04 23:34:21,552] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:34:31,559] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:34:41,563] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:34:51,565] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:35:01,568] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:35:11,570] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:35:21,573] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:35:31,576] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:35:41,577] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:35:51,580] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:36:01,584] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:36:11,587] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:36:21,590] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:36:31,593] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:36:41,595] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:36:51,597] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:37:01,599] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:37:11,600] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:37:21,602] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:37:31,605] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:37:41,607] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:37:51,610] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:38:01,611] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:38:11,614] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:38:21,615] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:38:31,617] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:38:41,619] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:38:51,623] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:39:01,625] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:39:11,628] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:39:21,630] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:39:31,632] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:39:41,634] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:39:51,636] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:40:01,639] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:40:11,641] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:40:21,643] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:40:31,646] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:40:41,647] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:40:51,649] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:41:01,652] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:41:11,654] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:41:21,657] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:41:31,659] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:41:41,662] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:41:51,664] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:42:01,667] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:42:11,669] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:42:21,671] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:42:31,672] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:42:41,674] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:42:51,676] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:43:01,679] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:43:11,681] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:43:21,684] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:43:31,686] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:43:41,689] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:43:51,692] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:44:01,694] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:44:11,696] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:44:21,697] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:44:31,699] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:44:41,701] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:44:51,703] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:45:01,706] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:45:11,707] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:45:21,710] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:45:31,712] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:45:41,714] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:45:51,716] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:46:01,718] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:46:11,719] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:46:21,723] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:46:31,725] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:46:41,727] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:46:51,730] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:47:01,732] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:47:11,733] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:47:21,735] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:47:31,736] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:47:41,738] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:47:51,740] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:48:01,742] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:48:11,745] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:48:21,748] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:48:31,749] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:48:41,751] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:48:51,753] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:49:01,755] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:49:11,757] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:49:21,759] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:49:31,761] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:49:41,762] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:49:51,764] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:50:01,766] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:50:11,768] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:50:21,771] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:50:31,773] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:50:41,775] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:50:51,777] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:51:01,779] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:51:11,781] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:51:21,784] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:51:31,786] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:51:41,788] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:51:51,790] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:52:01,792] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:52:11,795] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:52:21,798] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:52:31,800] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:52:41,803] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:52:51,805] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:53:01,806] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:53:11,807] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:53:21,808] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:53:31,809] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:53:41,811] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:53:51,812] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:54:01,814] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:54:11,816] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:54:21,817] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:54:31,819] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:54:41,821] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:54:51,823] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:55:01,824] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:55:11,827] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:55:21,830] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:55:31,832] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:55:41,834] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:55:51,836] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:56:01,838] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:56:11,840] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:56:21,842] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:56:31,843] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:56:41,845] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:56:51,847] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:56:54,822] WARN [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Received unknown topic or partition error in fetch for partition ResultsWeather-0 (org.apache.kafka.clients.consumer.internals.Fetcher:1306)
[2022-12-04 23:56:54,825] WARN [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Error while fetching metadata with correlation id 3175 : {ResultsWeather=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1100)
[2022-12-04 23:56:54,825] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Requesting to re-join the group and trigger rebalance since the assignment metadata has changed from (version2: {ResultsLocation=1, ResultsWeather=1, ResultsAlert=1}) to (version7: {ResultsLocation=1, ResultsAlert=1}) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:772)
[2022-12-04 23:56:54,825] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Requesting to re-join the group and trigger rebalance since the assignment metadata has changed from (version2: {ResultsLocation=1, ResultsWeather=1, ResultsAlert=1}) to (version7: {ResultsLocation=1, ResultsAlert=1}) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:772)
[2022-12-04 23:56:54,825] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Revoke previously assigned partitions ResultsLocation-0, ResultsWeather-0, ResultsAlert-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:307)
[2022-12-04 23:56:54,826] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2022-12-04 23:56:54,827] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Successfully joined group with generation Generation{generationId=8, memberId='connector-consumer-sink-results-0-aba31e6c-0b3f-4f37-89e0-1fc9c2d77b36', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2022-12-04 23:56:55,353] WARN [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Error while fetching metadata with correlation id 3177 : {ResultsWeather=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1100)
[2022-12-04 23:56:55,354] WARN [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] The following subscribed topics are not assigned to any members: [ResultsWeather]  (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:611)
[2022-12-04 23:56:55,354] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Finished assignment for group at generation 8: {connector-consumer-sink-results-0-aba31e6c-0b3f-4f37-89e0-1fc9c2d77b36=Assignment(partitions=[ResultsLocation-0, ResultsAlert-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:626)
[2022-12-04 23:56:55,357] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Successfully synced group in generation Generation{generationId=8, memberId='connector-consumer-sink-results-0-aba31e6c-0b3f-4f37-89e0-1fc9c2d77b36', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:760)
[2022-12-04 23:56:55,357] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Notifying assignor about the new Assignment(partitions=[ResultsLocation-0, ResultsAlert-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:276)
[2022-12-04 23:56:55,357] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Adding newly assigned partitions: ResultsLocation-0, ResultsAlert-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:288)
[2022-12-04 23:56:55,359] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Setting offset for partition ResultsAlert-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: r1)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:820)
[2022-12-04 23:56:55,359] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Setting offset for partition ResultsLocation-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: r1)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:820)
[2022-12-04 23:56:55,864] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Requesting to re-join the group and trigger rebalance since the assignment metadata has changed from (version8: {ResultsLocation=1, ResultsAlert=1}) to (version9: {ResultsLocation=1, ResultsWeather=1, ResultsAlert=1}) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:772)
[2022-12-04 23:56:55,864] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Requesting to re-join the group and trigger rebalance since the assignment metadata has changed from (version8: {ResultsLocation=1, ResultsAlert=1}) to (version9: {ResultsLocation=1, ResultsWeather=1, ResultsAlert=1}) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:772)
[2022-12-04 23:56:55,865] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Revoke previously assigned partitions ResultsLocation-0, ResultsAlert-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:307)
[2022-12-04 23:56:55,865] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2022-12-04 23:56:55,866] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Successfully joined group with generation Generation{generationId=9, memberId='connector-consumer-sink-results-0-aba31e6c-0b3f-4f37-89e0-1fc9c2d77b36', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2022-12-04 23:56:55,867] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Finished assignment for group at generation 9: {connector-consumer-sink-results-0-aba31e6c-0b3f-4f37-89e0-1fc9c2d77b36=Assignment(partitions=[ResultsLocation-0, ResultsWeather-0, ResultsAlert-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:626)
[2022-12-04 23:56:55,869] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Successfully synced group in generation Generation{generationId=9, memberId='connector-consumer-sink-results-0-aba31e6c-0b3f-4f37-89e0-1fc9c2d77b36', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:760)
[2022-12-04 23:56:55,870] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Notifying assignor about the new Assignment(partitions=[ResultsLocation-0, ResultsWeather-0, ResultsAlert-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:276)
[2022-12-04 23:56:55,870] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Adding newly assigned partitions: ResultsLocation-0, ResultsWeather-0, ResultsAlert-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:288)
[2022-12-04 23:56:55,871] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Found no committed offset for partition ResultsWeather-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1362)
[2022-12-04 23:56:55,872] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Setting offset for partition ResultsAlert-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: r1)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:820)
[2022-12-04 23:56:55,872] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Setting offset for partition ResultsLocation-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: r1)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:820)
[2022-12-04 23:56:56,367] INFO [Consumer clientId=connector-consumer-sink-results-0, groupId=connect-sink-results] Resetting offset for partition ResultsWeather-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: r1)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-04 23:57:00,917] INFO Attempting to open connection #1 to PostgreSql (io.confluent.connect.jdbc.util.CachedConnectionProvider:79)
[2022-12-04 23:57:00,922] INFO Maximum table name length for database is 63 bytes (io.confluent.connect.jdbc.dialect.PostgreSqlDatabaseDialect:130)
[2022-12-04 23:57:00,922] INFO JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2022-12-04 23:57:00,929] INFO Checking PostgreSql dialect for existence of TABLE "ResultsWeather" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:586)
[2022-12-04 23:57:00,931] INFO Using PostgreSql dialect TABLE "ResultsWeather" absent (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:594)
[2022-12-04 23:57:00,932] INFO Creating table with sql: CREATE TABLE "ResultsWeather" (
"id" TEXT NOT NULL,
"count" BIGINT NOT NULL,
PRIMARY KEY("id")) (io.confluent.connect.jdbc.sink.DbStructure:122)
[2022-12-04 23:57:00,951] INFO Checking PostgreSql dialect for existence of TABLE "ResultsWeather" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:586)
[2022-12-04 23:57:00,952] INFO Using PostgreSql dialect TABLE "ResultsWeather" present (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:594)
[2022-12-04 23:57:00,956] INFO Checking PostgreSql dialect for type of TABLE "ResultsWeather" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:880)
[2022-12-04 23:57:00,958] INFO Setting metadata for table "ResultsWeather" to Table{name='"ResultsWeather"', type=TABLE columns=[Column{'count', isPrimaryKey=false, allowsNull=false, sqlType=int8}, Column{'id', isPrimaryKey=true, allowsNull=false, sqlType=text}]} (io.confluent.connect.jdbc.util.TableDefinitions:64)
[2022-12-04 23:57:01,850] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:57:11,851] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:57:21,854] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:57:31,855] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:57:41,857] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:57:51,858] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:58:01,861] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:58:11,863] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:58:21,865] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:58:31,866] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:58:41,868] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:58:51,871] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:59:01,874] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:59:11,876] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:59:21,878] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:59:31,879] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:59:41,881] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
[2022-12-04 23:59:51,883] INFO WorkerSourceTask{id=source-dbinfo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:510)
